---
title: "AGS paper I simulation results"
author: "[John Zobolas](https://github.com/bblodfon)"
date: "Last updated: `r format(Sys.time(), '%d %B, %Y')`"
description: "AGS paper I simulation results"
url: 'https\://username.github.io/reponame/'
github-repo: "username/reponame"
bibliography: references.bib
link-citations: true
site: bookdown::bookdown_site
---

# Intro {-}

This report has the AGS-Paper I data analysis and resulting figures.

# Input {-}

Loading libraries:
```{r Load libraries, message = FALSE}
library(DT)
library(ggpubr)
library(plotly)
library(xfun)
library(dplyr)
library(tibble)
library(emba)
library(usefun)
library(readr)

# ROC packages
library(ROCR)
```

# Reproduce simulation results {-}

## ROC curves {-}

- Install `druglogics-synergy`
- Run the script `run_druglogics_synergy.sh` in the above repo using the configuration settings: 
  - `simulations: 50` ???
  - `attractor_tool: biolqm_stable_states`
  - `synergy_method: bliss` ???

Thus you will get a directory per simulation and inside will be several result files.

Here we use the ensemble-wise and model-wise synergies found in each respective simulation.

## Random model results {-}

The CASCADE 1.0 and 2.0 `.sif` network files can be found at the directories `ags_cascade_1.0` and `ags_cascade_2.0` on the
`druglogics-synergy` repository.

Run the abmlog for the CASCADE 2.0 topology:
```
java -cp target/abmlog-1.5.0-jar-with-dependencies.jar eu.druglogics.abmlog.RandomBooleanModelGenerator --file=test/cascade_2_0.sif --num=3000
```

Next, prune the resulting models to only the ones that have 1 stable state ($1292$) using a simple bash script, while renaming the modelnames inside the files so that they have the string `_run_` (mimicking thus the files generated by gitsbe - otherwise drabme fails!) - use the script `process_models.sh` inside the generated `models` directory from `abmlog`.

```
cd pathTo/druglogics-synergy/ags_cascade_2.0
```

- Move the `models` dir inside the `ags_cascade_2.0` dir
- Use attractor_tool: `biolqm_stable_states` in the config file
- Use either `synergy_method: hsa` or `synergy_method: bliss`
- Run drabme via `druglogics-synergy`:

```
java -cp ../target/synergy-1.2.0-jar-with-dependencies.jar eu.druglogics.drabme.Launcher --project=cascade_2.0_random_hsa --modelsDir=models --drugs=drugpanel --perturbations=perturbations --config=config --modeloutputs=modeloutputs
java -cp ../target/synergy-1.2.0-jar-with-dependencies.jar eu.druglogics.drabme.Launcher --project=cascade_2.0_random_bliss --modelsDir=models --drugs=drugpanel --perturbations=perturbations --config=config --modeloutputs=modeloutputs
```

The above procedure is the same for CASCADE 1.0. Changes:
- Network file is now the `cascade_1_0.sif`
- The `process_models.sh` needs a small name change (documented inside the script)
- The `models` directory should be put inside the `ags_cascade_1.0` of `druglogics-synergy`
- The drabme command should be run with `--project=cascade_1.0_random_hsa` and `--project=cascade_1.0_random_bliss`


# Cascade 1.0 Analysis {-}

:::{.blue-box}
Performance of automatically parameterized models against published data in PLOS comput biol 2015 Flobak paper
:::

Random performance (mw - ew): hsa - bliss
Calibrated performance (mw - ew): hsa - bliss
Investigate normalization parameter

```{r load cascade_1.0 results}
# 'ss' => calibrated models, 'random' => random models

## HSA results
ss_hsa_ensemblewise_file = paste0("results/hsa/cascade_1.0_ss_50sim_fixpoints_ensemblewise_synergies.tab")
ss_hsa_modelwise_file = paste0("results/hsa/cascade_1.0_ss_50sim_fixpoints_modelwise_synergies.tab")
random_hsa_ensemblewise_file = paste0("results/hsa/cascade_1.0_random_ensemblewise_synergies.tab")
random_hsa_modelwise_file = paste0("results/hsa/cascade_1.0_random_modelwise_synergies.tab")

ss_hsa_ensemblewise_synergies = emba::get_synergy_scores(ss_hsa_ensemblewise_file)
ss_hsa_modelwise_synergies = emba::get_synergy_scores(ss_hsa_modelwise_file, file_type = "modelwise")
random_hsa_ensemblewise_synergies = emba::get_synergy_scores(random_hsa_ensemblewise_file)
random_hsa_modelwise_synergies = emba::get_synergy_scores(random_hsa_modelwise_file, file_type = "modelwise")

## Bliss results
ss_bliss_ensemblewise_file = paste0("results/bliss/cascade_1.0_ss_50sim_fixpoints_ensemblewise_synergies.tab")
ss_bliss_modelwise_file = paste0("results/bliss/cascade_1.0_ss_50sim_fixpoints_modelwise_synergies.tab")
random_bliss_ensemblewise_file = paste0("results/bliss/cascade_1.0_random_bliss_ensemblewise_synergies.tab")
random_bliss_modelwise_file = paste0("results/bliss/cascade_1.0_random_bliss_modelwise_synergies.tab")

ss_bliss_ensemblewise_synergies = emba::get_synergy_scores(ss_bliss_ensemblewise_file)
ss_bliss_modelwise_synergies = emba::get_synergy_scores(ss_bliss_modelwise_file, file_type = "modelwise")
random_bliss_ensemblewise_synergies = emba::get_synergy_scores(random_bliss_ensemblewise_file)
random_bliss_modelwise_synergies = emba::get_synergy_scores(random_bliss_modelwise_file, file_type = "modelwise")

observed_synergies_file = paste0("results/observed_synergies_cascade_1.0")
observed_synergies = get_observed_synergies(observed_synergies_file)
# 1 (positive/observed synergy) or 0 (negative/not observed) for all tested drug combinations
observed = sapply(random_bliss_modelwise_synergies$perturbation %in% observed_synergies, as.integer)
```

```{r ROC, fig.width=5, fig.height=5, dpi=600, cache=TRUE}
pred = bind_cols(ss_hsa_ensemblewise_synergies %>% rename(ss_score = score), 
  random_hsa_ensemblewise_synergies %>% select(score) %>% rename(random_score = score), 
  as_tibble_col(observed, column_name = "observed"))

res_ss = get_roc_stats(df = pred, pred_col = "ss_score", obs_col = "observed")
res_random = get_roc_stats(df = pred, pred_col = "random_score", obs_col = "observed")

# Plot ROCs
my_palette = RColorBrewer::brewer.pal(n = 9, name="Set1")

plot(x = res_ss$roc_stats$FPR, y = res_ss$roc_stats$TPR,
  type = 'l', lwd = 2, col = my_palette[1], main = 'ROC curve, Ensemble-wise synergies (HSA)',
  xlab = 'False Positive Rate (FPR)', ylab = 'True Positive Rate (TPR)')
lines(x = res_random$roc_stats$FPR, y = res_random$roc_stats$TPR, 
  lwd = 2, col = my_palette[2])
legend('bottomright', title = 'AUC', col = my_palette[1:2], pch = 19,
  legend = c(paste(round(res_ss$AUC, digits = 3), "Calibrated"), 
    paste(round(res_random$AUC, digits = 3), "Random")))
grid()
abline(a = 0, b = 1, col = '#FF726F', lty = 2)
```















```{r ROC sensitivity cascade 1.0}
# original + beta * random
betas = seq(from = -20, to = 10, by = 0.1)

auc_values = sapply(betas, function(beta) {
  pred = pred %>% mutate(norm_score = ss_score + (beta * rand_score))
  #pred = pred %>% mutate(norm_score = ss_score_norm + (beta * rand_score_norm))
  res = get_roc_stats(df = pred, pred_col = "norm_score", obs_col = "observed")
  auc_value = res$AUC
})

df = as_tibble(cbind(betas, auc_values))

# ggline(data = df, x = "betas", y = "auc_values", numeric.x.axis = TRUE,
#   title = "AUC sensitivity to beta normalization parameter", xlab = "Beta parameter", ylab = "AUC value",
#   color = RColorBrewer::brewer.pal(3, "Set1")[2])

my.title.font = list(family = "Courier New, monospace", size = 18, color = "black")

plot_ly(data = df, x = ~betas, y = ~auc_values, width = 800,
  type = "scatter", mode = "lines+markers", colors = "Set1") %>%
  layout(title = list(text = "AUC sensitivity to beta normalization parameter", font = my.title.font),
    xaxis = list(title = "Beta parameter"),
    yaxis = list(title = "Area Under ROC curve")) %>%
  config(displayModeBar = FALSE)
```

```{r ROC cascade 1}
#best_beta = -0.7
#pred = pred %>% mutate(norm_score = ss_score + (best_beta * rand_score))
res = get_roc_stats(df = pred, pred_col = "combined_score_2", obs_col = "observed")

plot(x = res$roc_stats$FPR, y = res$roc_stats$TPR,
  type = 'l', lwd = 2, col = '#377EB8', main = 'ROC curve',
  xlab = 'False Positive Rate (FPR)', ylab = 'True Positive Rate (TPR)')
legend('bottomright', legend = round(res$AUC, digits = 3),
  title = 'AUC', col = '#377EB8', pch = 19)
grid()
abline(a = 0, b = 1, col = '#FF726F', lty = 2)
```

# Cascade 2.0 Analysis {-}

:::{.blue-box}
Performance of automatically parameterized models against a new dataset (SINTEF, AGS only)
:::

## AUC sensitivity (ensemblewise) {-}

$$score = original + \beta\times random$$

Using **CASCADE 2.0, 50 simulations, BioLQM fixpoints**:

Loading results:
```{r cascade 2.0 results}
original_file = paste0(res_dir, "cascade_2.0_ss_50sim_fixpoints_ensemblewise_synergies.tab")
random_file = paste0(res_dir, "cascade_2.0_rand_50sim_fixpoints_ensemblewise_synergies.tab")
observed_synergies_file = paste0(res_dir, "observed_synergies_cascade_2.0")

observed_synergies = emba::get_observed_synergies(observed_synergies_file)
orig_res = emba::get_synergy_scores(original_file)
rand_res = emba::get_synergy_scores(random_file)

# 1 or 0 for all tested drug combinations: is it observed (TP) or not (TN)?
observed = sapply(orig_res$perturbation %in% observed_synergies, as.integer)
```

Ensemblewise ROC sensitivy analysis:

```{r ensemble-wise ROC sensitivity analysis}
# original + beta * random
betas = seq(from = -5, to = 5, by = 0.05)

auc_values = sapply(betas, function(beta) {
  value = orig_res$score + (beta * rand_res$score)
  pred = prediction(predictions = 1 - normalize_to_range(value), labels = observed)
  auc_res = performance(prediction.obj = pred, measure = "auc")
  auc_value = unlist(auc_res@y.values)
})

df = as_tibble(cbind(betas, auc_values))

# ggline(data = df, x = "betas", y = "auc_values", numeric.x.axis = TRUE,
#   title = "AUC sensitivity to beta normalization parameter", xlab = "Beta parameter", ylab = "AUC value",
#   color = RColorBrewer::brewer.pal(3, "Set1")[2])

my.title.font = list(family = "Courier New, monospace", size = 18, color = "black")

plot_ly(data = df, x = ~betas, y = ~auc_values, width = 800,
  type = "scatter", mode = "lines+markers", colors = "Set1") %>%
  layout(title = list(text = "AUC sensitivity to beta normalization parameter", font = my.title.font),
    xaxis = list(title = "Beta parameter"),
    yaxis = list(title = "Area Under ROC curve")) %>%
  config(displayModeBar = FALSE)
```

:::{.green-box}
- How information from the 'random' models is augmenting calibrated (to steady state) results?
- $\beta \rightarrow +\infty$: only random model predictions
- $\beta \rightarrow -\infty$: only the *reverse* random model predictions
- $AUC_{\beta \rightarrow +\infty} + AUC_{\beta \rightarrow -\infty} = 1$ (complementary)
- Shape of the curve above means:
  - Random models perform statistically the same as calibrated ones
  - But they are not random, they are from the same *proliferative model pool* (all modeloutput nodes are included in the steady state)
:::

## AUC sensitivity (modelwise) {-}

```{r model-wise ROC sensitivity analysis}
modelwise_synergies_file = paste0(res_dir, "cascade_2.0_ss_50sim_fixpoints_modelwise_synergies.tab")
modelwise_synergies_file_rand = paste0(res_dir, "cascade_2.0_rand_50sim_fixpoints_modelwise_synergies.tab")

# original
modelwise_res = get_synergy_scores(file_name = modelwise_synergies_file, file_type = "modelwise")
modelwise_res = modelwise_res %>% 
  mutate(`synergy_prob_ss` = synergies/(synergies + `non-synergies`)) # add synergy probability

# random
modelwise_res_rand = get_synergy_scores(file_name = modelwise_synergies_file_rand, file_type = "modelwise")
modelwise_res_rand = modelwise_res_rand %>% 
  mutate(`synergy_prob_rand` = synergies/(synergies + `non-synergies`)) # add synergy probability
```

We can combine original and random via a weighted probability score:
$$(1-w) \times prob_{ss} + w \times prob_{rand}, w \in[0,1]$$
- More $w$, more random in the game
- Range: **from original only to random only**

```{r model-wise ROC sensitivity analysis, probability-weight based}
# weighted average
weights = seq(from = 0, to = 1, by = 0.05)

pred_modelwise = bind_cols(modelwise_res %>% select(perturbation),
  modelwise_res %>% select(synergy_prob_ss), 
  modelwise_res_rand %>% select(synergy_prob_rand),
  as_tibble_col(observed, column_name = "observed"))

auc_values = sapply(weights, function(w) {
  pred_modelwise = pred_modelwise %>% mutate(weighted_prob = 1 - (
      (1 - w) * pred_modelwise$synergy_prob_ss + w * pred_modelwise$synergy_prob_rand
  ))
  res = get_roc_stats(df = pred_modelwise, pred_col = "weighted_prob", obs_col = "observed")
  auc_value = res$AUC
})

df = as_tibble(cbind(weights, auc_values))

# ggline(data = df, x = "betas", y = "auc_values", numeric.x.axis = TRUE,
#   title = "AUC sensitivity to beta normalization parameter", xlab = "Beta parameter", ylab = "AUC value",
#   color = RColorBrewer::brewer.pal(3, "Set1")[2])

plot_ly(data = df, x = ~weights, y = ~auc_values, width = 800,
  type = "scatter", mode = "lines+markers", colors = "Set1") %>%
  layout(title = list(text = "AUC sensitivity to weighted average", font = my.title.font),
    xaxis = list(title = "Weight"),
    yaxis = list(title = "Area Under ROC curve")) %>%
  config(displayModeBar = FALSE)
```

## Correlation (ensemblewise vs modelwise) {-}

Results correlate between model-wise and ensemble-wise original (steady-state fitting) results:

```{r Correlation between ensemble-wise and model-wise original results, message=FALSE}
data = bind_cols(as_tibble(1 - normalize_to_range(orig_res$score)), modelwise_res %>% select(synergy_prob_ss))
colnames(data) = c("ensemblewise", "modelwise")

# all(modelwise_res$perturbation == predictions_df$perturbation)
ggscatter(data = data, x = "ensemblewise", y = "modelwise", add = "reg.line",
   add.params = list(color = "blue", fill = "lightgray"),
   conf.int = TRUE, cor.coef = TRUE, cor.coeff.args = list(method = "pearson"))
```

## Compare modelwise vs ensemblewise best ROCs {-}

```{r ROCR test usage - ensemble-wise}
# predictions is positive class probability: 1 = synergy, 0 not (so we have to convert accordingly the ensemble-wise data)
pred = prediction(predictions = 1 - normalize_to_range(orig_res$score - 0.2 * rand_res$score), labels = observed)
perf = performance(prediction.obj = pred, measure = "tpr", x.measure = "fpr") # ROC
plot(perf, main = "ROC (ensemble-wise), best beta")
auc_res = performance(prediction.obj = pred, measure = "auc")
auc_value = unlist(auc_res@y.values)
auc_value
```

```{r ROCR test usage - model-wise}
w = 0.2
pred_modelwise = pred_modelwise %>% mutate(weighted_prob = (1 - w) * pred_modelwise$synergy_prob_ss + w * pred_modelwise$synergy_prob_rand)

pred = prediction(predictions = pred_modelwise %>% pull(weighted_prob), labels = observed)
perf = performance(prediction.obj = pred, measure = "tpr", x.measure = "fpr") # ROC
plot(perf, main = "ROC (model-wise), best beta")

auc_res = performance(prediction.obj = pred, measure = "auc")
auc_value = unlist(auc_res@y.values)
auc_value
```

## Bliss Drabme assesement

```{r Bliss Cascade 2.0}
synergies_file_modelwise = "/home/john/tmp/ags_paper_res/bliss/cascade_2.0_ss_150sim_fixpoints_20200419_031423/cascade_2.0_ss_150sim_fixpoints_modelwise_synergies.tab"
synergies_file_modelwise = "/home/john/tmp/ags_paper_res/bliss/cascade_2.0_ss_200sim_fixpoints_20200419_053742/cascade_2.0_ss_200sim_fixpoints_modelwise_synergies.tab"
synergies_file_ensemblewise = "/home/john/tmp/ags_paper_res/bliss/cascade_2.0_ss_100sim_fixpoints_20200419_014102/cascade_2.0_ss_100sim_fixpoints_ensemblewise_synergies.tab"

a = emba::get_synergy_scores(file_name = synergies_file_modelwise, file_type = "modelwise")
a = a %>% mutate(`synergy_prob_ss` = synergies/(synergies + `non-synergies`)) # add synergy probability

b = emba::get_synergy_scores(file_name = synergies_file_ensemblewise, file_type = "ensemblewise")
b = bind_cols(b, as_tibble_col(observed, column_name = "observed"))

pred = prediction(predictions = a %>% pull(synergy_prob_ss), labels = observed)
#pred = prediction(predictions = 1 - normalize_to_range(b %>% pull(score)), labels = observed)
perf = performance(prediction.obj = pred, measure = "tpr", x.measure = "fpr") # ROC
plot(perf, main = "ROC modelwise-wise")

auc_res = performance(prediction.obj = pred, measure = "auc")
auc_value = unlist(auc_res@y.values)
auc_value

a = a %>% mutate(synergy_prob_reversed = 1 - synergy_prob_ss)
a = bind_cols(a, as_tibble_col(observed, column_name = "observed"))
res = get_roc_stats(df = a, pred_col = "synergy_prob_reversed", obs_col = "observed")
res$AUC

pROC::roc(observed ~ score, b, direction = ">", smooth = TRUE)
roc1 = roc(observed ~ synergy_prob_ss, a, direction = "<", ci = TRUE, plot = TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE, print.auc=TRUE, print.thres = TRUE, max.plot = TRUE, min.plot = TRUE, rand.plot = TRUE)
```



## ROC analytics for purely random models {-}

```{r ROC stats for purely random models}
random_file_new = paste0(res_dir, "cascade_2.0_random_ensemblewise_synergies.tab")
rand_res_new = emba::get_synergy_scores(random_file_new)

# original + beta * random
betas = seq(from = -5, to = 5, by = 0.05)

auc_values = sapply(betas, function(beta) {
  value = orig_res$score + (beta * rand_res_new$score)
  pred = prediction(predictions = 1 - normalize_to_range(value), labels = observed)
  auc_res = performance(prediction.obj = pred, measure = "auc")
  auc_value = unlist(auc_res@y.values)
})

df = as_tibble(cbind(betas, auc_values))

# ggline(data = df, x = "betas", y = "auc_values", numeric.x.axis = TRUE,
#   title = "AUC sensitivity to beta normalization parameter", xlab = "Beta parameter", ylab = "AUC value",
#   color = RColorBrewer::brewer.pal(3, "Set1")[2])

plot_ly(data = df, x = ~betas, y = ~auc_values, width = 800,
  type = "scatter", mode = "lines+markers", colors = "Set1") %>%
  layout(title = list(text = "AUC sensitivity to beta normalization parameter", font = my.title.font),
    xaxis = list(title = "Beta parameter"),
    yaxis = list(title = "Area Under ROC curve")) %>%
  config(displayModeBar = FALSE)
```

## Fitness vs performance {-}

The idea here is to generate many training data files from the steady state as used in the simulations above for the AGS, where some of the nodes will have their states *flipped* to the opposite state ($0$ to $1$ and vice versa).
That way, we can train models to different steady states, ranging from ones that differ to just a few nodes states up to a steady state that is the complete *reversed* version of the one used in the simulations above.

Using the `gen_training_data.R` script, we first choose a few number of flips ($11$ flips) ranging from $1$ to $24$ (all nodes) in the steady state.
Then, for each such *flipping-nodes* value, we generated $20$ new steady states with a randomly chosen set of nodes whose value is going to flip.
Thus, in total, $205$ training data files were produced ($205 = 9 \times 20 + 24 + 1$, where from the $11$ number of flips, the one flip happens for every node and flipping all the nodes simultaneously happens once).

Running the script `run_druglogics_synergy_training.sh` from the `druglogics-synergy` repository root, we get the simulation results for each of these training data files.
The only difference in the cascade 2.0 configuration file was the number of simulations ($15$) for each training data file and the attractor tool used (`biolqm_stable_states`).

We now load the data from these simulations:


# R session info {-}

```{r session info, comment=""}
xfun::session_info()
```

# References {-}

[["index.html", "AGS paper - Supplementary Information (SI) Intro Methodology/Input Overview Summary", " AGS paper - Supplementary Information (SI) John Zobolas Last updated: 26 October, 2020 Intro This report is the supplementary material for the AGS I Paper and has all the simulation results and investigations related to that paper, as well as instructions for reproducing the results. Methodology/Input Overview A list of things that change between the simulations and the presented figures are: The number of Gitsbe simulations: more simulations, more models generated. The type of mutation that Gitsbe models have: unless otherwise specified, the Gitsbe models have only link operator mutations. Topology mutations were also tested as well as a combination of topology and link operator mutations. The training data for the Gitsbe models: steady state (calibrated models) vs proliferative profile (random models). The type of mathematical model (HSA or Bliss) used in Drabme to evaluate the synergies either from the (Flobak et al. 2015) for the CASCADE 1.0 analysis or from the (Flobak et al. 2019) dataset for the CASCADE 2.0 analysis. More info on the calculations that Drabme does see here. The type of output used from Drabme: ensemble-wise or model-wise synergy results. Summary Observing the results across the whole report, we reach the following conclusions: To minimize the expected performance variance, executing \\(150\\) Gitsbe simulations is a good choice (no need for more, no matter the other input parameters). Ensemble-wise results do not correlate with model-wise results (see correlation results for CASCADE 1.0 and CASCADE 2.0). This happens because some drug perturbed models do not have stable states and thus cannot be evaluated for synergy.1 Model-wise ROC results are always better compared to ensemble-wise ROC results for the single predictor models (e.g. the calibrated non-normalized model results). When using a combined model predictor (see here) to augment/correct the calibrated models results, Drabme’s Bliss synergy assessment always brings significant performance benefit for the ensemble-wise results. When using HSA, that is not always the case (see one example and another). The model-wise results do not bring any performance benefit when used in a combined predictor. The value of \\(\\beta = -1\\) is a good estimation for the value that maximizes the combined predictor’s performance (\\(calibrated + \\beta \\times random\\)) across all of the report’s relevant investigations. Comparing the different parameterization schemes for the CASCADE 2.0 analysis (using the combined predictors with \\(\\beta = -1\\)), we observe that topology mutations outperform link operator mutations. There is correlation between fitness to the AGS steady state and normalized ensemble prediction performance. This is observed for the link operator mutated models here and a little bit more for the topology mutated ones. Using minimal trapspaces, where there is almost always an attractor found and the global output of the model can be calculated, we observed higher correlation between ensemble-wise and model-wise results (as expected)↩︎ "],["r-libraries.html", "R Libraries", " R Libraries For the ROC curves we used the function get_roc_stats() from the usefun R package (Zobolas 2020b) and for the PR curves the pr.curve() from the PRROC package (Grau, Grosse, and Keilwagen 2015). Several functions from the emba R package (Zobolas, Kuiper, and Flobak 2020) are also used to load the simulation results. The AUC sensitivity analysis (for a description see here) was inspired by work from (Pepe 2000). The heatmaps are generated with the ComplexHeatmap R package (Gu, Eils, and Schlesner 2016). The report template is from the rtemps R package (Zobolas 2020a). Loading libraries that are used in this report: library(DT) library(ggpubr) library(RColorBrewer) library(xfun) library(dplyr) library(tidyr) library(tibble) library(emba) library(usefun) library(readr) library(stringr) library(latex2exp) library(corrplot) library(PRROC) library(equatiomatic) library(glmnet) library(knitr) library(MAMSE) library(circlize) library(ComplexHeatmap) library(rstatix) "],["cascade-1-0-analysis.html", "CASCADE 1.0 Analysis HSA results Bliss results Best ROC and PRC Correlation Fitness Evolution Scrambled Topologies Investigation", " CASCADE 1.0 Analysis Performance of automatically parameterized models against published data in (Flobak et al. 2015) HSA results HSA refers to the synergy method used in Drabme to assess the synergies from the gitsbe models We test performance using ROC and PR AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state (\\(50\\) simulations) Random models: fitted to proliferation profile (\\(50\\) simulations) Gitsbe models have mutations on link operator only Load results: # &#39;ss&#39; =&gt; calibrated models, &#39;prolif&#39; =&gt; proliferative random models # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; model-wise ## HSA results ss_hsa_ew_file = paste0(&quot;results/link-only/cascade_1.0_ss_50sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) ss_hsa_mw_file = paste0(&quot;results/link-only/cascade_1.0_ss_50sim_fixpoints_hsa_modelwise_synergies.tab&quot;) prolif_hsa_ew_file = paste0(&quot;results/link-only/cascade_1.0_rand_50sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) prolif_hsa_mw_file = paste0(&quot;results/link-only/cascade_1.0_rand_50sim_fixpoints_hsa_modelwise_synergies.tab&quot;) ss_hsa_ensemblewise_synergies = emba::get_synergy_scores(ss_hsa_ew_file) ss_hsa_modelwise_synergies = emba::get_synergy_scores(ss_hsa_mw_file, file_type = &quot;modelwise&quot;) prolif_hsa_ensemblewise_synergies = emba::get_synergy_scores(prolif_hsa_ew_file) prolif_hsa_modelwise_synergies = emba::get_synergy_scores(prolif_hsa_mw_file, file_type = &quot;modelwise&quot;) # calculate probability of synergy in the modelwise results ss_hsa_modelwise_synergies = ss_hsa_modelwise_synergies %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) prolif_hsa_modelwise_synergies = prolif_hsa_modelwise_synergies %&gt;% mutate(synergy_prob_prolif = synergies/(synergies + `non-synergies`)) observed_synergies_file = paste0(&quot;results/observed_synergies_cascade_1.0&quot;) observed_synergies = get_observed_synergies(observed_synergies_file) # 1 (positive/observed synergy) or 0 (negative/not observed) for all tested drug combinations observed = sapply(prolif_hsa_modelwise_synergies$perturbation %in% observed_synergies, as.integer) # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; model-wise pred_ew_hsa = bind_cols(ss_hsa_ensemblewise_synergies %&gt;% rename(ss_score = score), prolif_hsa_ensemblewise_synergies %&gt;% select(score) %&gt;% rename(prolif_score = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_mw_hsa = bind_cols( ss_hsa_modelwise_synergies %&gt;% select(perturbation, synergy_prob_ss), prolif_hsa_modelwise_synergies %&gt;% select(synergy_prob_prolif), as_tibble_col(observed, column_name = &quot;observed&quot;)) ROC curves res_ss_ew = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;ss_score&quot;, label_col = &quot;observed&quot;) res_prolif_ew = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;prolif_score&quot;, label_col = &quot;observed&quot;) res_ss_mw = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_ss&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_prolif_mw = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_prolif&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs my_palette = RColorBrewer::brewer.pal(n = 9, name = &quot;Set1&quot;) plot(x = res_ss_ew$roc_stats$FPR, y = res_ss_ew$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_prolif_ew$roc_stats$FPR, y = res_prolif_ew$roc_stats$TPR, lwd = 3, col = my_palette[2]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, legend = c(paste(round(res_ss_ew$AUC, digits = 3), &quot;Calibrated&quot;), paste(round(res_prolif_ew$AUC, digits = 3), &quot;Random&quot;)), cex = 1.3) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) plot(x = res_ss_mw$roc_stats$FPR, y = res_ss_mw$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_prolif_mw$roc_stats$FPR, y = res_prolif_mw$roc_stats$TPR, lwd = 3, col = my_palette[2]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:3], pch = 19, legend = c(paste(round(res_ss_mw$AUC, digits = 3), &quot;Calibrated&quot;), paste(round(res_prolif_mw$AUC, digits = 3), &quot;Random&quot;)), cex = 1.3) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) Figure 1: ROC curves (CASCADE 1.0, HSA synergy method) PR curves pr_ss_ew_hsa = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(ss_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_prolif_ew_hsa = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(prolif_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_ss_mw_hsa = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(synergy_prob_ss), weights.class0 = pred_mw_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_prolif_mw_hsa = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(synergy_prob_prolif), weights.class0 = pred_mw_hsa %&gt;% pull(observed), curve = TRUE) plot(pr_ss_ew_hsa, main = &#39;PR curve, Ensemble-wise synergies (HSA)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_prolif_ew_hsa, add = TRUE, color = my_palette[2]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, legend = c(paste(round(pr_ss_ew_hsa$auc.davis.goadrich, digits = 3), &quot;Calibrated&quot;), paste(round(pr_prolif_ew_hsa$auc.davis.goadrich, digits = 3), &quot;Random&quot;))) grid(lwd = 0.5) plot(pr_ss_mw_hsa, main = &#39;PR curve, Model-wise synergies (HSA)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_prolif_mw_hsa, add = TRUE, color = my_palette[2]) legend(&#39;left&#39;, title = &#39;AUC&#39;, col = my_palette[1:3], pch = 19, legend = c(paste(round(pr_ss_mw_hsa$auc.davis.goadrich, digits = 3), &quot;Calibrated&quot;), paste(round(pr_prolif_mw_hsa$auc.davis.goadrich, digits = 3), &quot;Random&quot;))) grid(lwd = 0.5) Figure 2: PR curves (CASCADE 1.0, HSA synergy method) Calibrated models perform a lot better than the random ones AUC sensitivity Investigate combining the synergy results of calibrated and proliferative (random) models Quantify the amount of information from the proliferative (random) models that can be used to augment the calibrated results? Ensemble-wise scenario: \\(score = calibrated + \\beta \\times random\\) \\(\\beta \\rightarrow +\\infty\\): mostly proliferative (random) model predictions \\(\\beta \\rightarrow -\\infty\\): mostly reverse proliferative (random) model predictions \\(\\beta \\simeq -1\\): calibrated models are normalized against proliferative (random) model predictions. Model-wise scenario: \\((1-w) \\times prob_{cal} + w \\times prob_{rand}, w \\in[0,1]\\) \\(w=0\\): only calibrated model predictions \\(w=1\\): only proliferative (random) model predictions # Ensemble-wise betas = seq(from = -12, to = 12, by = 0.1) prolif_roc = sapply(betas, function(beta) { pred_ew_hsa = pred_ew_hsa %&gt;% mutate(combined_score = ss_score + beta * prolif_score) res = roc.curve(scores.class0 = pred_ew_hsa %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr = sapply(betas, function(beta) { pred_ew_hsa = pred_ew_hsa %&gt;% mutate(combined_score = ss_score + beta * prolif_score) res = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_ew = as_tibble(cbind(betas, prolif_roc, prolif_pr)) df_ew = df_ew %&gt;% tidyr::pivot_longer(-betas, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter (HSA, CASCADE 1.0)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + geom_vline(xintercept = 0) + geom_vline(xintercept = -1, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_text(aes(x=-2, label=&quot;β = -1&quot;, y=0.25), colour=&quot;black&quot;, angle=90) + grids() Figure 3: AUC sensitivity (CASCADE 1.0, HSA synergy method, Ensemble-wise results) # Model-wise weights = seq(from = 0, to = 1, by = 0.05) prolif_roc_mw = sapply(weights, function(w) { pred_mw_hsa = pred_mw_hsa %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_hsa$synergy_prob_ss + w * pred_mw_hsa$synergy_prob_prolif) res = roc.curve(scores.class0 = pred_mw_hsa %&gt;% pull(weighted_prob), weights.class0 = pred_mw_hsa %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr_mw = sapply(weights, function(w) { pred_mw_hsa = pred_mw_hsa %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_hsa$synergy_prob_ss + w * pred_mw_hsa$synergy_prob_prolif) res = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(weighted_prob), weights.class0 = pred_mw_hsa %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_mw = as_tibble(cbind(weights, prolif_roc_mw, prolif_pr_mw)) df_mw = df_mw %&gt;% tidyr::pivot_longer(-weights, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_mw, x = &quot;weights&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;weight $w$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title.position = &quot;center&quot;, title = TeX(&quot;AUC sensitivity to weighted average score (HSA, CASCADE 1.0)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + grids() Figure 4: AUC sensitivity (CASCADE 1.0, HSA synergy method, Model-wise results) There are \\(\\beta\\) values that can boost the predictive performance of the calibrated models (ensemble-wise) but no \\(w\\) weight in the model-wise case. \\(\\beta=-1\\) seems to be a common value that maximizes both the ROC-AUC and the PR-AUC. The PR-AUC is more sensitive than the ROC-AUC, so a better indicator of performance. Bliss results Bliss refers to the synergy method used in Drabme to assess the synergies from the gitsbe models We test performance using ROC and PR AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state (\\(50\\) simulations) Random models: fitted to proliferation profile (\\(50\\) simulations) Gitsbe models have mutations on link operator only Load results: # &#39;ss&#39; =&gt; calibrated models, &#39;prolif&#39; =&gt; random models ## Bliss results ss_bliss_ensemblewise_file = paste0(&quot;results/link-only/cascade_1.0_ss_50sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_file = paste0(&quot;results/link-only/cascade_1.0_ss_50sim_fixpoints_bliss_modelwise_synergies.tab&quot;) prolif_bliss_ensemblewise_file = paste0(&quot;results/link-only/cascade_1.0_rand_50sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) prolif_bliss_modelwise_file = paste0(&quot;results/link-only/cascade_1.0_rand_50sim_fixpoints_bliss_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_synergies = emba::get_synergy_scores(ss_bliss_ensemblewise_file) ss_bliss_modelwise_synergies = emba::get_synergy_scores(ss_bliss_modelwise_file, file_type = &quot;modelwise&quot;) prolif_bliss_ensemblewise_synergies = emba::get_synergy_scores(prolif_bliss_ensemblewise_file) prolif_bliss_modelwise_synergies = emba::get_synergy_scores(prolif_bliss_modelwise_file, file_type = &quot;modelwise&quot;) # calculate probability of synergy in the modelwise results ss_bliss_modelwise_synergies = ss_bliss_modelwise_synergies %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) prolif_bliss_modelwise_synergies = prolif_bliss_modelwise_synergies %&gt;% mutate(synergy_prob_prolif = synergies/(synergies + `non-synergies`)) # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; model-wise pred_ew_bliss = bind_cols(ss_bliss_ensemblewise_synergies %&gt;% rename(ss_score = score), prolif_bliss_ensemblewise_synergies %&gt;% select(score) %&gt;% rename(prolif_score = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_mw_bliss = bind_cols( ss_bliss_modelwise_synergies %&gt;% select(perturbation, synergy_prob_ss), prolif_bliss_modelwise_synergies %&gt;% select(synergy_prob_prolif), as_tibble_col(observed, column_name = &quot;observed&quot;)) ROC curves res_ss_ew = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score&quot;, label_col = &quot;observed&quot;) res_prolif_ew = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;prolif_score&quot;, label_col = &quot;observed&quot;) res_ss_mw = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_prolif_mw = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_prolif&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs plot(x = res_ss_ew$roc_stats$FPR, y = res_ss_ew$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_prolif_ew$roc_stats$FPR, y = res_prolif_ew$roc_stats$TPR, lwd = 3, col = my_palette[2]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, legend = c(paste(round(res_ss_ew$AUC, digits = 3), &quot;Calibrated&quot;), paste(round(res_prolif_ew$AUC, digits = 3), &quot;Random&quot;)), cex = 1.3) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) plot(x = res_ss_mw$roc_stats$FPR, y = res_ss_mw$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_prolif_mw$roc_stats$FPR, y = res_prolif_mw$roc_stats$TPR, lwd = 3, col = my_palette[2]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, legend = c(paste(round(res_ss_mw$AUC, digits = 3), &quot;Calibrated&quot;), paste(round(res_prolif_mw$AUC, digits = 3), &quot;Random&quot;)), cex = 1.3) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) Figure 5: ROC curves (CASCADE 1.0, Bliss synergy method) The ROC statistics data for the calibrated models are as follows: DT::datatable(data = res_ss_ew$roc_stats, options = list(pageLength = 5, lengthMenu = c(5, 10, 16), searching = FALSE)) %&gt;% formatRound(c(1,6,7,8,9), digits = 3) Figure 6: ROC data for Calibrated Models (CASCADE 1.0, Bliss synergy method) # investigate the average threshold as a synergy classification index # thres = res_ss_ew$roc_stats %&gt;% pull(threshold) # thres = thres[is.finite(thres)] # remove Inf&#39;s # res_ss_ew$roc_stats %&gt;% # filter(threshold &lt; mean(thres)) %&gt;% # slice(n()) %&gt;% kable() PR curves pr_ss_ew_bliss = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(ss_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_prolif_ew_bliss = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(prolif_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_ss_mw_bliss = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(synergy_prob_ss), weights.class0 = pred_mw_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_prolif_mw_bliss = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(synergy_prob_prolif), weights.class0 = pred_mw_bliss %&gt;% pull(observed), curve = TRUE) plot(pr_ss_ew_bliss, main = &#39;PR curve, Ensemble-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_prolif_ew_bliss, add = TRUE, color = my_palette[2]) legend(x = 0, y = 0.9, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, cex = 1.3, legend = c(paste(round(pr_ss_ew_bliss$auc.davis.goadrich, digits = 3), &quot;Calibrated&quot;), paste(round(pr_prolif_ew_bliss$auc.davis.goadrich, digits = 3), &quot;Random&quot;))) grid(lwd = 0.5) plot(pr_ss_mw_bliss, main = &#39;PR curve, Model-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_prolif_mw_bliss, add = TRUE, color = my_palette[2]) legend(x = 0, y = 0.9, title = &#39;AUC&#39;, col = my_palette[1:3], pch = 19, cex = 1.3, legend = c(paste(round(pr_ss_mw_bliss$auc.davis.goadrich, digits = 3), &quot;Calibrated&quot;), paste(round(pr_prolif_mw_bliss$auc.davis.goadrich, digits = 3), &quot;Random&quot;))) grid(lwd = 0.5) Figure 7: PR curves (CASCADE 1.0, Bliss synergy method) Calibrated models perform a lot better than the random ones AUC sensitivity Investigate same thing as described in here. # Ensemble-wise betas = seq(from = -12, to = 12, by = 0.1) prolif_roc = sapply(betas, function(beta) { pred_ew_bliss = pred_ew_bliss %&gt;% mutate(combined_score = ss_score + beta * prolif_score) res = roc.curve(scores.class0 = pred_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr = sapply(betas, function(beta) { pred_ew_bliss = pred_ew_bliss %&gt;% mutate(combined_score = ss_score + beta * prolif_score) res = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_ew = as_tibble(cbind(betas, prolif_roc, prolif_pr)) df_ew = df_ew %&gt;% tidyr::pivot_longer(-betas, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter (Bliss, CASCADE 1.0)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + geom_vline(xintercept = 0) + geom_vline(xintercept = -1, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_text(aes(x=-2, label=&quot;β = -1&quot;, y=0.25), colour=&quot;black&quot;, angle=90) + grids() Figure 8: AUC sensitivity (CASCADE 1.0, Bliss synergy method, Ensemble-wise results) # Model-wise weights = seq(from = 0, to = 1, by = 0.05) prolif_roc_mw = sapply(weights, function(w) { pred_mw_bliss = pred_mw_bliss %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_bliss$synergy_prob_ss + w * pred_mw_bliss$synergy_prob_prolif) res = roc.curve(scores.class0 = pred_mw_bliss %&gt;% pull(weighted_prob), weights.class0 = pred_mw_bliss %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr_mw = sapply(weights, function(w) { pred_mw_bliss = pred_mw_bliss %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_bliss$synergy_prob_ss + w * pred_mw_bliss$synergy_prob_prolif) res = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(weighted_prob), weights.class0 = pred_mw_bliss %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_mw = as_tibble(cbind(weights, prolif_roc_mw, prolif_pr_mw)) df_mw = df_mw %&gt;% tidyr::pivot_longer(-weights, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_mw, x = &quot;weights&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;weight $w$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title.position = &quot;center&quot;, title = TeX(&quot;AUC sensitivity to weighted average score (Bliss, CASCADE 1.0)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + grids() Figure 9: AUC sensitivity (CASCADE 1.0, Bliss synergy method, Model-wise results) There are \\(\\beta\\) values that can boost the predictive performance of the calibrated models (ensemble-wise) but no \\(w\\) weight in the model-wise case. The PR-AUC is more sensitive than the ROC-AUC, so a better indicator of performance. A value very close to \\(\\beta=-1\\) seems to be the one maximizes both the ROC-AUC and the PR-AUC. The ROC ensemble-wise statistics data for the combined predictor \\(calibrated + \\beta \\times random, \\beta=-1\\) are: beta = -1 pred_ew_bliss = pred_ew_bliss %&gt;% mutate(combined_score = ss_score + beta * prolif_score) res_comb_pred = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;combined_score&quot;, label_col = &quot;observed&quot;) DT::datatable(data = res_comb_pred$roc_stats, options = list(pageLength = 5, lengthMenu = c(5, 10, 16), searching = FALSE)) %&gt;% formatRound(c(1,6,7,8,9), digits = 3) Figure 10: ROC data for Combined Predictor (CASCADE 1.0, Bliss synergy method) # All observed synergies are in top 6 # pred_ew_bliss %&gt;% arrange(combined_score) Best ROC and PRC Only for the next plot, Calibrated stands for the combined predictor results, i.e. \\(calibrated + \\beta \\times random, \\beta=-1\\). plot(x = res_comb_pred$roc_stats$FPR, y = res_comb_pred$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_prolif_ew$roc_stats$FPR, y = res_prolif_ew$roc_stats$TPR, lwd = 3, col = my_palette[2]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, legend = c(paste(round(res_comb_pred$AUC, digits = 3), &quot;Calibrated&quot;), paste(round(res_prolif_ew$AUC, digits = 3), &quot;Random&quot;)), cex = 1.3) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) res_comb_pred_pr = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) plot(res_comb_pred_pr, main = &#39;PR curve, Ensemble-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_prolif_ew_bliss, add = TRUE, color = my_palette[2]) legend(x = 0, y = 0.9, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, cex = 1.3, legend = c(paste(round(res_comb_pred_pr$auc.davis.goadrich, digits = 3), &quot;Calibrated&quot;), paste(round(pr_prolif_ew_bliss$auc.davis.goadrich, digits = 3), &quot;Random&quot;))) grid(lwd = 0.5) Figure 11: ROC and PR curves for Random and Best Combined Predictor (CASCADE 1.0, Bliss synergy method) Correlation We test for correlation between all the synergy predictor results shown in the previous curves. This means ensemble-wise vs model-wise, random proliferative models vs calibrated models and HSA vs Bliss synergy assessment. P-values are represented at 3 significant levels: \\(0.05, 0.01, 0.001\\) (*, **, ***) and the correlation coefficient is calculated using Kendall’s tau statistic. synergy_scores = bind_cols( pred_ew_hsa %&gt;% select(ss_score, prolif_score) %&gt;% rename(cal_ew_hsa = ss_score, random_ew_hsa = prolif_score), pred_ew_bliss %&gt;% select(ss_score, prolif_score) %&gt;% rename(cal_ew_bliss = ss_score, random_ew_bliss = prolif_score), pred_mw_hsa %&gt;% select(synergy_prob_ss, synergy_prob_prolif) %&gt;% rename(cal_mw_hsa = synergy_prob_ss, random_mw_hsa = synergy_prob_prolif), pred_mw_bliss %&gt;% select(synergy_prob_ss, synergy_prob_prolif) %&gt;% rename(cal_mw_bliss = synergy_prob_ss, random_mw_bliss = synergy_prob_prolif) ) M = cor(synergy_scores, method = &quot;kendall&quot;) res = cor.mtest(synergy_scores, method = &quot;kendall&quot;) corrplot(corr = M, type = &quot;upper&quot;, p.mat = res$p, sig.level = c(.001, .01, .05), pch.cex = 1, pch.col = &quot;white&quot;, insig = &quot;label_sig&quot;, tl.col = &quot;black&quot;, tl.srt = 45) Figure 12: Correlation Plot for CASCADE 1.0 Results Model-wise don’t correlate a lot with ensemble-wise results (topright part of the correlation plot). HSA and Bliss results correlate, higher for the model-wise (bottomright) than the ensemble-wise results (topleft). Calibrated results also show some correlation with the random results Fitness Evolution We did a test run of Gitsbe with \\(1000\\) simulations, fitting to steady state (generating thus calibrated models). The only difference between the following results and the ones above is the total number of simulations specified in the configuration and that the option bootstrap_mutations_factor was set to \\(1\\) (to avoid reaching good fitness models in the earlier generations). Firstly, we show the fitness evolution of the first \\(20\\) simulations. Each data point is the average fitness in that generation out of \\(20\\) models. Note that some simulations end because the target fitness is reached by some of the models (\\(0.99\\)). read_summary_file = function(file_name) { lines = readr::read_lines(file = file_name, skip = 5, skip_empty_rows = TRUE) data_list = list() index = 1 gen_fit_list = list() gen_index = 1 for (line_index in 1:length(lines)) { line = lines[line_index] if (stringr::str_detect(string = line, pattern = &quot;Simulation&quot;)) { data_list[[index]] = dplyr::bind_cols(gen_fit_list) index = index + 1 gen_fit_list = list() gen_index = 1 } else { # read fitness values gen_fit_list[[gen_index]] = tibble::as_tibble_col(as.numeric(unlist(strsplit(line, split = &#39;\\t&#39;))), column_name = paste0(gen_index)) gen_index = gen_index + 1 } } # add the last simulation&#39;s values data_list[[index]] = dplyr::bind_cols(gen_fit_list) return(data_list) } fitness_summary_file = &quot;results/link-only/cascade_1.0_ss_1000sim_fixpoints_hsa_summary.txt&quot; # `fit_res` is a list of tibbles # Each tibble has the fitness results of a simulation # Rows represent the models and columns are the generations fit_res = read_summary_file(file_name = fitness_summary_file) first_sim_data = colMeans(fit_res[[1]]) plot(1:length(first_sim_data), y = first_sim_data, ylim = c(0,1), xlim = c(0,20), type = &#39;l&#39;, lwd = 1.5, main = &#39;Fitness Evolution across Generations&#39;, xlab = &#39;Generations&#39;, ylab = &#39;Average Fitness&#39;, col = usefun:::colors.100[1]) index = 2 for (fit_data in fit_res) { if (index &gt; 20) break #if (ncol(fit_data) != 20) next mean_fit_per_gen = colMeans(fit_data) lines(x = 1:length(mean_fit_per_gen), y = mean_fit_per_gen, lwd = 1.5, col = usefun:::colors.100[index]) index = index + 1 } grid(lwd = 0.5) Figure 13: Fitness Evolution (20 simulations, CASCADE 1.0) Next, we plot the average fitness + standard deviation per generation across all \\(1000\\) simulations: # `avg_fit` is a tibble with rows the number of simulations and # columns the generations. Each value in a (sim,gen) cell is the average # fitness of models in that particular (sim,gen) combination avg_fit = do.call(dplyr::bind_rows, sapply(fit_res, colMeans)) avg_fit_long = avg_fit %&gt;% pivot_longer(cols = everything()) %&gt;% mutate(name = as.integer(name)) ggline(data = avg_fit_long, x = &quot;name&quot;, y = &quot;value&quot;, color = my_palette[2], add = &quot;mean_sd&quot;, add.params = list(color = &quot;black&quot;), ylim = c(0, 1), main = &quot;Fitness Evolution across Generations&quot;, xlab = &quot;Generations&quot;, ylab = &quot;Fitness&quot;) + theme(plot.title = element_text(hjust = 0.5)) + grids() Figure 14: Fitness Evolution (1000 simulations, CASCADE 1.0) # DIY way: # df = avg_fit_long %&gt;% group_by(name) %&gt;% # summarise(median = median(value, na.rm = TRUE), # mean = mean(value, na.rm = TRUE), # sd = sd(value, na.rm = TRUE)) # # ggplot(data = df, aes(x=name, y=mean)) + # ggtitle(&quot;Fitness Evolution across Generations&quot;) + # xlab(&quot;Generations&quot;) + ylab(&quot;Fitness&quot;) + # geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2) + # geom_line(color=&#39;steelblue&#39;) + # geom_point(color=&#39;steelblue&#39;) + # theme_pubr() + theme(plot.title = element_text(hjust = 0.5)) + # grids() The average fitness stabilizes after \\(\\approx 10-15\\) generations but also the standard deviation: new models are still being created through the crossover genetic algorithm phase to explore various model parameterization while keeping the fitness score relatively high. The S-shaped (sigmoid) curve is in agreement with Holland’s schema theorem (Holland 1992). Scrambled Topologies Investigation We create several scrambled topologies from the CASCADE 1.0 one, in order to assess the tolerance of the curated network topology to random edge changes with regards to model ensemble performance. We introduce \\(4\\) types of topology scrambling that are performed in a varying number of edges. The more edges are changed, the more scrambled/randomized is the resulting topology. The \\(4\\) types of scrambling are: Randomly permutating the source nodes of the edges (source) Randomly permutating the target nodes of the edges (target) Changing the effect from inhibition to activation and vice-versa (effect) Combining all the above (all) For each type of scrambling we make \\(10\\) random topologies for each expected similarity score between the randomized and the curated topology, ranging from \\(0\\) similarity to \\(0.98\\) with a total of \\(22\\) steps, thus \\(10\\times22=220\\) random topologies per different type of scrambling. See more details on how to generate these topologies in the script gen_scrambled_topologies.R. To get the drug combination predictions for each scrambled topology, we executed the druglogics-synergy module with the default configuration (\\(50\\) simulations per topology, for both calibrated to steady state and random proliferative models, using the Bliss synergy assessment method in Drabme) - see more info on the run_druglogics_synergy_on_scrambled_topologies.sh script. We calculate the normalized predictor performance (\\(calibrated -random\\)) for each topology-specific simulation and tidy up the result data in get_syn_res_scrambled_topo.R. Next, we load the data results and add the ROC and PR AUC results of the combined predictor (termed Calibrated) for the curated CASCADE 1.0 topology (see above). Note that the topology scrambling type is set to none for the results that used the original/curated CASCADE 1.0 topology. scrambled_topo_res = readRDS(file = &#39;results/scrambled_topo_res.rds&#39;) # the un-scrambled topology results have a similarity score equal to 1, &#39;none&#39; # scrambling whatsoever as `scramble_type`, and the ROC and PR AUC values have been previously # calculated and shown in the figures above but we re-do them here anyway :) res_comb_roc = PRROC::roc.curve(scores.class0 = pred_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed)) res_comb_pr = PRROC::pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed)) scrambled_topo_res = dplyr::bind_rows(scrambled_topo_res, tibble::tibble(sim = 1, scramble_type = &#39;none&#39;, roc_auc = res_comb_roc$auc, pr_auc = res_comb_pr$auc.davis.goadrich)) Interestingly, there were some scrambled topologies which didn’t produce not even \\(1\\) boolean model with a stable state when using the genetic algorithm of Gitsbe (so no predictions could be made for these topologies): ordered_types = c(&#39;none&#39;, &#39;source&#39;, &#39;target&#39;, &#39;effect&#39;, &#39;all&#39;) scrambled_topo_res %&gt;% group_by(scramble_type) %&gt;% summarise(percent = sum(is.na(roc_auc))/n(), .groups = &#39;drop&#39;) %&gt;% mutate(scramble_type = factor(scramble_type, levels = ordered_types)) %&gt;% ggplot(aes(x = scramble_type, y = percent, fill = scramble_type)) + geom_col() + geom_text(aes(label = scales::percent(percent, accuracy = 1)), vjust = -0.5, size = 8) + scale_y_continuous(labels = scales::percent, limits = c(0,1)) + scale_fill_brewer(palette = &quot;Set1&quot;) + guides(fill = guide_legend(title = latex2exp::TeX(&quot;Scramble Type&quot;))) + labs(x = &quot;&quot;, title = &quot;Topologies with zero-stable-state boolean models&quot;, y = &quot;&quot;) + theme_classic(base_size = 14) + theme(axis.text.x = element_text(size = 18)) Figure 15: Percentage of topologies that did not have any boolean model with a stable state after simulation with Gitsbe ended. Every possible topology scrambling type is represented. So tweaking the source nodes of each edge in the curated topology, resulted in \\(11\\%\\) of the produced topologies to have a network configuration that wouldn’t allow the existence of attractor stability in the explored link-operator parameterization space of the Gitsbe algorithm. Tweaking the target nodes results in less topologies having this property (\\(5\\%\\)). Lastly, tweaking the effect (activation vs inhibition), you always get some boolean models with a stable state attractor. Source Scrambling ggpubr::ggscatter(data = scrambled_topo_res %&gt;% filter(scramble_type == &#39;source&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)), x = &quot;sim&quot;, y = &quot;roc_auc&quot;, color = &quot;scramble_type&quot;, palette = c(&#39;red&#39;, &#39;black&#39;), xlab = &quot;Similarity Score&quot;, title = &quot;Source node Scrambling vs Performance (ROC)&quot;, ylab = &quot;ROC AUC&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, label.y.npc = &quot;top&quot;, size = 6, cor.coef.name = &quot;tau&quot;)) + ylim(c(0,1)) + geom_text(x = 0.95, y = 1, label = &quot;CASCADE 1.0&quot;) + theme(plot.title = element_text(hjust = 0.5), legend.position = &#39;none&#39;) ggpubr::ggscatter(data = scrambled_topo_res %&gt;% filter(scramble_type == &#39;source&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)), x = &quot;sim&quot;, y = &quot;pr_auc&quot;, color = &quot;scramble_type&quot;, palette = c(&#39;red&#39;, &#39;black&#39;), xlab = &quot;Similarity Score&quot;, title = &quot;Source node Scrambling vs Performance (Precision-Recall)&quot;, ylab = &quot;PR AUC&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, label.y.npc = &quot;top&quot;, size = 6, cor.coef.name = &quot;tau&quot;)) + ylim(c(0,1)) + geom_text(x = 0.9, y = 0.91, label = &quot;CASCADE 1.0&quot;) + theme(plot.title = element_text(hjust = 0.5), legend.position = &#39;none&#39;) Figure 16: Source node scrambling vs Performance (ROC and PR AUC) Target Scrambling ggpubr::ggscatter(data = scrambled_topo_res %&gt;% filter(scramble_type == &#39;target&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)), x = &quot;sim&quot;, y = &quot;roc_auc&quot;, color = &quot;scramble_type&quot;, palette = c(&#39;red&#39;, &#39;black&#39;), xlab = &quot;Similarity Score&quot;, title = &quot;Target node Scrambling vs Performance (ROC)&quot;, ylab = &quot;ROC AUC&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, label.y.npc = &quot;top&quot;, size = 6, cor.coef.name = &quot;tau&quot;)) + ylim(c(0,1)) + geom_text(x = 0.95, y = 1, label = &quot;CASCADE 1.0&quot;) + theme(plot.title = element_text(hjust = 0.5), legend.position = &#39;none&#39;) ggpubr::ggscatter(data = scrambled_topo_res %&gt;% filter(scramble_type == &#39;target&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)), x = &quot;sim&quot;, y = &quot;pr_auc&quot;, color = &quot;scramble_type&quot;, palette = c(&#39;red&#39;, &#39;black&#39;), xlab = &quot;Similarity Score&quot;, title = &quot;Target node Scrambling vs Performance (Precision-Recall)&quot;, ylab = &quot;PR AUC&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, label.y.npc = &quot;top&quot;, size = 6, cor.coef.name = &quot;tau&quot;)) + ylim(c(0,1)) + geom_text(x = 0.9, y = 0.91, label = &quot;CASCADE 1.0&quot;) + theme(plot.title = element_text(hjust = 0.5), legend.position = &#39;none&#39;) Figure 17: Target node scrambling vs Performance (ROC and PR AUC) Effect Scrambling ggpubr::ggscatter(data = scrambled_topo_res %&gt;% filter(scramble_type == &#39;effect&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)), x = &quot;sim&quot;, y = &quot;roc_auc&quot;, color = &quot;scramble_type&quot;, palette = c(&#39;black&#39;, &#39;red&#39;), xlab = &quot;Similarity Score&quot;, title = &quot;Source node Scrambling vs Performance (ROC)&quot;, ylab = &quot;ROC AUC&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, label.y.npc = &quot;top&quot;, size = 6, cor.coef.name = &quot;tau&quot;)) + ylim(c(0,1)) + geom_text(x = 0.9, y = 0.98, label = &quot;CASCADE 1.0&quot;) + theme(plot.title = element_text(hjust = 0.5), legend.position = &#39;none&#39;) ggpubr::ggscatter(data = scrambled_topo_res %&gt;% filter(scramble_type == &#39;effect&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)), x = &quot;sim&quot;, y = &quot;pr_auc&quot;, color = &quot;scramble_type&quot;, palette = c(&#39;black&#39;, &#39;red&#39;), xlab = &quot;Similarity Score&quot;, title = &quot;Source node Scrambling vs Performance (Precision-Recall)&quot;, ylab = &quot;PR AUC&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, label.y.npc = &quot;top&quot;, size = 6, cor.coef.name = &quot;tau&quot;)) + ylim(c(0,1)) + geom_text(x = 0.9, y = 0.91, label = &quot;CASCADE 1.0&quot;) + theme(plot.title = element_text(hjust = 0.5), legend.position = &#39;none&#39;) Figure 18: Effect scrambling vs Performance (ROC and PR AUC) Source, target and effect Scrambling ggpubr::ggscatter(data = scrambled_topo_res %&gt;% filter(scramble_type == &#39;all&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)), x = &quot;sim&quot;, y = &quot;roc_auc&quot;, color = &quot;scramble_type&quot;, palette = c(&#39;black&#39;, &#39;red&#39;), xlab = &quot;Similarity Score&quot;, title = &quot;Source, Target and Effect Scrambling vs Performance (ROC)&quot;, ylab = &quot;ROC AUC&quot;) + ylim(c(0,1)) + geom_text(x = 0.95, y = 1, label = &quot;CASCADE 1.0&quot;) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 0.85, y = 0.45, label = &quot;Random Predictions (AUC = 0.5)&quot;), color = &#39;#377EB8&#39;) + theme(plot.title = element_text(hjust = 0.5), legend.position = &#39;none&#39;) ggpubr::ggscatter(data = scrambled_topo_res %&gt;% filter(scramble_type == &#39;all&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)), x = &quot;sim&quot;, y = &quot;pr_auc&quot;, color = &quot;scramble_type&quot;, palette = c(&#39;black&#39;, &#39;red&#39;), xlab = &quot;Similarity Score&quot;, title = &quot;Source, Target and Effect Scrambling vs Performance (Precision-Recall)&quot;, ylab = &quot;PR AUC&quot;) + ylim(c(0,1)) + geom_text(x = 0.9, y = 0.91, label = &quot;CASCADE 1.0&quot;) + geom_hline(yintercept = sum(observed)/length(observed), linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 0.83, y = 0.08, label = &quot;Random Predictions (AUC = 0.2)&quot;), color = &#39;#377EB8&#39;) + theme(plot.title = element_text(hjust = 0.5), legend.position = &#39;none&#39;) Figure 19: Source, Target node and effect scrambling vs Performance (ROC and PR AUC) Bootstrap calibrated Models + Boxplots Since almost all scrambled results (no matter the type of scrambling) are worse than the results we got when using the curated/unscrambled CASCADE 1.0 topology, we proceed to further generate bootstrap model predictions derived from the curated topology to assess if the result we had found weren’t artifacts and/or outliers. We generate a large pool of gitsbe models (\\(1000\\)) and draw randomly batches of \\(50\\) models and assess ROC and PR AUC performance for each one of these normalized to the random model predictions (see above). All these bootstrapped models will be part of one category called Curated. The rest of the scrambled topology data (that we presented in scatter plots) will be split to \\(4\\) groups based on their similarity score (percentage of common edges with curated topology) and we will visualize the different groups with boxplots. TOADD =&gt; How to reproduce, scripts, etc. Load the bootstrap results and tidy up the data: # add the bootstrapped results of the curated topology to the scrambled results scrambled_topo_res = readRDS(file = &#39;results/scrambled_topo_res.rds&#39;) boot_cascade1_res = readRDS(file = &#39;results/boot_cascade1_res.rds&#39;) scrambled_topo_res = dplyr::bind_rows(scrambled_topo_res, boot_cascade1_res) # group by similarity score scrambled_topo_res = scrambled_topo_res %&gt;% mutate(grp = factor(x = case_when(sim &gt;= 0 &amp; sim &lt; 0.25 ~ &#39;0 - 0.25&#39;, sim &gt;= 0.25 &amp; sim &lt; 0.5 ~ &#39;0.25 - 0.5&#39;, sim &gt;= 0.5 &amp; sim &lt; 0.75 ~ &#39;0.5 - 0.75&#39;, sim &gt;= 0.75 &amp; sim &lt; 1 ~ &#39;0.75 - 1&#39;, sim == 1 ~ &#39;Curated&#39;), levels = c(&#39;0 - 0.25&#39;, &#39;0.25 - 0.5&#39;, &#39;0.5 - 0.75&#39;, &#39;0.75 - 1&#39;, &#39;Curated&#39;))) # ROC results scrambled_topo_res %&gt;% filter(scramble_type == &#39;source&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)) %&gt;% ggplot(aes(x = grp, y = roc_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 1.0 Topology&#39;, y = &#39;ROC AUC&#39;, title = &quot;Source Scrambling vs Performance (ROC)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 5, y = 0.45, label = &quot;Random (AUC = 0.5)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) # PR results scrambled_topo_res %&gt;% filter(scramble_type == &#39;source&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)) %&gt;% ggplot(aes(x = grp, y = pr_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 1.0 Topology&#39;, y = &#39;PR AUC&#39;, title = &quot;Source Scrambling vs Performance (Precision-Recall)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = sum(observed)/length(observed), linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 5, y = 0.15, label = &quot;Random (AUC = 0.2)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 20: Source scrambling + bootstrap CASCADE 1.0 model results vs Performance (ROC and PR AUC) # ROC results scrambled_topo_res %&gt;% filter(scramble_type == &#39;target&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)) %&gt;% ggplot(aes(x = grp, y = roc_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 1.0 Topology&#39;, y = &#39;ROC AUC&#39;, title = &quot;Target Scrambling vs Performance (ROC)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 5, y = 0.45, label = &quot;Random (AUC = 0.5)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) # PR results scrambled_topo_res %&gt;% filter(scramble_type == &#39;target&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)) %&gt;% ggplot(aes(x = grp, y = pr_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 1.0 Topology&#39;, y = &#39;PR AUC&#39;, title = &quot;Target Scrambling vs Performance (Precision-Recall)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = sum(observed)/length(observed), linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 5, y = 0.15, label = &quot;Random (AUC = 0.2)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 21: Target node scrambling + bootstrap CASCADE 1.0 model results vs Performance (ROC and PR AUC) # ROC results scrambled_topo_res %&gt;% filter(scramble_type == &#39;effect&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)) %&gt;% ggplot(aes(x = grp, y = roc_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 1.0 Topology&#39;, y = &#39;ROC AUC&#39;, title = &quot;Effect Scrambling vs Performance (ROC)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 5, y = 0.45, label = &quot;Random (AUC = 0.5)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) # PR results scrambled_topo_res %&gt;% filter(scramble_type == &#39;effect&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)) %&gt;% ggplot(aes(x = grp, y = pr_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 1.0 Topology&#39;, y = &#39;PR AUC&#39;, title = &quot;Effect Scrambling vs Performance (Precision-Recall)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = sum(observed)/length(observed), linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 5, y = 0.15, label = &quot;Random (AUC = 0.2)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 22: Effect scrambling + bootstrap CASCADE 1.0 model results vs Performance (ROC and PR AUC) # ROC results scrambled_topo_res %&gt;% filter(scramble_type == &#39;all&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)) %&gt;% ggplot(aes(x = grp, y = roc_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 1.0 Topology&#39;, y = &#39;ROC AUC&#39;, title = &quot;Target Scrambling vs Performance (ROC)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 5, y = 0.45, label = &quot;Random (AUC = 0.5)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) # PR results scrambled_topo_res %&gt;% filter(scramble_type == &#39;all&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)) %&gt;% ggplot(aes(x = grp, y = pr_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 1.0 Topology&#39;, y = &#39;PR AUC&#39;, title = &quot;Target Scrambling vs Performance (Precision-Recall)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = sum(observed)/length(observed), linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 5, y = 0.15, label = &quot;Random (AUC = 0.2)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 23: Source, Target node and effect scrambling + bootstrap CASCADE 1.0 model results vs Performance (ROC and PR AUC) Pretty much, scrambled results == random, curated always better! Try to put the all together??? "],["cascade-2-0-analysis-link-operator-mutations.html", "CASCADE 2.0 Analysis (Link Operator Mutations) HSA results Bliss results Best ROC and PRC Correlation Fitness Evolution Fitness vs Ensemble Performance Heatmaps: Stable State and Parameterization", " CASCADE 2.0 Analysis (Link Operator Mutations) Performance of automatically parameterized models against SINTEF dataset (Flobak et al. 2019) HSA results HSA refers to the synergy method used in Drabme to assess the synergies from the gitsbe models We test performance using ROC and PR AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state (\\(50,100,150,200\\) simulations) Random models: fitted to proliferation profile (\\(150\\) simulations) Gitsbe models have mutations on link operator only Load results: # &#39;ss&#39; =&gt; calibrated models, &#39;prolif&#39; =&gt; random models # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; model-wise ## HSA results ss_hsa_ensemblewise_50sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_50sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) ss_hsa_modelwise_50sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_50sim_fixpoints_hsa_modelwise_synergies.tab&quot;) ss_hsa_ensemblewise_100sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_100sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) ss_hsa_modelwise_100sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_100sim_fixpoints_hsa_modelwise_synergies.tab&quot;) ss_hsa_ensemblewise_150sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_150sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) ss_hsa_modelwise_150sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_150sim_fixpoints_hsa_modelwise_synergies.tab&quot;) ss_hsa_ensemblewise_200sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_200sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) ss_hsa_modelwise_200sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_200sim_fixpoints_hsa_modelwise_synergies.tab&quot;) prolif_hsa_ensemblewise_file = paste0(&quot;results/link-only/cascade_2.0_rand_150sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) prolif_hsa_modelwise_file = paste0(&quot;results/link-only/cascade_2.0_rand_150sim_fixpoints_hsa_modelwise_synergies.tab&quot;) ss_hsa_ensemblewise_synergies_50sim = emba::get_synergy_scores(ss_hsa_ensemblewise_50sim_file) ss_hsa_modelwise_synergies_50sim = emba::get_synergy_scores(ss_hsa_modelwise_50sim_file, file_type = &quot;modelwise&quot;) ss_hsa_ensemblewise_synergies_100sim = emba::get_synergy_scores(ss_hsa_ensemblewise_100sim_file) ss_hsa_modelwise_synergies_100sim = emba::get_synergy_scores(ss_hsa_modelwise_100sim_file, file_type = &quot;modelwise&quot;) ss_hsa_ensemblewise_synergies_150sim = emba::get_synergy_scores(ss_hsa_ensemblewise_150sim_file) ss_hsa_modelwise_synergies_150sim = emba::get_synergy_scores(ss_hsa_modelwise_150sim_file, file_type = &quot;modelwise&quot;) ss_hsa_ensemblewise_synergies_200sim = emba::get_synergy_scores(ss_hsa_ensemblewise_200sim_file) ss_hsa_modelwise_synergies_200sim = emba::get_synergy_scores(ss_hsa_modelwise_200sim_file, file_type = &quot;modelwise&quot;) prolif_hsa_ensemblewise_synergies_150sim = emba::get_synergy_scores(prolif_hsa_ensemblewise_file) prolif_hsa_modelwise_synergies_150sim = emba::get_synergy_scores(prolif_hsa_modelwise_file, file_type = &quot;modelwise&quot;) # calculate probability of synergy in the modelwise results ss_hsa_modelwise_synergies_50sim = ss_hsa_modelwise_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_hsa_modelwise_synergies_100sim = ss_hsa_modelwise_synergies_100sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_hsa_modelwise_synergies_150sim = ss_hsa_modelwise_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_hsa_modelwise_synergies_200sim = ss_hsa_modelwise_synergies_200sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) prolif_hsa_modelwise_synergies_150sim = prolif_hsa_modelwise_synergies_150sim %&gt;% mutate(synergy_prob_prolif = synergies/(synergies + `non-synergies`)) observed_synergies_file = paste0(&quot;results/observed_synergies_cascade_2.0&quot;) observed_synergies = get_observed_synergies(observed_synergies_file) # 1 (positive/observed synergy) or 0 (negative/not observed) for all tested drug combinations observed = sapply(prolif_hsa_modelwise_synergies_150sim$perturbation %in% observed_synergies, as.integer) # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; model-wise pred_ew_hsa = bind_cols( ss_hsa_ensemblewise_synergies_50sim %&gt;% select(score) %&gt;% rename(ss_score_50sim = score), ss_hsa_ensemblewise_synergies_100sim %&gt;% select(score) %&gt;% rename(ss_score_100sim = score), ss_hsa_ensemblewise_synergies_150sim %&gt;% select(score) %&gt;% rename(ss_score_150sim = score), ss_hsa_ensemblewise_synergies_200sim %&gt;% select(score) %&gt;% rename(ss_score_200sim = score), prolif_hsa_ensemblewise_synergies_150sim %&gt;% select(score) %&gt;% rename(prolif_score_150sim = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_mw_hsa = bind_cols( ss_hsa_modelwise_synergies_50sim %&gt;% select(perturbation, synergy_prob_ss) %&gt;% rename(synergy_prob_ss_50sim = synergy_prob_ss), ss_hsa_modelwise_synergies_100sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_100sim = synergy_prob_ss), ss_hsa_modelwise_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_150sim = synergy_prob_ss), ss_hsa_modelwise_synergies_200sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_200sim = synergy_prob_ss), prolif_hsa_modelwise_synergies_150sim %&gt;% select(synergy_prob_prolif) %&gt;% rename(synergy_prob_prolif_150sim = synergy_prob_prolif), as_tibble_col(observed, column_name = &quot;observed&quot;)) ROC curves res_ss_ew_50sim = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;ss_score_50sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_100sim = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;ss_score_100sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_150sim = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;ss_score_150sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_200sim = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;ss_score_200sim&quot;, label_col = &quot;observed&quot;) res_prolif_ew_150sim = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;prolif_score_150sim&quot;, label_col = &quot;observed&quot;) res_ss_mw_50sim = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_ss_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_100sim = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_ss_100sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_150sim = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_ss_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_200sim = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_ss_200sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_prolif_mw_150sim = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_prolif_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs plot(x = res_ss_ew_50sim$roc_stats$FPR, y = res_ss_ew_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_ss_ew_100sim$roc_stats$FPR, y = res_ss_ew_100sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = res_ss_ew_150sim$roc_stats$FPR, y = res_ss_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = res_ss_ew_200sim$roc_stats$FPR, y = res_ss_ew_200sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) lines(x = res_prolif_ew_150sim$roc_stats$FPR, y = res_prolif_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[5]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:5], pch = 19, legend = c(paste(round(res_ss_ew_50sim$AUC, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(res_ss_ew_100sim$AUC, digits = 3), &quot;Calibrated (100 sim)&quot;), paste(round(res_ss_ew_150sim$AUC, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(res_ss_ew_200sim$AUC, digits = 3), &quot;Calibrated (200 sim)&quot;), paste(round(res_prolif_ew_150sim$AUC, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) plot(x = res_ss_mw_50sim$roc_stats$FPR, y = res_ss_mw_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_ss_mw_100sim$roc_stats$FPR, y = res_ss_mw_100sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = res_ss_mw_150sim$roc_stats$FPR, y = res_ss_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = res_ss_mw_200sim$roc_stats$FPR, y = res_ss_mw_200sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) lines(x = res_prolif_mw_150sim$roc_stats$FPR, y = res_prolif_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[5]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:5], pch = 19, legend = c(paste(round(res_ss_mw_50sim$AUC, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(res_ss_mw_100sim$AUC, digits = 3), &quot;Calibrated (100 sim)&quot;), paste(round(res_ss_mw_150sim$AUC, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(res_ss_mw_200sim$AUC, digits = 3), &quot;Calibrated (200 sim)&quot;), paste(round(res_prolif_mw_150sim$AUC, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) Figure 24: ROC curves (CASCADE 2.0, HSA synergy method) PR curves pr_ss_ew_hsa_50sim = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(ss_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_ss_ew_hsa_100sim = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(ss_score_100sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_ss_ew_hsa_150sim = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(ss_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_ss_ew_hsa_200sim = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(ss_score_200sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_prolif_ew_hsa_150sim = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(prolif_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_ss_mw_hsa_50sim = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(synergy_prob_ss_50sim), weights.class0 = pred_mw_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_ss_mw_hsa_100sim = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(synergy_prob_ss_100sim), weights.class0 = pred_mw_hsa %&gt;% pull(observed), curve = TRUE) pr_ss_mw_hsa_150sim = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(synergy_prob_ss_150sim), weights.class0 = pred_mw_hsa %&gt;% pull(observed), curve = TRUE) pr_ss_mw_hsa_200sim = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(synergy_prob_ss_200sim), weights.class0 = pred_mw_hsa %&gt;% pull(observed), curve = TRUE) pr_prolif_mw_hsa_150sim = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(synergy_prob_prolif_150sim), weights.class0 = pred_mw_hsa %&gt;% pull(observed), curve = TRUE) plot(pr_ss_ew_hsa_50sim, main = &#39;PR curve, Ensemble-wise synergies (HSA)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_ss_ew_hsa_100sim, add = TRUE, color = my_palette[2]) plot(pr_ss_ew_hsa_150sim, add = TRUE, color = my_palette[3]) plot(pr_ss_ew_hsa_200sim, add = TRUE, color = my_palette[4]) plot(pr_prolif_ew_hsa_150sim, add = TRUE, color = my_palette[5]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:5], pch = 19, legend = c(paste(round(pr_ss_ew_hsa_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_ss_ew_hsa_100sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (100 sim)&quot;), paste(round(pr_ss_ew_hsa_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_ss_ew_hsa_200sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (200 sim)&quot;), paste(round(pr_prolif_ew_hsa_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) plot(pr_ss_mw_hsa_50sim, main = &#39;PR curve, Model-wise synergies (HSA)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_ss_mw_hsa_100sim, add = TRUE, color = my_palette[2]) plot(pr_ss_mw_hsa_150sim, add = TRUE, color = my_palette[3]) plot(pr_ss_mw_hsa_200sim, add = TRUE, color = my_palette[4]) plot(pr_prolif_mw_hsa_150sim, add = TRUE, color = my_palette[5]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:5], pch = 19, legend = c(paste(round(pr_ss_mw_hsa_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_ss_mw_hsa_100sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (100 sim)&quot;), paste(round(pr_ss_mw_hsa_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_ss_mw_hsa_200sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (200 sim)&quot;), paste(round(pr_prolif_mw_hsa_150sim$auc.davis.goadrich, digits = 3), &quot;Random (200 sim)&quot;))) grid(lwd = 0.5) Figure 25: PR curves (CASCADE 2.0, HSA synergy method) To minimize the resulting performance variance, \\(150\\) seems to be a good number of Gitsbe simulations to run for the CASCADE 2.0 network. The PR curves show that the performance of each individual predictor is poor compared to the baseline. Someone looking at the ROC curves only, might reach a different conclusion. Random models perform almost equally well to calibrated models. The model-wise approach produces slightly better ROC results than the ensemble-wise approach AUC sensitivity Investigate same thing as described in here. This is very crucial since the PR performance is poor for the individual predictors, but a combined predictor might be able to counter this. We will combine the synergy scores from the random proliferative simulations with the results from the calibrated Gitsbe simulations (using the results from the \\(150\\) simulation runs). # Ensemble-wise betas = seq(from = -7.5, to = 7.5, by = 0.1) prolif_roc = sapply(betas, function(beta) { pred_ew_hsa = pred_ew_hsa %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = roc.curve(scores.class0 = pred_ew_hsa %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr = sapply(betas, function(beta) { pred_ew_hsa = pred_ew_hsa %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_ew = as_tibble(cbind(betas, prolif_roc, prolif_pr)) df_ew = df_ew %&gt;% tidyr::pivot_longer(-betas, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter (HSA, CASCADE 2.0)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + geom_vline(xintercept = 0) + geom_vline(xintercept = -1, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_text(aes(x=-1.5, label=&quot;β = -1&quot;, y=0.25), colour=&quot;black&quot;, angle=90) + grids() Figure 26: AUC sensitivity (CASCADE 2.0, HSA synergy method, Ensemble-wise results) # Model-wise weights = seq(from = 0, to = 1, by = 0.05) prolif_roc_mw = sapply(weights, function(w) { pred_mw_hsa = pred_mw_hsa %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_hsa$synergy_prob_ss_150sim + w * pred_mw_hsa$synergy_prob_prolif_150sim) res = roc.curve(scores.class0 = pred_mw_hsa %&gt;% pull(weighted_prob), weights.class0 = pred_mw_hsa %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr_mw = sapply(weights, function(w) { pred_mw_hsa = pred_mw_hsa %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_hsa$synergy_prob_ss_150sim + w * pred_mw_hsa$synergy_prob_prolif_150sim) res = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(weighted_prob), weights.class0 = pred_mw_hsa %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_mw = as_tibble(cbind(weights, prolif_roc_mw, prolif_pr_mw)) df_mw = df_mw %&gt;% tidyr::pivot_longer(-weights, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_mw, x = &quot;weights&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;weight $w$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title.position = &quot;center&quot;, title = TeX(&quot;AUC sensitivity to weighted average score (HSA, CASCADE 2.0)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + grids() Figure 27: AUC sensitivity (CASCADE 2.0, HSA synergy method, Model-wise results) No added benefit when using the model-wise approach. The proliferative models seem to add a small contribution to the calibrated models performance (right panel ensemble-wise results =&gt; ROC-AUC increases, PR-AUC is insignificantly changed nonetheless). The \\(\\beta_{best}\\) that maximizes the ROC and PR AUC for the combination of random and calibrated models and is equal to \\(\\beta_{best}=-0.3\\). For \\(\\beta=-1\\) we do not observe performance improvement in this case. Logistic Regression Analysis We tried fitting a model using logistic regression as a different approach to combine/augment the results from calibrated simulations with the random proliferative ones (for the HSA-assessed ensemble-wise results where there was a minimal benefit). model = glm(formula = observed ~ ss_score_150sim + prolif_score_150sim - 1, data = pred_ew_hsa, family = binomial()) model_tidy = broom::tidy(model) coef1 = model_tidy %&gt;% filter(term == &quot;ss_score_150sim&quot;) %&gt;% pull(estimate) coef2 = model_tidy %&gt;% filter(term == &quot;prolif_score_150sim&quot;) %&gt;% pull(estimate) pred_ew_hsa = pred_ew_hsa %&gt;% mutate(glm = coef1 * ss_score_150sim + coef2 * prolif_score_150sim) res_roc = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;glm&quot;, label_col = &quot;observed&quot;) res_pr = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(glm) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed)) The model with the coefficients is as follows (note that adding an intercept makes ROC AUC result considerably worse): extract_eq(model, use_coefs = TRUE) \\[ \\log\\left[ \\frac { P( \\operatorname{observed} = \\operatorname{1} ) }{ 1 - P( \\operatorname{observed} = \\operatorname{1} ) } \\right] = -10.63(\\operatorname{ss\\_score\\_150sim}) + 42.92(\\operatorname{prolif\\_score\\_150sim}) + \\epsilon \\] The ROC AUC produced with a logistic regression model is lower than the calibrated models (with \\(150\\) Gitsbe simulations): 0.5782313 (PR-AUC is also lower: 0.0527052). Regularized Logistic Regression Analysis Because the coefficient values found from the above approach are large, we try a regularized logistic regression approach using the glmnet R package (Friedman et al. 2020). We cross validate the \\(\\lambda\\) parameter and try with different \\(\\alpha \\in [0,1]\\) (\\(\\alpha=0\\) means Ridge regression, \\(\\alpha=1\\) means LASSO, in between means Elastic net) while either minimizing the missclassification error (type.measure=\"class\") or maximizing the ROC-AUC (type.measure = \"auc\"). For each respective \\(\\alpha\\) we choose the \\(\\lambda_{min}\\) as the one the minimizes the average CV error. The intercept was again excluded as it resulted in worse AUC performance. x = pred_ew_hsa %&gt;% select(ss_score_150sim, prolif_score_150sim) %&gt;% as.matrix() y = pred_ew_hsa %&gt;% pull(observed) data_list = list() index = 1 for (i in 0:10) { # from Ridge to LASSO a = i/10 for (measure in c(&quot;auc&quot;, &quot;class&quot;)) { set.seed(42) # for reproducibility cvfit = cv.glmnet(x, y, family = &quot;binomial&quot;, type.measure = measure, intercept = FALSE, alpha = a) coef_mat = coef(cvfit, s = &quot;lambda.min&quot;) pred_ew_hsa = pred_ew_hsa %&gt;% mutate(glm_reg = coef_mat[1] + coef_mat[2] * ss_score_150sim + coef_mat[3] * prolif_score_150sim) res_roc = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;glm_reg&quot;, label_col = &quot;observed&quot;) pr_roc = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(glm_reg) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed)) data_list[[index]] = as_tibble_row(list(alpha = a, measure = measure, ROC_AUC = res_roc$AUC, PR_AUC = pr_roc$auc.davis.goadrich)) index = index + 1 } } data = bind_rows(data_list) # List the best two results data %&gt;% arrange(desc(ROC_AUC)) %&gt;% slice(1:4) %&gt;% kable() alpha measure ROC_AUC PR_AUC 0.0 auc 0.6802721 0.0623343 0.0 class 0.6802721 0.0623343 0.1 auc 0.5770975 0.0527103 0.2 auc 0.5770975 0.0527103 The best ROC AUC produced with a regularized logistic regression model is also lower than the one using calibrated models alone (with \\(150\\) Gitsbe simulations). Note that we get warnings when using glmnet because of the small number of observations for the positive class (observed synergies). Resulting coefficients vary, but tend to be either all too small or larger on the random proliferative model predictor. MAMSE ROC Analysis Using the MAMSE R package (Plante 2017) we try another method to combine the predictor values from the calibrated and the random proliferative models. The resulting ROC curve gets a little bit distorted and AUC is not statistically better from the reference sample population (i.e. the calibrated Gitsbe models with \\(150\\) simulations): # healthy =&gt; non-synergy, diseased =&gt; synergy healthy = list() healthy[[1]] = pred_ew_hsa %&gt;% filter(observed == 0) %&gt;% pull(ss_score_150sim) healthy[[2]] = pred_ew_hsa %&gt;% filter(observed == 0) %&gt;% pull(prolif_score_150sim) diseased = list() diseased[[1]] = pred_ew_hsa %&gt;% filter(observed == 1) %&gt;% pull(ss_score_150sim) diseased[[2]] = pred_ew_hsa %&gt;% filter(observed == 1) %&gt;% pull(prolif_score_150sim) plot(roc(healthy = healthy, diseased = diseased, smalldiseased=TRUE, AUC=TRUE, wh=NULL, wd=NULL, FPR=NULL, method=&quot;np&quot;)) Figure 28: Combined Ensemble-wise Classifier using MAMSE ROC (CASCADE 2.0, HSA) Bliss results Bliss refers to the synergy method used in Drabme to assess the synergies from the gitsbe models We test performance using ROC and PR AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state (\\(50,100,150,200\\) simulations) Random models: fitted to proliferation profile (\\(150\\) simulations) Gitsbe models have mutations on link operator only Load results: # &#39;ss&#39; =&gt; calibrated models, &#39;prolif&#39; =&gt; random proliferative models ## Bliss results ss_bliss_ensemblewise_50sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_50sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_50sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_50sim_fixpoints_bliss_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_100sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_100sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_100sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_100sim_fixpoints_bliss_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_150sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_150sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_150sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_150sim_fixpoints_bliss_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_200sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_200sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_200sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_200sim_fixpoints_bliss_modelwise_synergies.tab&quot;) prolif_bliss_ensemblewise_150sim_file = paste0(&quot;results/link-only/cascade_2.0_rand_150sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) prolif_bliss_modelwise_150sim_file = paste0(&quot;results/link-only/cascade_2.0_rand_150sim_fixpoints_bliss_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_synergies_50sim = emba::get_synergy_scores(ss_bliss_ensemblewise_50sim_file) ss_bliss_modelwise_synergies_50sim = emba::get_synergy_scores(ss_bliss_modelwise_50sim_file, file_type = &quot;modelwise&quot;) ss_bliss_ensemblewise_synergies_100sim = emba::get_synergy_scores(ss_bliss_ensemblewise_100sim_file) ss_bliss_modelwise_synergies_100sim = emba::get_synergy_scores(ss_bliss_modelwise_100sim_file, file_type = &quot;modelwise&quot;) ss_bliss_ensemblewise_synergies_150sim = emba::get_synergy_scores(ss_bliss_ensemblewise_150sim_file) ss_bliss_modelwise_synergies_150sim = emba::get_synergy_scores(ss_bliss_modelwise_150sim_file, file_type = &quot;modelwise&quot;) ss_bliss_ensemblewise_synergies_200sim = emba::get_synergy_scores(ss_bliss_ensemblewise_200sim_file) ss_bliss_modelwise_synergies_200sim = emba::get_synergy_scores(ss_bliss_modelwise_200sim_file, file_type = &quot;modelwise&quot;) prolif_bliss_ensemblewise_synergies_150sim = emba::get_synergy_scores(prolif_bliss_ensemblewise_150sim_file) prolif_bliss_modelwise_synergies_150sim = emba::get_synergy_scores(prolif_bliss_modelwise_150sim_file, file_type = &quot;modelwise&quot;) # calculate probability of synergy in the modelwise results ss_bliss_modelwise_synergies_50sim = ss_bliss_modelwise_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_bliss_modelwise_synergies_100sim = ss_bliss_modelwise_synergies_100sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_bliss_modelwise_synergies_150sim = ss_bliss_modelwise_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_bliss_modelwise_synergies_200sim = ss_bliss_modelwise_synergies_200sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) prolif_bliss_modelwise_synergies_150sim = prolif_bliss_modelwise_synergies_150sim %&gt;% mutate(synergy_prob_prolif = synergies/(synergies + `non-synergies`)) # tidy data pred_ew_bliss = bind_cols( ss_bliss_ensemblewise_synergies_50sim %&gt;% select(perturbation, score) %&gt;% rename(ss_score_50sim = score), ss_bliss_ensemblewise_synergies_100sim %&gt;% select(score) %&gt;% rename(ss_score_100sim = score), ss_bliss_ensemblewise_synergies_150sim %&gt;% select(score) %&gt;% rename(ss_score_150sim = score), ss_bliss_ensemblewise_synergies_200sim %&gt;% select(score) %&gt;% rename(ss_score_200sim = score), prolif_bliss_ensemblewise_synergies_150sim %&gt;% select(score) %&gt;% rename(prolif_score_150sim = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_mw_bliss = bind_cols( ss_bliss_modelwise_synergies_50sim %&gt;% select(perturbation, synergy_prob_ss) %&gt;% rename(synergy_prob_ss_50sim = synergy_prob_ss), ss_bliss_modelwise_synergies_100sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_100sim = synergy_prob_ss), ss_bliss_modelwise_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_150sim = synergy_prob_ss), ss_bliss_modelwise_synergies_200sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_200sim = synergy_prob_ss), prolif_bliss_modelwise_synergies_150sim %&gt;% select(synergy_prob_prolif) %&gt;% rename(synergy_prob_prolif_150sim = synergy_prob_prolif), as_tibble_col(observed, column_name = &quot;observed&quot;)) ROC curves # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; model-wise res_ss_ew_50sim = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score_50sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_100sim = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score_100sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_150sim = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score_150sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_200sim = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score_200sim&quot;, label_col = &quot;observed&quot;) res_prolif_ew_150sim = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;prolif_score_150sim&quot;, label_col = &quot;observed&quot;) res_ss_mw_50sim = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_100sim = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss_100sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_150sim = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_200sim = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss_200sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_prolif_mw_150sim = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_prolif_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs plot(x = res_ss_ew_50sim$roc_stats$FPR, y = res_ss_ew_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_ss_ew_100sim$roc_stats$FPR, y = res_ss_ew_100sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = res_ss_ew_150sim$roc_stats$FPR, y = res_ss_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = res_ss_ew_200sim$roc_stats$FPR, y = res_ss_ew_200sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) lines(x = res_prolif_ew_150sim$roc_stats$FPR, y = res_prolif_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[5]) legend(&#39;topleft&#39;, title = &#39;AUC&#39;, col = my_palette[1:5], pch = 19, legend = c(paste(round(res_ss_ew_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(res_ss_ew_100sim$AUC, digits = 2), &quot;Calibrated (100 sim)&quot;), paste(round(res_ss_ew_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(res_ss_ew_200sim$AUC, digits = 2), &quot;Calibrated (200 sim)&quot;), paste(round(res_prolif_ew_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) plot(x = res_ss_mw_50sim$roc_stats$FPR, y = res_ss_mw_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_ss_mw_100sim$roc_stats$FPR, y = res_ss_mw_100sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = res_ss_mw_150sim$roc_stats$FPR, y = res_ss_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = res_ss_mw_200sim$roc_stats$FPR, y = res_ss_mw_200sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) lines(x = res_prolif_mw_150sim$roc_stats$FPR, y = res_prolif_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[5]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:5], pch = 19, cex = 0.9, legend = c(paste(round(res_ss_mw_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(res_ss_mw_100sim$AUC, digits = 2), &quot;Calibrated (100 sim)&quot;), paste(round(res_ss_mw_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(res_ss_mw_200sim$AUC, digits = 2), &quot;Calibrated (200 sim)&quot;), paste(round(res_prolif_mw_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) Figure 29: ROC curves (CASCADE 2.0, Bliss synergy method) PR curves pr_ss_ew_bliss_50sim = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(ss_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_ss_ew_bliss_100sim = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(ss_score_100sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_ss_ew_bliss_150sim = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(ss_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_ss_ew_bliss_200sim = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(ss_score_200sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_prolif_ew_bliss_150sim = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(prolif_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_ss_mw_bliss_50sim = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(synergy_prob_ss_50sim), weights.class0 = pred_mw_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_ss_mw_bliss_100sim = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(synergy_prob_ss_100sim), weights.class0 = pred_mw_bliss %&gt;% pull(observed), curve = TRUE) pr_ss_mw_bliss_150sim = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(synergy_prob_ss_150sim), weights.class0 = pred_mw_bliss %&gt;% pull(observed), curve = TRUE) pr_ss_mw_bliss_200sim = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(synergy_prob_ss_200sim), weights.class0 = pred_mw_bliss %&gt;% pull(observed), curve = TRUE) pr_prolif_mw_bliss_150sim = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(synergy_prob_prolif_150sim), weights.class0 = pred_mw_bliss %&gt;% pull(observed), curve = TRUE) plot(pr_ss_ew_bliss_50sim, main = &#39;PR curve, Ensemble-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_ss_ew_bliss_100sim, add = TRUE, color = my_palette[2]) plot(pr_ss_ew_bliss_150sim, add = TRUE, color = my_palette[3]) plot(pr_ss_ew_bliss_200sim, add = TRUE, color = my_palette[4]) plot(pr_prolif_ew_bliss_150sim, add = TRUE, color = my_palette[5]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:6], pch = 19, legend = c(paste(round(pr_ss_ew_bliss_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_ss_ew_bliss_100sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (100 sim)&quot;), paste(round(pr_ss_ew_bliss_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_ss_ew_bliss_200sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (200 sim)&quot;), paste(round(pr_prolif_ew_bliss_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) plot(pr_ss_mw_bliss_50sim, main = &#39;PR curve, Model-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_ss_mw_bliss_100sim, add = TRUE, color = my_palette[2]) plot(pr_ss_mw_bliss_150sim, add = TRUE, color = my_palette[3]) plot(pr_ss_mw_bliss_200sim, add = TRUE, color = my_palette[4]) plot(pr_prolif_mw_bliss_150sim, add = TRUE, color = my_palette[5]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:5], pch = 19, legend = c(paste(round(pr_ss_mw_bliss_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_ss_mw_bliss_100sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (100 sim)&quot;), paste(round(pr_ss_mw_bliss_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_ss_mw_bliss_200sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (200 sim)&quot;), paste(round(pr_prolif_mw_bliss_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) Figure 30: PR curves (CASCADE 2.0, Bliss synergy method) To minimize the resulting performance variance, \\(150\\) seems to be a good number of Gitsbe simulations to run for the CASCADE 2.0 network. Individual predictor model-wise results (when looking at the ROC curves) show good performance. Individual predictor ensemble-wise results show that random and calibrated models have poor performance. The PR curves show that the performance of all individual predictors is poor compared to the baseline. Bootstrap Random Model AUC In the previous ROC and PR curves we found a very low ensemble-wise random (proliferative) model performance, indicated by the low numbers of ROC and PR AUC. We want to assess the statistical significance of this result, by bootstraping many model samples from a pool of random models and evaluating the performance of these ensembles. For more details on how to generate the bootstrapped model ensembles, see section Random Model Bootstrap. The following code is used to load the results from the simulations (we have already saved the result for convenience): data_dir = &quot;/home/john/tmp/ags_paper_res/link-only/bliss/random_model_bootstrap&quot; data_list = list() index = 1 for (res_dir in list.dirs(data_dir, recursive = FALSE)) { if (stringr::str_detect(string = res_dir, pattern = &quot;cascade_2.0_rand_prolif_bliss_batch&quot;)) { ew_synergies_file = list.files(path = res_dir, pattern = &quot;ensemblewise_synergies&quot;, full.names = TRUE) rand_scores = emba::get_synergy_scores(ew_synergies_file) observed = sapply(rand_scores$perturbation %in% observed_synergies, as.integer) res_roc = PRROC::roc.curve(scores.class0 = rand_scores$score %&gt;% (function(x) {-x}), weights.class0 = observed) res_pr = PRROC::pr.curve(scores.class0 = rand_scores$score %&gt;% (function(x) {-x}), weights.class0 = observed) # bind all to one (OneForAll) df = dplyr::bind_cols(roc_auc = res_roc$auc, pr_auc = res_pr$auc.davis.goadrich) data_list[[index]] = df index = index + 1 } } rand_res = bind_rows(data_list) saveRDS(rand_res, file = &quot;results/bootstrap_rand_res.rds&quot;) As we can see below, the random model performance if indeed very close to the median of the bootstrapped AUCs: rand_res = readRDS(file = &quot;results/bootstrap_rand_res.rds&quot;) ggboxplot(data = rand_res, y = &quot;roc_auc&quot;, title = &quot;Bootstrap Random Models (ROC)&quot;, xlab = &quot;&quot;, ylab = &quot;ROC AUC&quot;, fill = &quot;gray&quot;) + theme(plot.title = element_text(hjust = 0.5)) + rremove(&quot;x.text&quot;) + rremove(&quot;x.ticks&quot;) ggboxplot(data = rand_res, y = &quot;pr_auc&quot;, title = &quot;Bootstrap Random Models (Precision-Recall)&quot;, xlab = &quot;&quot;, ylab = &quot;PR AUC&quot;, fill = &quot;gray&quot;) + theme(plot.title = element_text(hjust = 0.5)) + rremove(&quot;x.text&quot;) + rremove(&quot;x.ticks&quot;) Figure 31: Random Model Bootstrap: ROC and PR AUCs (CASCADE 2.0, Bliss synergy method) AUC sensitivity Investigate same thing as described in here. This is very crucial since the PR performance is poor for the individual predictors and the ensemble-wise predictors were really bad in terms of AUC-ROC, but a combined predictor might be able to counter this. We will combine the synergy scores from the random proliferative simulations with the results from the calibrated Gitsbe simulations (number of simulations: \\(150\\)). # Ensemble-wise betas = seq(from = -5, to = 5, by = 0.1) prolif_roc = sapply(betas, function(beta) { pred_ew_bliss = pred_ew_bliss %&gt;% mutate(combined_score = ss_score_50sim + beta * prolif_score_150sim) res = roc.curve(scores.class0 = pred_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr = sapply(betas, function(beta) { pred_ew_bliss = pred_ew_bliss %&gt;% mutate(combined_score = ss_score_50sim + beta * prolif_score_150sim) res = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_ew = as_tibble(cbind(betas, prolif_roc, prolif_pr)) df_ew = df_ew %&gt;% tidyr::pivot_longer(-betas, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, ylim = c(0,0.85), panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + geom_vline(xintercept = 0) + geom_vline(xintercept = -1.6, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_vline(xintercept = -1, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_text(aes(x=-2, y=0.4, label=&quot;β = -1.6&quot;), angle=90, colour=&quot;black&quot;) + geom_text(aes(x=-0.75, y=0.38, label=&quot;β = -1&quot;), angle=90, colour=&quot;black&quot;) + grids() Figure 32: AUC sensitivity (CASCADE 2.0, Bliss synergy method, Ensemble-wise results) # Model-wise weights = seq(from = 0, to = 1, by = 0.05) prolif_roc_mw = sapply(weights, function(w) { pred_mw_bliss = pred_mw_bliss %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_bliss$synergy_prob_ss_150sim + w * pred_mw_bliss$synergy_prob_prolif_150sim) res = roc.curve(scores.class0 = pred_mw_bliss %&gt;% pull(weighted_prob), weights.class0 = pred_mw_bliss %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr_mw = sapply(weights, function(w) { pred_mw_bliss = pred_mw_bliss %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_bliss$synergy_prob_ss_150sim + w * pred_mw_bliss$synergy_prob_prolif_150sim) res = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(weighted_prob), weights.class0 = pred_mw_bliss %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_mw = as_tibble(cbind(weights, prolif_roc_mw, prolif_pr_mw)) df_mw = df_mw %&gt;% tidyr::pivot_longer(-weights, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_mw, x = &quot;weights&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;weight $w$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title.position = &quot;center&quot;, title = TeX(&quot;AUC sensitivity to weighted average score (Bliss, CASCADE 2.0)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + grids() Figure 33: AUC sensitivity (CASCADE 2.0, Bliss synergy method, Model-wise results) No added benefit when using the model-wise approach. The random proliferative models can be used to normalize against the predictions of the calibrated models and thus bring significant contribution to the calibrated models performance (both ROC-AUC and PR-AUC are increased). The \\(\\beta_{best}\\) that maximizes the ROC and PR AUC for the combination of proliferative and calibrated models and is equal to \\(\\beta_{best}=-1.6\\). For \\(\\beta=-1\\) we still see significant performance improvement. Best ROC and PRC For the Bliss ensemble-wise results we demonstrated above that a value of \\(\\beta_{best}=-1.6\\) can result in significant performance gain of the combined predictor (\\(calibrated + \\beta \\times random\\)) using the results from the \\(150\\) simulation runs (the results for \\(\\beta=-1\\) were still better than the single predictors). Here, we present the ROC and PR curves for the calibrated (normalized to random model) predictions compared to the random proliferative model results. Only for the next plot, Calibrated stands for the combined predictor results, i.e. \\(calibrated + \\beta \\times random, \\beta=-1\\). best_beta1 = -1.6 best_beta2 = -1 pred_ew_bliss = pred_ew_bliss %&gt;% mutate(best_score1 = ss_score_150sim + best_beta1 * prolif_score_150sim, best_score2 = ss_score_150sim + best_beta2 * prolif_score_150sim) roc_best_res1 = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;best_score1&quot;, label_col = &quot;observed&quot;) roc_best_res2 = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;best_score2&quot;, label_col = &quot;observed&quot;) pr_best_res1 = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(best_score1) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_best_res2 = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(best_score2) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) # Plot best ROCs plot(x = roc_best_res2$roc_stats$FPR, y = roc_best_res2$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = (&#39;ROC curve, Ensemble-wise synergies (Bliss)&#39;), xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_prolif_ew_150sim$roc_stats$FPR, y = res_prolif_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) #lines(x = roc_best_res1$roc_stats$FPR, y = roc_best_res1$roc_stats$TPR, # lwd = 2, col = my_palette[3]) legend(&#39;topleft&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, cex = 1.5, legend = c(paste(round(roc_best_res2$AUC, digits = 2), &#39;Calibrated&#39;), paste(round(res_prolif_ew_150sim$AUC, digits = 2), &#39;Random&#39;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) # Plot best PRCs plot(pr_best_res2, main = &#39;PR curve, Ensemble-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE, lwd = 3) plot(pr_prolif_ew_bliss_150sim, add = TRUE, color = my_palette[2], lwd = 3) #plot(pr_best_res1, add = TRUE, color = my_palette[3], lwd = 2) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, cex = 1.5, legend = c(paste(round(pr_best_res2$auc.davis.goadrich, digits = 2), &#39;Calibrated&#39;), paste(round(pr_ss_ew_bliss_150sim$auc.davis.goadrich, digits = 2), &#39;Random&#39;))) grid(lwd = 0.5) Figure 34: ROC and PR curves for Random and Combined Predictor (CASCADE 2.0, Link Operator Mutations) The ROC ensemble-wise statistics data for the combined predictor (\\(\\beta=-1\\), the Calibrated in the above plot) are as follows: DT::datatable(data = roc_best_res2$roc_stats, options = list(pageLength = 5, lengthMenu = c(5, 20, 40), searching = FALSE)) %&gt;% formatRound(c(1,6,7,8,9), digits = 3) Figure 35: ROC data for Best Combined Predictor (CASCADE 2.0, Link Operator Mutations, Bliss synergy method) # TP synergies at a specified threshold (0 below) # pred_ew_bliss %&gt;% # select(perturbation, observed, best_score2) %&gt;% # filter(best_score2 &lt; 0, observed == 1) # investigate the average threshold as a synergy classification index # thres = roc_best_res2$roc_stats %&gt;% pull(threshold) # thres = thres[is.finite(thres)] # remove Inf&#39;s # roc_best_res2$roc_stats %&gt;% # filter(threshold &lt; mean(thres)) %&gt;% # slice(n()) %&gt;% kable() Correlation We test for correlation between some of the results shown in the ROC curves. The results tested are the ensemble-wise vs model-wise, random models vs calibrated models and HSA vs Bliss synergy assessment (the calibrated and proliferative models are from the \\(150\\) simulation results). P-values are represented at 3 significant levels: \\(0.05, 0.01, 0.001\\) (*, **, ***) and the correlation coefficient is calculated using Kendall’s tau statistic. synergy_scores = bind_cols( pred_ew_hsa %&gt;% select(ss_score_150sim, prolif_score_150sim) %&gt;% rename(cal_ew_hsa = ss_score_150sim, random_ew_hsa = prolif_score_150sim), pred_ew_bliss %&gt;% select(ss_score_150sim, prolif_score_150sim) %&gt;% rename(cal_ew_bliss = ss_score_150sim, random_ew_bliss = prolif_score_150sim), pred_mw_hsa %&gt;% select(synergy_prob_ss_150sim, synergy_prob_prolif_150sim) %&gt;% rename(cal_mw_hsa = synergy_prob_ss_150sim, random_mw_hsa = synergy_prob_prolif_150sim), pred_mw_bliss %&gt;% select(synergy_prob_ss_150sim, synergy_prob_prolif_150sim) %&gt;% rename(cal_mw_bliss = synergy_prob_ss_150sim, random_mw_bliss = synergy_prob_prolif_150sim) ) M = cor(synergy_scores, method = &quot;kendall&quot;) res = cor.mtest(synergy_scores, method = &quot;kendall&quot;) corrplot(corr = M, type = &quot;upper&quot;, p.mat = res$p, sig.level = c(.001, .01, .05), pch.cex = 1, pch.col = &quot;white&quot;, insig = &quot;label_sig&quot;, tl.col = &quot;black&quot;, tl.srt = 45) Figure 36: Correlation Plot for CASCADE 2.0 Results Bliss ensemble-wise results don’t correlate at all with the model-wise results (topright part of the correlation plot). The HSA ensemble-wise results do so (at some degree). Between the ensemble-wise results there is no strong correlation (topleft) while between the model-wise (bottomright) there is strong correlation. Fitness Evolution Results are from the run with \\(200\\) Gitsbe simulations, fitting to steady state (calibrated models). fitness_summary_file = &quot;results/link-only/cascade_2.0_ss_200sim_fixpoints_hsa_summary.txt&quot; fit_res = read_summary_file(file_name = fitness_summary_file) # rows = simulations, columns = generations # value in (sim,gen) cell = average fitness of models in that particular (sim,gen) combination avg_fit_link = do.call(dplyr::bind_rows, sapply(fit_res, colMeans)) colnames(avg_fit_link) = 1:ncol(avg_fit_link) avg_fit_long_link = avg_fit_link %&gt;% pivot_longer(cols = everything()) %&gt;% mutate(name = as.integer(name)) ggline(data = avg_fit_long_link, x = &quot;name&quot;, y = &quot;value&quot;, color = my_palette[2], add = &quot;mean_sd&quot;, add.params = list(color = &quot;black&quot;), main = &quot;Fitness Evolution across Generations&quot;, xlab = &quot;Generations&quot;, ylab = &quot;Fitness&quot;) + theme(plot.title = element_text(hjust = 0.5)) + grids() Figure 37: Fitness Evolution (200 simulations, link operator mutations, CASCADE 2.0) Fitness vs Ensemble Performance We check for correlation between the calibrated models fitness to the AGS steady state and their ensemble performance subject to normalization to the random model predictions. The main idea here is that we generate different training data samples, in which the boolean steady state nodes have their values flipped (so they are only partially correct) and we fit models to these (\\(20\\) simulations =&gt; \\(60\\) models per training data, \\(205\\) training data samples in total). These calibrated model ensembles can then be tested for their prediction performance. Then we use the ensemble-wise random proliferative model predictions (\\(150\\) simulations) to normalize (\\(\\beta=-1\\)) against the calibrated model predictions and compute the AUC ROC and AUC PR for each model ensemble. Check how to generate the appropriate data and run the simulations in the section Fitness vs Performance Methods. The code to load the simulation result data is the following (we have already saved the result for convenience): # get flipped training data results data_dir = &quot;/home/john/tmp/ags_paper_res/fit-vs-performance-results-bliss&quot; # define `beta` value for normalization beta = -1 data_list = list() index = 1 for (res_dir in list.dirs(data_dir, recursive = FALSE)) { ew_synergies_file = list.files(path = res_dir, pattern = &quot;ensemblewise_synergies&quot;, full.names = TRUE) ew_ss_scores = emba::get_synergy_scores(ew_synergies_file) # get the models stable states models_dir = paste0(res_dir, &quot;/models&quot;) # you get messages for models with {#stable states} != 1 # a few models have 2 stable states and they are not included # in the returned data frame models_stable_states = emba::get_stable_state_from_models_dir(models_dir) # calculate models fitness to AGS steady state models_fit = apply(models_stable_states[, names(steady_state)], 1, usefun::get_percentage_of_matches, steady_state) # calculate normalized model performance (ROC-AUC and PR-AUC) pred = dplyr::bind_cols( random = pred_ew_bliss %&gt;% select(prolif_score_150sim) %&gt;% rename(random_score = prolif_score_150sim), ss = ew_ss_scores %&gt;% select(score) %&gt;% rename(ss_score = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) # get the normalized synergy scores pred = pred %&gt;% mutate(combined_score = ss_score + beta * random_score) res_roc = PRROC::roc.curve(scores.class0 = pred %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred %&gt;% pull(observed)) res_pr = PRROC::pr.curve(scores.class0 = pred %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred %&gt;% pull(observed)) # bind all to one (OneForAll) df = dplyr::bind_cols( roc_auc = res_roc$auc, pr_auc = res_pr$auc.davis.goadrich, avg_fit = mean(models_fit)) data_list[[index]] = df index = index + 1 } res = bind_rows(data_list) saveRDS(res, file = &quot;results/res_fit_aucs.rds&quot;) Load the already-stored result: res = readRDS(file = &quot;results/res_fit_aucs.rds&quot;) We check if our data is normally distributed using the Shapiro-Wilk normality test: shapiro.test(x = res$roc_auc) Shapiro-Wilk normality test data: res$roc_auc W = 0.92436, p-value = 8.883e-09 shapiro.test(x = res$pr_auc) Shapiro-Wilk normality test data: res$pr_auc W = 0.94464, p-value = 4.475e-07 shapiro.test(x = res$avg_fit) Shapiro-Wilk normality test data: res$avg_fit W = 0.89506, p-value = 8.472e-11 We observe from the low p-values that the data is not normally distributed. Thus, we are going to use a non-parametric correlation metric, namely the Kendall rank-based test (and it’s respective coefficient, \\(\\tau\\)), to check for correlation between the ensemble model performance (ROC-AUC, PR-AUC) and the fitness to the AGS steady state: ggscatter(data = res, x = &quot;avg_fit&quot;, y = &quot;roc_auc&quot;, xlab = &quot;Average Fitness per Model Ensemble&quot;, title = &quot;Fitness to AGS Steady State vs Performance (ROC)&quot;, ylab = &quot;ROC AUC&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, label.y.npc = &quot;bottom&quot;, size = 6, cor.coef.name = &quot;tau&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 38: Fitness to AGS Steady State vs ROC-AUC Performance (CASCADE 2.0, Bliss synergy method, Ensemble-wise normalized results) ggscatter(data = res, x = &quot;avg_fit&quot;, y = &quot;pr_auc&quot;, xlab = &quot;Average Fitness per Model Ensemble&quot;, title = &quot;Fitness to AGS Steady State vs Performance (Precision-Recall)&quot;, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), ylab = &quot;PR AUC&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, size = 6, cor.coef.name = &quot;tau&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 39: Fitness to AGS Steady State vs PR-AUC Performance (CASCADE 2.0, Bliss synergy method, Ensemble-wise normalized results) We observe that there exists some correlation between the normalized ensemble model performance vs the models fitness to the training steady state data. The performance as measured by the ROC AUC is less sensitive to changes in the training data but there is better correlation with regards to the PR AUC, which is a more informative measure for our imbalanced dataset (Saito and Rehmsmeier 2015). Heatmaps: Stable State and Parameterization The drawn heatmaps use the Calibrated models (fitted to steady state) from the Gitsbe run with \\(150\\) simulations (using the Bliss Drabme synergy assessment). The colored column (node) names are part of the AGS training steady state models_dir = &quot;results/link-only/models_cascade_2.0_ss_150sim_bliss/&quot; # Steady States and Link Operators models_stable_states = emba::get_stable_state_from_models_dir(models_dir) models_link_operators = emba::get_link_operators_from_models_dir(models_dir) # get the AGS steady state steady_state_file = &quot;results/steadystate&quot; lines = readLines(steady_state_file) ss_data = unlist(strsplit(x = lines[8], split = &quot;\\t&quot;)) ss_mat = stringr::str_split(string = ss_data, pattern = &quot;:&quot;, simplify = TRUE) colnames(ss_mat) = c(&quot;nodes&quot;, &quot;states&quot;) ss_tbl = ss_mat %&gt;% as_tibble() %&gt;% mutate_at(vars(states), as.integer) steady_state = ss_tbl %&gt;% pull(states) names(steady_state) = ss_tbl %&gt;% pull(nodes) # calculate models fitness to AGS steady state models_fit = apply(models_stable_states[, names(steady_state)], 1, usefun::get_percentage_of_matches, steady_state) # make sure model name order is ok all(names(models_fit) == rownames(models_stable_states)) all(names(models_fit) == rownames(models_link_operators)) # coloring state_colors = c(&quot;red&quot;, &quot;lightyellow&quot;) state_col_fun = circlize::colorRamp2(breaks = c(0, 1), colors = state_colors) fit_col_fun = circlize::colorRamp2(breaks = c(min(models_fit), max(models_fit)), colors = c(&quot;red&quot;, &quot;green&quot;)) # define fitness color bar fit_annot = rowAnnotation(fitness = anno_simple(x = models_fit, col = fit_col_fun), show_annotation_name = FALSE) # color steady state nodes in the heatmap ss_nodes_colors = rep(&quot;black&quot;, length(colnames(models_stable_states))) names(ss_nodes_colors) = colnames(models_stable_states) ss_nodes_colors[names(ss_nodes_colors) %in% names(steady_state)] = &quot;magenta&quot; heatmap_ss = ComplexHeatmap::Heatmap(matrix = as.matrix(models_stable_states), name = &quot;heatmap_ss&quot;, column_title = &quot;Models Stable States&quot;, column_title_gp = gpar(fontsize = 20), column_names_gp = gpar(fontsize = 3, col = ss_nodes_colors), row_dend_width = unit(0.7, &quot;inches&quot;), column_dend_height = unit(1, &quot;inches&quot;), col = state_col_fun, show_row_names = FALSE, left_annotation = fit_annot, show_heatmap_legend = FALSE) #use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 20) # define the 2 legends activity_state_legend = Legend(title = &quot;Activity State&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), legend_gp = gpar(fill = state_colors)) fit_legend = Legend(title = &quot;Fitness&quot;, col = fit_col_fun) train_legend = Legend(labels = c(&quot;Training&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;)), labels_gp = gpar(fontface = &quot;bold&quot;)) legend_list = packLegend(activity_state_legend, fit_legend, train_legend, direction = &quot;vertical&quot;) heatmap_ss = draw(heatmap_ss, annotation_legend_list = legend_list, annotation_legend_side = &quot;right&quot;) Figure 40: Stable States Heatmap (150 simulations, 450 models, link operator mutations, CASCADE 2.0) # code to add rectangular boxes for specific nodes # co = column_order(heatmap_ss) # nc = ncol(models_stable_states) # marked_nodes = c(&quot;MYC&quot;, &quot;TP53&quot;) # decorate_heatmap_body(heatmap = &quot;heatmap_ss&quot;, code = { # for(node in marked_nodes) { # i = which(colnames(models_stable_states)[co] == node) # grid.rect(x = (i-0.5)/nc, width = 1/nc, gp=gpar(col=&quot;black&quot;, fill = NA, lwd = 1)) # } # }) # color steady state nodes in the heatmap lo_nodes_colors = rep(&quot;black&quot;, length(colnames(models_link_operators))) names(lo_nodes_colors) = colnames(models_link_operators) lo_nodes_colors[names(lo_nodes_colors) %in% names(steady_state)] = &quot;magenta&quot; # 10 of 24 heatmap_param = ComplexHeatmap::Heatmap(matrix = as.matrix(models_link_operators), name = &quot;heatmap_param&quot;, column_title = &quot;Model Parameterization&quot;, column_title_gp = gpar(fontsize = 20), column_names_gp = gpar(fontsize = 8, col = lo_nodes_colors), col = state_col_fun, show_row_names = FALSE, left_annotation = fit_annot, show_heatmap_legend = FALSE) #use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 20) # define the 2 legends (`fit_legend` is same as in previous heatmap) link_operators_legend = Legend(title = &quot;Link Operator&quot;, labels = c(&quot;AND NOT&quot;, &quot;OR NOT&quot;), legend_gp = gpar(fill = state_colors)) train_legend = Legend(labels = c(&quot;Training&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;)), labels_gp = gpar(fontface = &quot;bold&quot;)) legend_list = packLegend(link_operators_legend, fit_legend, train_legend, direction = &quot;vertical&quot;) draw(heatmap_param, annotation_legend_list = legend_list, annotation_legend_side = &quot;right&quot;) Figure 41: Parameterization Heatmap (150 simulations, 450 models, 52 equations with link operators, CASCADE 2.0) "],["cascade-2-0-analysis-topology-mutations.html", "CASCADE 2.0 Analysis (Topology Mutations) HSA Results Bliss Results Best ROC and PRC Fitness vs Ensemble Performance", " CASCADE 2.0 Analysis (Topology Mutations) Load the results: # &#39;ss&#39; =&gt; calibrated models, &#39;rand&#39; =&gt; proliferative models (so not random but kind of!) # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; modelwise ## HSA results ss topo_ss_hsa_ew_50sim_file = paste0(&quot;results/topology-only/cascade_2.0_ss_50sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) topo_ss_hsa_mw_50sim_file = paste0(&quot;results/topology-only/cascade_2.0_ss_50sim_fixpoints_hsa_modelwise_synergies.tab&quot;) topo_ss_hsa_ew_150sim_file = paste0(&quot;results/topology-only/cascade_2.0_ss_150sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) topo_ss_hsa_mw_150sim_file = paste0(&quot;results/topology-only/cascade_2.0_ss_150sim_fixpoints_hsa_modelwise_synergies.tab&quot;) topo_ss_hsa_ew_synergies_50sim = emba::get_synergy_scores(topo_ss_hsa_ew_50sim_file) topo_ss_hsa_mw_synergies_50sim = emba::get_synergy_scores(topo_ss_hsa_mw_50sim_file, file_type = &quot;modelwise&quot;) topo_ss_hsa_ew_synergies_150sim = emba::get_synergy_scores(topo_ss_hsa_ew_150sim_file) topo_ss_hsa_mw_synergies_150sim = emba::get_synergy_scores(topo_ss_hsa_mw_150sim_file, file_type = &quot;modelwise&quot;) ## HSA results rand topo_prolif_hsa_ew_50sim_file = paste0(&quot;results/topology-only/cascade_2.0_rand_50sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) topo_prolif_hsa_mw_50sim_file = paste0(&quot;results/topology-only/cascade_2.0_rand_50sim_fixpoints_hsa_modelwise_synergies.tab&quot;) topo_prolif_hsa_ew_150sim_file = paste0(&quot;results/topology-only/cascade_2.0_rand_150sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) topo_prolif_hsa_mw_150sim_file = paste0(&quot;results/topology-only/cascade_2.0_rand_150sim_fixpoints_hsa_modelwise_synergies.tab&quot;) topo_prolif_hsa_ew_synergies_50sim = emba::get_synergy_scores(topo_prolif_hsa_ew_50sim_file) topo_prolif_hsa_mw_synergies_50sim = emba::get_synergy_scores(topo_prolif_hsa_mw_50sim_file, file_type = &quot;modelwise&quot;) topo_prolif_hsa_ew_synergies_150sim = emba::get_synergy_scores(topo_prolif_hsa_ew_150sim_file) topo_prolif_hsa_mw_synergies_150sim = emba::get_synergy_scores(topo_prolif_hsa_mw_150sim_file, file_type = &quot;modelwise&quot;) ## Bliss results ss topo_ss_bliss_ew_50sim_file = paste0(&quot;results/topology-only/cascade_2.0_ss_50sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) topo_ss_bliss_mw_50sim_file = paste0(&quot;results/topology-only/cascade_2.0_ss_50sim_fixpoints_bliss_modelwise_synergies.tab&quot;) topo_ss_bliss_ew_150sim_file = paste0(&quot;results/topology-only/cascade_2.0_ss_150sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) topo_ss_bliss_mw_150sim_file = paste0(&quot;results/topology-only/cascade_2.0_ss_150sim_fixpoints_bliss_modelwise_synergies.tab&quot;) topo_ss_bliss_ew_synergies_50sim = emba::get_synergy_scores(topo_ss_bliss_ew_50sim_file) topo_ss_bliss_mw_synergies_50sim = emba::get_synergy_scores(topo_ss_bliss_mw_50sim_file, file_type = &quot;modelwise&quot;) topo_ss_bliss_ew_synergies_150sim = emba::get_synergy_scores(topo_ss_bliss_ew_150sim_file) topo_ss_bliss_mw_synergies_150sim = emba::get_synergy_scores(topo_ss_bliss_mw_150sim_file, file_type = &quot;modelwise&quot;) ## Bliss results rand topo_prolif_bliss_ew_50sim_file = paste0(&quot;results/topology-only/cascade_2.0_rand_50sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) topo_prolif_bliss_mw_50sim_file = paste0(&quot;results/topology-only/cascade_2.0_rand_50sim_fixpoints_bliss_modelwise_synergies.tab&quot;) topo_prolif_bliss_ew_150sim_file = paste0(&quot;results/topology-only/cascade_2.0_rand_150sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) topo_prolif_bliss_mw_150sim_file = paste0(&quot;results/topology-only/cascade_2.0_rand_150sim_fixpoints_bliss_modelwise_synergies.tab&quot;) topo_prolif_bliss_ew_synergies_50sim = emba::get_synergy_scores(topo_prolif_bliss_ew_50sim_file) topo_prolif_bliss_mw_synergies_50sim = emba::get_synergy_scores(topo_prolif_bliss_mw_50sim_file, file_type = &quot;modelwise&quot;) topo_prolif_bliss_ew_synergies_150sim = emba::get_synergy_scores(topo_prolif_bliss_ew_150sim_file) topo_prolif_bliss_mw_synergies_150sim = emba::get_synergy_scores(topo_prolif_bliss_mw_150sim_file, file_type = &quot;modelwise&quot;) # calculate probability of synergy in the modelwise results topo_ss_hsa_mw_synergies_50sim = topo_ss_hsa_mw_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topo_ss_hsa_mw_synergies_150sim = topo_ss_hsa_mw_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topo_prolif_hsa_mw_synergies_50sim = topo_prolif_hsa_mw_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topo_prolif_hsa_mw_synergies_150sim = topo_prolif_hsa_mw_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topo_ss_bliss_mw_synergies_50sim = topo_ss_bliss_mw_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topo_ss_bliss_mw_synergies_150sim = topo_ss_bliss_mw_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topo_prolif_bliss_mw_synergies_50sim = topo_prolif_bliss_mw_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topo_prolif_bliss_mw_synergies_150sim = topo_prolif_bliss_mw_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) # Tidy the data pred_topo_ew_hsa = bind_cols( topo_ss_hsa_ew_synergies_50sim %&gt;% rename(ss_score_50sim = score), topo_ss_hsa_ew_synergies_150sim %&gt;% select(score) %&gt;% rename(ss_score_150sim = score), topo_prolif_hsa_ew_synergies_50sim %&gt;% select(score) %&gt;% rename(prolif_score_50sim = score), topo_prolif_hsa_ew_synergies_150sim %&gt;% select(score) %&gt;% rename(prolif_score_150sim = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_topo_mw_hsa = bind_cols( topo_ss_hsa_mw_synergies_50sim %&gt;% select(perturbation, synergy_prob_ss) %&gt;% rename(synergy_prob_ss_50sim = synergy_prob_ss), topo_ss_hsa_mw_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_150sim = synergy_prob_ss), topo_prolif_hsa_mw_synergies_50sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_prolif_50sim = synergy_prob_ss), topo_prolif_hsa_mw_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_prolif_150sim = synergy_prob_ss), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_topo_ew_bliss = bind_cols( topo_ss_bliss_ew_synergies_50sim %&gt;% rename(ss_score_50sim = score), topo_ss_bliss_ew_synergies_150sim %&gt;% select(score) %&gt;% rename(ss_score_150sim = score), topo_prolif_bliss_ew_synergies_50sim %&gt;% select(score) %&gt;% rename(prolif_score_50sim = score), topo_prolif_bliss_ew_synergies_150sim %&gt;% select(score) %&gt;% rename(prolif_score_150sim = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_topo_mw_bliss = bind_cols( topo_ss_bliss_mw_synergies_50sim %&gt;% select(perturbation, synergy_prob_ss) %&gt;% rename(synergy_prob_ss_50sim = synergy_prob_ss), topo_ss_bliss_mw_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_150sim = synergy_prob_ss), topo_prolif_bliss_mw_synergies_50sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_prolif_50sim = synergy_prob_ss), topo_prolif_bliss_mw_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_prolif_150sim = synergy_prob_ss), as_tibble_col(observed, column_name = &quot;observed&quot;)) HSA Results HSA refers to the synergy method used in Drabme to assess the synergies from the gitsbe models We test performance using ROC and PR AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state (\\(50,150\\) simulations) Random models: fitted to proliferation profile (\\(50,150\\) simulations) Gitsbe models have only topology mutations (\\(50\\) mutations as a bootstrap value, \\(10\\) after models with stable states are found) ROC curves topo_res_ss_ew_50sim = get_roc_stats(df = pred_topo_ew_hsa, pred_col = &quot;ss_score_50sim&quot;, label_col = &quot;observed&quot;) topo_res_ss_ew_150sim = get_roc_stats(df = pred_topo_ew_hsa, pred_col = &quot;ss_score_150sim&quot;, label_col = &quot;observed&quot;) topo_res_prolif_ew_50sim = get_roc_stats(df = pred_topo_ew_hsa, pred_col = &quot;prolif_score_50sim&quot;, label_col = &quot;observed&quot;) topo_res_prolif_ew_150sim = get_roc_stats(df = pred_topo_ew_hsa, pred_col = &quot;prolif_score_150sim&quot;, label_col = &quot;observed&quot;) topo_res_ss_mw_50sim = get_roc_stats(df = pred_topo_mw_hsa, pred_col = &quot;synergy_prob_ss_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topo_res_ss_mw_150sim = get_roc_stats(df = pred_topo_mw_hsa, pred_col = &quot;synergy_prob_ss_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topo_res_prolif_mw_50sim = get_roc_stats(df = pred_topo_mw_hsa, pred_col = &quot;synergy_prob_prolif_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topo_res_prolif_mw_150sim = get_roc_stats(df = pred_topo_mw_hsa, pred_col = &quot;synergy_prob_prolif_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs plot(x = topo_res_ss_ew_50sim$roc_stats$FPR, y = topo_res_ss_ew_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = topo_res_ss_ew_150sim$roc_stats$FPR, y = topo_res_ss_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = topo_res_prolif_ew_50sim$roc_stats$FPR, y = topo_res_prolif_ew_50sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = topo_res_prolif_ew_150sim$roc_stats$FPR, y = topo_res_prolif_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(topo_res_ss_ew_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(topo_res_ss_ew_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(topo_res_prolif_ew_50sim$AUC, digits = 2), &quot;Random (50 sim)&quot;), paste(round(topo_res_prolif_ew_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) plot(x = topo_res_ss_mw_50sim$roc_stats$FPR, y = topo_res_ss_mw_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = topo_res_ss_mw_150sim$roc_stats$FPR, y = topo_res_ss_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = topo_res_prolif_mw_50sim$roc_stats$FPR, y = topo_res_prolif_mw_50sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = topo_res_prolif_mw_150sim$roc_stats$FPR, y = topo_res_prolif_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(topo_res_ss_mw_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(topo_res_ss_mw_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(topo_res_prolif_mw_50sim$AUC, digits = 2), &quot;Random (50 sim)&quot;), paste(round(topo_res_prolif_mw_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) Figure 42: ROC curves (CASCADE 2.0, Topology Mutations, HSA synergy method) PR curves pr_topo_res_ss_ew_50sim = pr.curve(scores.class0 = pred_topo_ew_hsa %&gt;% pull(ss_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_topo_res_ss_ew_150sim = pr.curve(scores.class0 = pred_topo_ew_hsa %&gt;% pull(ss_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_topo_res_prolif_ew_50sim = pr.curve(scores.class0 = pred_topo_ew_hsa %&gt;% pull(prolif_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_topo_res_prolif_ew_150sim = pr.curve(scores.class0 = pred_topo_ew_hsa %&gt;% pull(prolif_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_topo_res_ss_mw_50sim = pr.curve(scores.class0 = pred_topo_mw_hsa %&gt;% pull(synergy_prob_ss_50sim), weights.class0 = pred_topo_mw_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_topo_res_ss_mw_150sim = pr.curve(scores.class0 = pred_topo_mw_hsa %&gt;% pull(synergy_prob_ss_150sim), weights.class0 = pred_topo_mw_hsa %&gt;% pull(observed), curve = TRUE) pr_topo_res_prolif_mw_50sim = pr.curve(scores.class0 = pred_topo_mw_hsa %&gt;% pull(synergy_prob_prolif_50sim), weights.class0 = pred_topo_mw_hsa %&gt;% pull(observed), curve = TRUE) pr_topo_res_prolif_mw_150sim = pr.curve(scores.class0 = pred_topo_mw_hsa %&gt;% pull(synergy_prob_prolif_150sim), weights.class0 = pred_topo_mw_hsa %&gt;% pull(observed), curve = TRUE) plot(pr_topo_res_ss_ew_50sim, main = &#39;PR curve, Ensemble-wise synergies (HSA)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_topo_res_ss_ew_150sim, add = TRUE, color = my_palette[2]) plot(pr_topo_res_prolif_ew_50sim, add = TRUE, color = my_palette[3]) plot(pr_topo_res_prolif_ew_150sim, add = TRUE, color = my_palette[4]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(pr_topo_res_ss_ew_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_topo_res_ss_ew_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_topo_res_prolif_ew_50sim$auc.davis.goadrich, digits = 3), &quot;Random (50 sim)&quot;), paste(round(pr_topo_res_prolif_ew_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) plot(pr_topo_res_ss_mw_50sim, main = &#39;PR curve, Model-wise synergies (HSA)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_topo_res_ss_mw_150sim, add = TRUE, color = my_palette[2]) plot(pr_topo_res_prolif_mw_50sim, add = TRUE, color = my_palette[3]) plot(pr_topo_res_prolif_mw_150sim, add = TRUE, color = my_palette[4]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(pr_topo_res_ss_mw_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_topo_res_ss_mw_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_topo_res_prolif_mw_50sim$auc.davis.goadrich, digits = 3), &quot;Random (50 sim)&quot;), paste(round(pr_topo_res_prolif_mw_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) Figure 43: PR curves (CASCADE 2.0, Topology Mutations, HSA synergy method) The PR curves show that the performance of each individual predictor is poor compared to the baseline. Someone looking at the ROC curves only might reach a different conclusion. Random proliferative models perform slightly better than the calibrated ones. The model-wise approach produces slightly better ROC results than the ensemble-wise approach. AUC sensitivity Investigate same thing as described in here. This is very crucial since the PR performance is poor for the individual predictors, but a combined predictor might be able to counter this. We will combine the synergy scores from the random proliferative simulations with the results from the calibrated Gitsbe simulations (number of simulations: \\(150\\)). # Ensemble-wise betas = seq(from = -5, to = 5, by = 0.1) prolif_roc_topo = sapply(betas, function(beta) { pred_topo_ew_hsa = pred_topo_ew_hsa %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = roc.curve(scores.class0 = pred_topo_ew_hsa %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_hsa %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr_topo = sapply(betas, function(beta) { pred_topo_ew_hsa = pred_topo_ew_hsa %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = pr.curve(scores.class0 = pred_topo_ew_hsa %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_hsa %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_ew = as_tibble(cbind(betas, prolif_roc_topo, prolif_pr_topo)) df_ew = df_ew %&gt;% tidyr::pivot_longer(-betas, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, ylim = c(0,0.85), panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + geom_vline(xintercept = 0) + geom_vline(xintercept = -1, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_text(aes(x=-1.5, label=&quot;β = -1&quot;, y=0.14), colour=&quot;black&quot;, angle=90) + grids() Figure 44: AUC sensitivity (CASCADE 2.0, Topology Mutations, HSA synergy method, Ensemble-wise results) The proliferative models do not bring any significant change to the prediction performance of the calibrated models. Bliss Results Bliss refers to the synergy method used in Drabme to assess the synergies from the gitsbe models We test performance using ROC and PR AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state (\\(50,150\\) simulations) Random models: fitted to proliferation profile (\\(50,150\\) simulations) Gitsbe models have only topology mutations (\\(50\\) mutations as a bootstrap value, \\(10\\) after models with stable states are found) ROC curves topo_res_ss_ew_50sim = get_roc_stats(df = pred_topo_ew_bliss, pred_col = &quot;ss_score_50sim&quot;, label_col = &quot;observed&quot;) topo_res_ss_ew_150sim = get_roc_stats(df = pred_topo_ew_bliss, pred_col = &quot;ss_score_150sim&quot;, label_col = &quot;observed&quot;) topo_res_prolif_ew_50sim = get_roc_stats(df = pred_topo_ew_bliss, pred_col = &quot;prolif_score_50sim&quot;, label_col = &quot;observed&quot;) topo_res_prolif_ew_150sim = get_roc_stats(df = pred_topo_ew_bliss, pred_col = &quot;prolif_score_150sim&quot;, label_col = &quot;observed&quot;) topo_res_ss_mw_50sim = get_roc_stats(df = pred_topo_mw_bliss, pred_col = &quot;synergy_prob_ss_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topo_res_ss_mw_150sim = get_roc_stats(df = pred_topo_mw_bliss, pred_col = &quot;synergy_prob_ss_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topo_res_prolif_mw_50sim = get_roc_stats(df = pred_topo_mw_bliss, pred_col = &quot;synergy_prob_prolif_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topo_res_prolif_mw_150sim = get_roc_stats(df = pred_topo_mw_bliss, pred_col = &quot;synergy_prob_prolif_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs plot(x = topo_res_ss_ew_50sim$roc_stats$FPR, y = topo_res_ss_ew_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = topo_res_ss_ew_150sim$roc_stats$FPR, y = topo_res_ss_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = topo_res_prolif_ew_50sim$roc_stats$FPR, y = topo_res_prolif_ew_50sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = topo_res_prolif_ew_150sim$roc_stats$FPR, y = topo_res_prolif_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(topo_res_ss_ew_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(topo_res_ss_ew_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(topo_res_prolif_ew_50sim$AUC, digits = 2), &quot;Random (50 sim)&quot;), paste(round(topo_res_prolif_ew_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) plot(x = topo_res_ss_mw_50sim$roc_stats$FPR, y = topo_res_ss_mw_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = topo_res_ss_mw_150sim$roc_stats$FPR, y = topo_res_ss_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = topo_res_prolif_mw_50sim$roc_stats$FPR, y = topo_res_prolif_mw_50sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = topo_res_prolif_mw_150sim$roc_stats$FPR, y = topo_res_prolif_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(topo_res_ss_mw_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(topo_res_ss_mw_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(topo_res_prolif_mw_50sim$AUC, digits = 2), &quot;Random (50 sim)&quot;), paste(round(topo_res_prolif_mw_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) Figure 45: ROC curves (CASCADE 2.0, Topology Mutations, Bliss synergy method) PR curves pr_topo_res_ss_ew_50sim = pr.curve(scores.class0 = pred_topo_ew_bliss %&gt;% pull(ss_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_topo_res_ss_ew_150sim = pr.curve(scores.class0 = pred_topo_ew_bliss %&gt;% pull(ss_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_topo_res_prolif_ew_50sim = pr.curve(scores.class0 = pred_topo_ew_bliss %&gt;% pull(prolif_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_topo_res_prolif_ew_150sim = pr.curve(scores.class0 = pred_topo_ew_bliss %&gt;% pull(prolif_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_topo_res_ss_mw_50sim = pr.curve(scores.class0 = pred_topo_mw_bliss %&gt;% pull(synergy_prob_ss_50sim), weights.class0 = pred_topo_mw_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_topo_res_ss_mw_150sim = pr.curve(scores.class0 = pred_topo_mw_bliss %&gt;% pull(synergy_prob_ss_150sim), weights.class0 = pred_topo_mw_bliss %&gt;% pull(observed), curve = TRUE) pr_topo_res_prolif_mw_50sim = pr.curve(scores.class0 = pred_topo_mw_bliss %&gt;% pull(synergy_prob_prolif_50sim), weights.class0 = pred_topo_mw_bliss %&gt;% pull(observed), curve = TRUE) pr_topo_res_prolif_mw_150sim = pr.curve(scores.class0 = pred_topo_mw_bliss %&gt;% pull(synergy_prob_prolif_150sim), weights.class0 = pred_topo_mw_bliss %&gt;% pull(observed), curve = TRUE) plot(pr_topo_res_ss_ew_50sim, main = &#39;PR curve, Ensemble-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_topo_res_ss_ew_150sim, add = TRUE, color = my_palette[2]) plot(pr_topo_res_prolif_ew_50sim, add = TRUE, color = my_palette[3]) plot(pr_topo_res_prolif_ew_150sim, add = TRUE, color = my_palette[4]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(pr_topo_res_ss_ew_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_topo_res_ss_ew_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_topo_res_prolif_ew_50sim$auc.davis.goadrich, digits = 3), &quot;Random (50 sim)&quot;), paste(round(pr_topo_res_prolif_ew_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) plot(pr_topo_res_ss_mw_50sim, main = &#39;PR curve, Model-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_topo_res_ss_mw_150sim, add = TRUE, color = my_palette[2]) plot(pr_topo_res_prolif_mw_50sim, add = TRUE, color = my_palette[3]) plot(pr_topo_res_prolif_mw_150sim, add = TRUE, color = my_palette[4]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(pr_topo_res_ss_mw_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_topo_res_ss_mw_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_topo_res_prolif_mw_50sim$auc.davis.goadrich, digits = 3), &quot;Random (50 sim)&quot;), paste(round(pr_topo_res_prolif_mw_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) Figure 46: PR curves (CASCADE 2.0, Topology Mutations, Bliss synergy method) The PR curves show that the performance of all individual predictors is poor compared to the baseline. Random proliferative models perform slightly better than the calibrated ones. The model-wise approach produces slightly better ROC and PR results than the ensemble-wise approach AUC sensitivity Investigate same thing as described in here. This is very crucial since the PR performance is poor for the individual predictors, but a combined predictor might be able to counter this. We will combine the synergy scores from the random proliferative simulations with the results from the calibrated Gitsbe simulations (number of simulations: \\(150\\)). # Ensemble-wise betas = seq(from = -5, to = 5, by = 0.1) prolif_roc = sapply(betas, function(beta) { pred_topo_ew_bliss = pred_topo_ew_bliss %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = roc.curve(scores.class0 = pred_topo_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_bliss %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr = sapply(betas, function(beta) { pred_topo_ew_bliss = pred_topo_ew_bliss %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = pr.curve(scores.class0 = pred_topo_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_bliss %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_ew = as_tibble(cbind(betas, prolif_roc, prolif_pr)) df_ew = df_ew %&gt;% tidyr::pivot_longer(-betas, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, ylim = c(0,0.85), panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + geom_vline(xintercept = 0) + geom_vline(xintercept = -1, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_text(aes(x=-1.5, label=&quot;β = -1&quot;, y=0.15), colour=&quot;black&quot;, angle = 90) + grids() Figure 47: AUC sensitivity (CASCADE 2.0, Topology Mutations, Bliss synergy method, Ensemble-wise results) The proliferative models can be used to normalize against the predictions of the calibrated models and thus bring significant contribution to the calibrated models performance (both ROC-AUC and PR-AUC are increased). The \\(\\beta_{best}\\) values of the combined calibrated and random proliferative model predictor that maximize the ROC-AUC and PR-AUC respectively are \\(\\beta_{best}^{\\text{ROC-AUC}}=-0.8\\) and \\(\\beta_{best}^{\\text{PR-AUC}}=-1\\) Best ROC and PRC For the Bliss ensemble-wise results we demonstrated above that a value of \\(\\beta_{best}=-1\\) can result in significant performance gain of the combined predictor (\\(calibrated + \\beta \\times random\\)). So, the best ROC and PR curves we can get with our simulations when using models with topology mutations are: best_beta = -1 pred_topo_ew_bliss = pred_topo_ew_bliss %&gt;% mutate(best_score = ss_score_150sim + best_beta * prolif_score_150sim) roc_best_res = get_roc_stats(df = pred_topo_ew_bliss, pred_col = &quot;best_score&quot;, label_col = &quot;observed&quot;) pr_best_res = pr.curve(scores.class0 = pred_topo_ew_bliss %&gt;% pull(best_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) # Plot best ROC plot(x = roc_best_res$roc_stats$FPR, y = roc_best_res$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = TeX(&#39;ROC curve (Ensemble-wise), $calibrated + \\\\beta \\\\times random$&#39;), xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) legend(&#39;bottomright&#39;, title = TeX(&#39;AUC ($\\\\beta$ = -1)&#39;), col = my_palette[1], pch = 19, legend = paste(round(roc_best_res$AUC, digits = 2), &#39;Bliss (150 sim)&#39;), cex = 1.5) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) # Plot best PRC plot(pr_best_res, main = TeX(&#39;PR curve (Ensemble-wise), $calibrated + \\\\beta \\\\times random$&#39;), auc.main = FALSE, color = my_palette[2], rand.plot = TRUE) legend(&#39;topright&#39;, title = TeX(&#39;AUC ($\\\\beta$ = -1)&#39;), col = my_palette[2], pch = 19, legend = paste(round(pr_best_res$auc.davis.goadrich, digits = 3), &#39;Bliss (150 sim)&#39;), cex = 1.5) grid(lwd = 0.5) Figure 48: ROC and PR curve for best beta (CASCADE 2.0, Topology Mutations) Fitness vs Ensemble Performance We check for correlation between the calibrated models fitness to the AGS steady state and their ensemble performance subject to normalization to the random model predictions. The main idea here is that we generate different training data samples, in which the boolean steady state nodes have their values flipped (so they are only partially correct) and we fit models to these (\\(50\\) simulations =&gt; \\(150\\) topology-mutated models per training data, \\(205\\) training data samples in total). These calibrated model ensembles can then be tested for their prediction performance. Then we use the ensemble-wise random proliferative model predictions (\\(50\\) simulations) to normalize (\\(\\beta=-1\\)) against the calibrated model predictions and compute the AUC ROC and AUC PR for each model ensemble. Check how to generate the appropriate data and run the simulations in the section Fitness vs Performance Methods. The code to load the simulation result data is the following (we have already saved the result for convenience): # get flipped training data results data_dir = &quot;/home/john/tmp/ags_paper_res/fit-vs-performance-results-bliss-topo/&quot; # define `beta` value for normalization beta = -1 data_list = list() index = 1 for (res_dir in list.dirs(data_dir, recursive = FALSE)) { ew_synergies_file = list.files(path = res_dir, pattern = &quot;ensemblewise_synergies&quot;, full.names = TRUE) ew_ss_scores = emba::get_synergy_scores(ew_synergies_file) # get the models stable states models_dir = paste0(res_dir, &quot;/models&quot;) # you get messages for models with {#stable states} != 1 # a few models have 2 stable states and they are not included # in the returned data frame models_stable_states = emba::get_stable_state_from_models_dir(models_dir) # calculate models fitness to AGS steady state models_fit = apply(models_stable_states[, names(steady_state)], 1, usefun::get_percentage_of_matches, steady_state) # calculate normalized model performance (ROC-AUC and PR-AUC) pred = dplyr::bind_cols( pred_topo_ew_bliss %&gt;% select(prolif_score_50sim) %&gt;% rename(random_score = prolif_score_50sim), ew_ss_scores %&gt;% select(score) %&gt;% rename(ss_score = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) # get the normalized synergy scores pred = pred %&gt;% mutate(combined_score = ss_score + beta * random_score) res_roc = PRROC::roc.curve(scores.class0 = pred %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred %&gt;% pull(observed)) res_pr = PRROC::pr.curve(scores.class0 = pred %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred %&gt;% pull(observed)) # bind all to one (OneForAll) df = dplyr::bind_cols( roc_auc = res_roc$auc, pr_auc = res_pr$auc.davis.goadrich, avg_fit = mean(models_fit)) data_list[[index]] = df index = index + 1 } res = bind_rows(data_list) saveRDS(res, file = &quot;results/res_fit_aucs_topo.rds&quot;) Load the already-stored result: res = readRDS(file = &quot;results/res_fit_aucs_topo.rds&quot;) We check if our data is normally distributed using the Shapiro-Wilk normality test: shapiro.test(x = res$roc_auc) Shapiro-Wilk normality test data: res$roc_auc W = 0.98463, p-value = 0.02488 shapiro.test(x = res$pr_auc) Shapiro-Wilk normality test data: res$pr_auc W = 0.92214, p-value = 6.025e-09 shapiro.test(x = res$avg_fit) Shapiro-Wilk normality test data: res$avg_fit W = 0.88305, p-value = 1.609e-11 We observe from the low p-values that the data is not normally distributed. Thus, we are going to use a non-parametric correlation metric, namely the Kendall rank-based test (and it’s respective coefficient, \\(\\tau\\)), to check for correlation between the ensemble model performance (ROC-AUC, PR-AUC) and the fitness to the AGS steady state: ggscatter(data = res, x = &quot;avg_fit&quot;, y = &quot;roc_auc&quot;, xlab = &quot;Average Fitness per Model Ensemble&quot;, title = &quot;Fitness to AGS Steady State vs Performance (ROC)&quot;, ylab = &quot;ROC AUC&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, size = 6, cor.coef.name = &quot;tau&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 49: Fitness to AGS Steady State vs ROC-AUC Performance (CASCADE 2.0, Topology mutations, Bliss synergy method, Ensemble-wise normalized results) ggscatter(data = res, x = &quot;avg_fit&quot;, y = &quot;pr_auc&quot;, xlab = &quot;Average Fitness per Model Ensemble&quot;, title = &quot;Fitness to AGS Steady State vs Performance (Precision-Recall)&quot;, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), ylab = &quot;PR AUC&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, size = 6, cor.coef.name = &quot;tau&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 50: Fitness to AGS Steady State vs PR-AUC Performance (CASCADE 2.0, Topology Mutations, Bliss synergy method, Ensemble-wise normalized results) We observe that there exists some correlation between the normalized ensemble model performance vs the models fitness to the training steady state data. Correlation results are better than when applying link-operator mutations to the models. The topology mutations offer a larger variation in performance in terms of both ROC and PR AUC, given the limited set of provided steady state nodes for calibration of the models (24 out of 144 in total for the AGS cell line). The performance as measured by the ROC AUC is less sensitive to changes in the training data but there is better correlation with regards to the PR AUC, which is a more informative measure for our imbalanced dataset (Saito and Rehmsmeier 2015). "],["cascade-2-0-analysis-topology-and-link-operator-mutations.html", "CASCADE 2.0 Analysis (Topology and Link Operator Mutations) HSA Results Bliss Results Best ROC and PRC", " CASCADE 2.0 Analysis (Topology and Link Operator Mutations) # &#39;ss&#39; =&gt; calibrated models, &#39;rand&#39; =&gt; proliferative models (so not random but kind of!) # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; modelwise ## HSA results ss topolink_ss_hsa_ew_50sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_ss_50sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) topolink_ss_hsa_mw_50sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_ss_50sim_fixpoints_hsa_modelwise_synergies.tab&quot;) topolink_ss_hsa_ew_150sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_ss_150sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) topolink_ss_hsa_mw_150sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_ss_150sim_fixpoints_hsa_modelwise_synergies.tab&quot;) topolink_ss_hsa_ew_synergies_50sim = emba::get_synergy_scores(topolink_ss_hsa_ew_50sim_file) topolink_ss_hsa_mw_synergies_50sim = emba::get_synergy_scores(topolink_ss_hsa_mw_50sim_file, file_type = &quot;modelwise&quot;) topolink_ss_hsa_ew_synergies_150sim = emba::get_synergy_scores(topolink_ss_hsa_ew_150sim_file) topolink_ss_hsa_mw_synergies_150sim = emba::get_synergy_scores(topolink_ss_hsa_mw_150sim_file, file_type = &quot;modelwise&quot;) ## HSA results rand topolink_prolif_hsa_ew_50sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_rand_50sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) topolink_prolif_hsa_mw_50sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_rand_50sim_fixpoints_hsa_modelwise_synergies.tab&quot;) topolink_prolif_hsa_ew_150sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_rand_150sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) topolink_prolif_hsa_mw_150sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_rand_150sim_fixpoints_hsa_modelwise_synergies.tab&quot;) topolink_prolif_hsa_ew_synergies_50sim = emba::get_synergy_scores(topolink_prolif_hsa_ew_50sim_file) topolink_prolif_hsa_mw_synergies_50sim = emba::get_synergy_scores(topolink_prolif_hsa_mw_50sim_file, file_type = &quot;modelwise&quot;) topolink_prolif_hsa_ew_synergies_150sim = emba::get_synergy_scores(topolink_prolif_hsa_ew_150sim_file) topolink_prolif_hsa_mw_synergies_150sim = emba::get_synergy_scores(topolink_prolif_hsa_mw_150sim_file, file_type = &quot;modelwise&quot;) ## Bliss results ss topolink_ss_bliss_ew_50sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_ss_50sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) topolink_ss_bliss_mw_50sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_ss_50sim_fixpoints_bliss_modelwise_synergies.tab&quot;) topolink_ss_bliss_ew_150sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_ss_150sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) topolink_ss_bliss_mw_150sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_ss_150sim_fixpoints_bliss_modelwise_synergies.tab&quot;) topolink_ss_bliss_ew_synergies_50sim = emba::get_synergy_scores(topolink_ss_bliss_ew_50sim_file) topolink_ss_bliss_mw_synergies_50sim = emba::get_synergy_scores(topolink_ss_bliss_mw_50sim_file, file_type = &quot;modelwise&quot;) topolink_ss_bliss_ew_synergies_150sim = emba::get_synergy_scores(topolink_ss_bliss_ew_150sim_file) topolink_ss_bliss_mw_synergies_150sim = emba::get_synergy_scores(topolink_ss_bliss_mw_150sim_file, file_type = &quot;modelwise&quot;) ## Bliss results rand topolink_prolif_bliss_ew_50sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_rand_50sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) topolink_prolif_bliss_mw_50sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_rand_50sim_fixpoints_bliss_modelwise_synergies.tab&quot;) topolink_prolif_bliss_ew_150sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_rand_150sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) topolink_prolif_bliss_mw_150sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_rand_150sim_fixpoints_bliss_modelwise_synergies.tab&quot;) topolink_prolif_bliss_ew_synergies_50sim = emba::get_synergy_scores(topolink_prolif_bliss_ew_50sim_file) topolink_prolif_bliss_mw_synergies_50sim = emba::get_synergy_scores(topolink_prolif_bliss_mw_50sim_file, file_type = &quot;modelwise&quot;) topolink_prolif_bliss_ew_synergies_150sim = emba::get_synergy_scores(topolink_prolif_bliss_ew_150sim_file) topolink_prolif_bliss_mw_synergies_150sim = emba::get_synergy_scores(topolink_prolif_bliss_mw_150sim_file, file_type = &quot;modelwise&quot;) # calculate probability of synergy in the modelwise results topolink_ss_hsa_mw_synergies_50sim = topolink_ss_hsa_mw_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topolink_ss_hsa_mw_synergies_150sim = topolink_ss_hsa_mw_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topolink_prolif_hsa_mw_synergies_50sim = topolink_prolif_hsa_mw_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topolink_prolif_hsa_mw_synergies_150sim = topolink_prolif_hsa_mw_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topolink_ss_bliss_mw_synergies_50sim = topolink_ss_bliss_mw_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topolink_ss_bliss_mw_synergies_150sim = topolink_ss_bliss_mw_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topolink_prolif_bliss_mw_synergies_50sim = topolink_prolif_bliss_mw_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topolink_prolif_bliss_mw_synergies_150sim = topolink_prolif_bliss_mw_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) # Tidy the data pred_topolink_ew_hsa = bind_cols( topolink_ss_hsa_ew_synergies_50sim %&gt;% rename(ss_score_50sim = score), topolink_ss_hsa_ew_synergies_150sim %&gt;% select(score) %&gt;% rename(ss_score_150sim = score), topolink_prolif_hsa_ew_synergies_50sim %&gt;% select(score) %&gt;% rename(prolif_score_50sim = score), topolink_prolif_hsa_ew_synergies_150sim %&gt;% select(score) %&gt;% rename(prolif_score_150sim = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_topolink_mw_hsa = bind_cols( topolink_ss_hsa_mw_synergies_50sim %&gt;% select(perturbation, synergy_prob_ss) %&gt;% rename(synergy_prob_ss_50sim = synergy_prob_ss), topolink_ss_hsa_mw_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_150sim = synergy_prob_ss), topolink_prolif_hsa_mw_synergies_50sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_prolif_50sim = synergy_prob_ss), topolink_prolif_hsa_mw_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_prolif_150sim = synergy_prob_ss), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_topolink_ew_bliss = bind_cols( topolink_ss_bliss_ew_synergies_50sim %&gt;% rename(ss_score_50sim = score), topolink_ss_bliss_ew_synergies_150sim %&gt;% select(score) %&gt;% rename(ss_score_150sim = score), topolink_prolif_bliss_ew_synergies_50sim %&gt;% select(score) %&gt;% rename(prolif_score_50sim = score), topolink_prolif_bliss_ew_synergies_150sim %&gt;% select(score) %&gt;% rename(prolif_score_150sim = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_topolink_mw_bliss = bind_cols( topolink_ss_bliss_mw_synergies_50sim %&gt;% select(perturbation, synergy_prob_ss) %&gt;% rename(synergy_prob_ss_50sim = synergy_prob_ss), topolink_ss_bliss_mw_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_150sim = synergy_prob_ss), topolink_prolif_bliss_mw_synergies_50sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_prolif_50sim = synergy_prob_ss), topolink_prolif_bliss_mw_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_prolif_150sim = synergy_prob_ss), as_tibble_col(observed, column_name = &quot;observed&quot;)) HSA Results HSA refers to the synergy method used in Drabme to assess the synergies from the gitsbe models We test performance using ROC and PR AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state (\\(50,150\\) simulations) Random models: fitted to proliferation profile (\\(50,150\\) simulations) Gitsbe models have both balance and topology mutations (\\(3000,50\\) mutations as a bootstrap value, \\(3\\) and \\(10\\) respectively after models with stable states are found) ROC curves topolink_res_ss_ew_50sim = get_roc_stats(df = pred_topolink_ew_hsa, pred_col = &quot;ss_score_50sim&quot;, label_col = &quot;observed&quot;) topolink_res_ss_ew_150sim = get_roc_stats(df = pred_topolink_ew_hsa, pred_col = &quot;ss_score_150sim&quot;, label_col = &quot;observed&quot;) topolink_res_prolif_ew_50sim = get_roc_stats(df = pred_topolink_ew_hsa, pred_col = &quot;prolif_score_50sim&quot;, label_col = &quot;observed&quot;) topolink_res_prolif_ew_150sim = get_roc_stats(df = pred_topolink_ew_hsa, pred_col = &quot;prolif_score_150sim&quot;, label_col = &quot;observed&quot;) topolink_res_ss_mw_50sim = get_roc_stats(df = pred_topolink_mw_hsa, pred_col = &quot;synergy_prob_ss_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topolink_res_ss_mw_150sim = get_roc_stats(df = pred_topolink_mw_hsa, pred_col = &quot;synergy_prob_ss_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topolink_res_prolif_mw_50sim = get_roc_stats(df = pred_topolink_mw_hsa, pred_col = &quot;synergy_prob_prolif_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topolink_res_prolif_mw_150sim = get_roc_stats(df = pred_topolink_mw_hsa, pred_col = &quot;synergy_prob_prolif_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs plot(x = topolink_res_ss_ew_50sim$roc_stats$FPR, y = topolink_res_ss_ew_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = topolink_res_ss_ew_150sim$roc_stats$FPR, y = topolink_res_ss_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = topolink_res_prolif_ew_50sim$roc_stats$FPR, y = topolink_res_prolif_ew_50sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = topolink_res_prolif_ew_150sim$roc_stats$FPR, y = topolink_res_prolif_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(topolink_res_ss_ew_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(topolink_res_ss_ew_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(topolink_res_prolif_ew_50sim$AUC, digits = 2), &quot;Random (50 sim)&quot;), paste(round(topolink_res_prolif_ew_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) plot(x = topolink_res_ss_mw_50sim$roc_stats$FPR, y = topolink_res_ss_mw_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = topolink_res_ss_mw_150sim$roc_stats$FPR, y = topolink_res_ss_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = topolink_res_prolif_mw_50sim$roc_stats$FPR, y = topolink_res_prolif_mw_50sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = topolink_res_prolif_mw_150sim$roc_stats$FPR, y = topolink_res_prolif_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(topolink_res_ss_mw_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(topolink_res_ss_mw_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(topolink_res_prolif_mw_50sim$AUC, digits = 2), &quot;Random (50 sim)&quot;), paste(round(topolink_res_prolif_mw_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) Figure 51: ROC curves (CASCADE 2.0, Link Operator and Topology Mutations, HSA synergy method) PR curves pr_topolink_res_ss_ew_50sim = pr.curve(scores.class0 = pred_topolink_ew_hsa %&gt;% pull(ss_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_topolink_res_ss_ew_150sim = pr.curve(scores.class0 = pred_topolink_ew_hsa %&gt;% pull(ss_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_topolink_res_prolif_ew_50sim = pr.curve(scores.class0 = pred_topolink_ew_hsa %&gt;% pull(prolif_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_topolink_res_prolif_ew_150sim = pr.curve(scores.class0 = pred_topolink_ew_hsa %&gt;% pull(prolif_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_topolink_res_ss_mw_50sim = pr.curve(scores.class0 = pred_topolink_mw_hsa %&gt;% pull(synergy_prob_ss_50sim), weights.class0 = pred_topolink_mw_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_topolink_res_ss_mw_150sim = pr.curve(scores.class0 = pred_topolink_mw_hsa %&gt;% pull(synergy_prob_ss_150sim), weights.class0 = pred_topolink_mw_hsa %&gt;% pull(observed), curve = TRUE) pr_topolink_res_prolif_mw_50sim = pr.curve(scores.class0 = pred_topolink_mw_hsa %&gt;% pull(synergy_prob_prolif_50sim), weights.class0 = pred_topolink_mw_hsa %&gt;% pull(observed), curve = TRUE) pr_topolink_res_prolif_mw_150sim = pr.curve(scores.class0 = pred_topolink_mw_hsa %&gt;% pull(synergy_prob_prolif_150sim), weights.class0 = pred_topolink_mw_hsa %&gt;% pull(observed), curve = TRUE) plot(pr_topolink_res_ss_ew_50sim, main = &#39;PR curve, Ensemble-wise synergies (HSA)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_topolink_res_ss_ew_150sim, add = TRUE, color = my_palette[2]) plot(pr_topolink_res_prolif_ew_50sim, add = TRUE, color = my_palette[3]) plot(pr_topolink_res_prolif_ew_150sim, add = TRUE, color = my_palette[4]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(pr_topolink_res_ss_ew_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_topolink_res_ss_ew_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_topolink_res_prolif_ew_50sim$auc.davis.goadrich, digits = 3), &quot;Random (50 sim)&quot;), paste(round(pr_topolink_res_prolif_ew_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) plot(pr_topolink_res_ss_mw_50sim, main = &#39;PR curve, Model-wise synergies (HSA)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_topolink_res_ss_mw_150sim, add = TRUE, color = my_palette[2]) plot(pr_topolink_res_prolif_mw_50sim, add = TRUE, color = my_palette[3]) plot(pr_topolink_res_prolif_mw_150sim, add = TRUE, color = my_palette[4]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(pr_topolink_res_ss_mw_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_topolink_res_ss_mw_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_topolink_res_prolif_mw_50sim$auc.davis.goadrich, digits = 3), &quot;Random (50 sim)&quot;), paste(round(pr_topolink_res_prolif_mw_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) Figure 52: PR curves (CASCADE 2.0, Link Operator and Topology Mutations, HSA synergy method) The PR curves show that the performance of each individual predictor is poor compared to the baseline. Someone looking at the ROC curves only might reach a different conclusion. The model-wise approach produces slightly better ROC results than the ensemble-wise approach. AUC sensitivity Investigate same thing as described in here. This is very crucial since the PR performance is poor for the individual predictors, but a combined predictor might be able to counter this. We will combine the synergy scores from the random proliferative simulations with the results from the calibrated Gitsbe simulations (number of simulations: \\(150\\)). # Ensemble-wise betas = seq(from = -5, to = 5, by = 0.1) prolif_roc_topo = sapply(betas, function(beta) { pred_topolink_ew_hsa = pred_topolink_ew_hsa %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = roc.curve(scores.class0 = pred_topolink_ew_hsa %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_hsa %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr_topo = sapply(betas, function(beta) { pred_topolink_ew_hsa = pred_topolink_ew_hsa %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = pr.curve(scores.class0 = pred_topolink_ew_hsa %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_hsa %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_ew = as_tibble(cbind(betas, prolif_roc_topo, prolif_pr_topo)) df_ew = df_ew %&gt;% tidyr::pivot_longer(-betas, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, ylim = c(0,0.85), panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + geom_vline(xintercept = 0) + geom_vline(xintercept = -1, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_text(aes(x=-1.6, label=&quot;β = -1&quot;, y=0.33), colour=&quot;black&quot;, angle=90) + grids() Figure 53: AUC sensitivity (CASCADE 2.0, Link Operator and Topology Mutations, HSA synergy method, Ensemble-wise results) The random proliferative models can be used to normalize against the predictions of the calibrated models and thus bring significant contribution to the calibrated models performance (PR-AUC shows much more sensitivity in that regard - it increases substantially more than the ROC-AUC). The \\(\\beta_{best}\\) value of the combined calibrated and random proliferative model predictor that maximizes both the ROC-AUC and PR-AUC is \\(\\beta_{best}=-1\\). Bliss Results Bliss refers to the synergy method used in Drabme to assess the synergies from the gitsbe models We test performance using ROC and PR AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state (\\(50,150\\) simulations) Random models: fitted to proliferation profile (\\(50,150\\) simulations) Gitsbe models have both balance and topology mutations (\\(3000,50\\) mutations as a bootstrap value, \\(3\\) and \\(10\\) respectively after models with stable states are found) ROC curves topolink_res_ss_ew_50sim = get_roc_stats(df = pred_topolink_ew_bliss, pred_col = &quot;ss_score_50sim&quot;, label_col = &quot;observed&quot;) topolink_res_ss_ew_150sim = get_roc_stats(df = pred_topolink_ew_bliss, pred_col = &quot;ss_score_150sim&quot;, label_col = &quot;observed&quot;) topolink_res_prolif_ew_50sim = get_roc_stats(df = pred_topolink_ew_bliss, pred_col = &quot;prolif_score_50sim&quot;, label_col = &quot;observed&quot;) topolink_res_prolif_ew_150sim = get_roc_stats(df = pred_topolink_ew_bliss, pred_col = &quot;prolif_score_150sim&quot;, label_col = &quot;observed&quot;) topolink_res_ss_mw_50sim = get_roc_stats(df = pred_topolink_mw_bliss, pred_col = &quot;synergy_prob_ss_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topolink_res_ss_mw_150sim = get_roc_stats(df = pred_topolink_mw_bliss, pred_col = &quot;synergy_prob_ss_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topolink_res_prolif_mw_50sim = get_roc_stats(df = pred_topolink_mw_bliss, pred_col = &quot;synergy_prob_prolif_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topolink_res_prolif_mw_150sim = get_roc_stats(df = pred_topolink_mw_bliss, pred_col = &quot;synergy_prob_prolif_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs plot(x = topolink_res_ss_ew_50sim$roc_stats$FPR, y = topolink_res_ss_ew_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = topolink_res_ss_ew_150sim$roc_stats$FPR, y = topolink_res_ss_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = topolink_res_prolif_ew_50sim$roc_stats$FPR, y = topolink_res_prolif_ew_50sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = topolink_res_prolif_ew_150sim$roc_stats$FPR, y = topolink_res_prolif_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(topolink_res_ss_ew_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(topolink_res_ss_ew_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(topolink_res_prolif_ew_50sim$AUC, digits = 2), &quot;Random (50 sim)&quot;), paste(round(topolink_res_prolif_ew_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) plot(x = topolink_res_ss_mw_50sim$roc_stats$FPR, y = topolink_res_ss_mw_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = topolink_res_ss_mw_150sim$roc_stats$FPR, y = topolink_res_ss_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = topolink_res_prolif_mw_50sim$roc_stats$FPR, y = topolink_res_prolif_mw_50sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = topolink_res_prolif_mw_150sim$roc_stats$FPR, y = topolink_res_prolif_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(topolink_res_ss_mw_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(topolink_res_ss_mw_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(topolink_res_prolif_mw_50sim$AUC, digits = 2), &quot;Random (50 sim)&quot;), paste(round(topolink_res_prolif_mw_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) Figure 54: ROC curves (CASCADE 2.0, Link Operator and Topology Mutations, Bliss synergy method) PR curves pr_topolink_res_ss_ew_50sim = pr.curve(scores.class0 = pred_topolink_ew_bliss %&gt;% pull(ss_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_topolink_res_ss_ew_150sim = pr.curve(scores.class0 = pred_topolink_ew_bliss %&gt;% pull(ss_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_topolink_res_prolif_ew_50sim = pr.curve(scores.class0 = pred_topolink_ew_bliss %&gt;% pull(prolif_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_topolink_res_prolif_ew_150sim = pr.curve(scores.class0 = pred_topolink_ew_bliss %&gt;% pull(prolif_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_topolink_res_ss_mw_50sim = pr.curve(scores.class0 = pred_topolink_mw_bliss %&gt;% pull(synergy_prob_ss_50sim), weights.class0 = pred_topolink_mw_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_topolink_res_ss_mw_150sim = pr.curve(scores.class0 = pred_topolink_mw_bliss %&gt;% pull(synergy_prob_ss_150sim), weights.class0 = pred_topolink_mw_bliss %&gt;% pull(observed), curve = TRUE) pr_topolink_res_prolif_mw_50sim = pr.curve(scores.class0 = pred_topolink_mw_bliss %&gt;% pull(synergy_prob_prolif_50sim), weights.class0 = pred_topolink_mw_bliss %&gt;% pull(observed), curve = TRUE) pr_topolink_res_prolif_mw_150sim = pr.curve(scores.class0 = pred_topolink_mw_bliss %&gt;% pull(synergy_prob_prolif_150sim), weights.class0 = pred_topolink_mw_bliss %&gt;% pull(observed), curve = TRUE) plot(pr_topolink_res_ss_ew_50sim, main = &#39;PR curve, Ensemble-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_topolink_res_ss_ew_150sim, add = TRUE, color = my_palette[2]) plot(pr_topolink_res_prolif_ew_50sim, add = TRUE, color = my_palette[3]) plot(pr_topolink_res_prolif_ew_150sim, add = TRUE, color = my_palette[4]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(pr_topolink_res_ss_ew_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_topolink_res_ss_ew_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_topolink_res_prolif_ew_50sim$auc.davis.goadrich, digits = 3), &quot;Random (50 sim)&quot;), paste(round(pr_topolink_res_prolif_ew_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) plot(pr_topolink_res_ss_mw_50sim, main = &#39;PR curve, Model-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_topolink_res_ss_mw_150sim, add = TRUE, color = my_palette[2]) plot(pr_topolink_res_prolif_mw_50sim, add = TRUE, color = my_palette[3]) plot(pr_topolink_res_prolif_mw_150sim, add = TRUE, color = my_palette[4]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(pr_topolink_res_ss_mw_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_topolink_res_ss_mw_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_topolink_res_prolif_mw_50sim$auc.davis.goadrich, digits = 3), &quot;Random (50 sim)&quot;), paste(round(pr_topolink_res_prolif_mw_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) Figure 55: PR curves (CASCADE 2.0, Link Operator and Topology Mutations, Bliss synergy method) The PR curves show that the performance of each individual predictor is poor compared to the baseline. The model-wise approach produces better ROC and PR results than the ensemble-wise approach (performance in terms of AUC value is almost doubled) AUC sensitivity Investigate same thing as described in here. This is very crucial since the PR performance is poor for the individual predictors, but a combined predictor might be able to counter this. We will combine the synergy scores from the random proliferative simulations with the results from the calibrated Gitsbe simulations (number of simulations: \\(150\\)). # Ensemble-wise betas = seq(from = -5, to = 5, by = 0.1) prolif_roc = sapply(betas, function(beta) { pred_topolink_ew_bliss = pred_topolink_ew_bliss %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = roc.curve(scores.class0 = pred_topolink_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_bliss %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr = sapply(betas, function(beta) { pred_topolink_ew_bliss = pred_topolink_ew_bliss %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = pr.curve(scores.class0 = pred_topolink_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_bliss %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_ew = as_tibble(cbind(betas, prolif_roc, prolif_pr)) df_ew = df_ew %&gt;% tidyr::pivot_longer(-betas, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, ylim = c(0,0.85), panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + geom_vline(xintercept = 0) + geom_vline(xintercept = -1, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_text(aes(x=-1.5, label=&quot;β = -1&quot;, y=0.35), colour=&quot;black&quot;, angle = 90) + grids() Figure 56: AUC sensitivity (CASCADE 2.0, Link Operator and Topology Mutations, Bliss synergy method, Ensemble-wise results) The random proliferative models can be used to normalize against the predictions of the calibrated models and thus bring significant contribution to the calibrated models performance (both ROC-AUC and PR-AUC are increased). The \\(\\beta_{best}\\) values of the combined calibrated and random model predictor that maximize the ROC-AUC and PR-AUC respectively are \\(\\beta_{best}^{\\text{ROC-AUC}}=-1.1\\) and \\(\\beta_{best}^{\\text{PR-AUC}}=-1.3\\). For \\(\\beta=-1\\) we still see significant performance improvement. Best ROC and PRC For both the Bliss and HSA ensemble-wise results we demonstrated above that a value of \\(\\beta_{best}=-1\\) can result in significant performance gain of the combined predictor (\\(calibrated + \\beta \\times random\\)). So, the best ROC and PR curves we can get with our simulations when using models with both link operator (balance) and topology mutations are: best_beta = -1 pred_topolink_ew_hsa = pred_topolink_ew_hsa %&gt;% mutate(best_score = ss_score_150sim + best_beta * prolif_score_150sim) pred_topolink_ew_bliss = pred_topolink_ew_bliss %&gt;% mutate(best_score = ss_score_150sim + best_beta * prolif_score_150sim) roc_best_res_hsa = get_roc_stats(df = pred_topolink_ew_hsa, pred_col = &quot;best_score&quot;, label_col = &quot;observed&quot;) roc_best_res_bliss = get_roc_stats(df = pred_topolink_ew_bliss, pred_col = &quot;best_score&quot;, label_col = &quot;observed&quot;) pr_best_res_hsa = pr.curve(scores.class0 = pred_topolink_ew_hsa %&gt;% pull(best_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_best_res_bliss = pr.curve(scores.class0 = pred_topolink_ew_bliss %&gt;% pull(best_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_bliss %&gt;% pull(observed), curve = TRUE) # Plot best ROCs plot(x = roc_best_res_hsa$roc_stats$FPR, y = roc_best_res_hsa$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = TeX(&#39;ROC curve (Ensemble-wise), $calibrated + \\\\beta \\\\times random$&#39;), xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = roc_best_res_bliss$roc_stats$FPR, y = roc_best_res_bliss$roc_stats$TPR, lwd = 3, col = my_palette[2]) legend(&#39;bottomright&#39;, title = TeX(&#39;AUC ($\\\\beta$ = -1)&#39;), col = c(my_palette[1:2]), pch = 19, cex = 1.5, legend = c(paste(round(roc_best_res_hsa$AUC, digits = 2), &#39;HSA (150 sim)&#39;), paste(round(roc_best_res_bliss$AUC, digits = 2), &#39;Bliss (150 sim)&#39;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) # Plot best PRCs plot(pr_best_res_hsa, main = TeX(&#39;PR curve (Ensemble-wise), $calibrated + \\\\beta \\\\times random$&#39;), auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_best_res_bliss, add = TRUE, color = my_palette[2]) legend(&#39;topright&#39;, title = TeX(&#39;AUC ($\\\\beta$ = -1)&#39;), col = c(my_palette[1:2]), pch = 19, cex = 1.5, legend = c(paste(round(pr_best_res_hsa$auc.davis.goadrich, digits = 2), &#39;HSA (150 sim)&#39;), paste(round(pr_best_res_bliss$auc.davis.goadrich, digits = 2), &#39;Bliss (150 sim)&#39;))) grid(lwd = 0.5) Figure 57: ROC and PR curve for best beta (CASCADE 2.0, Link Operator and Topology Mutations) "],["parameterization-vs-performance.html", "Parameterization vs Performance Best ROC and PRC Bootstrap Simulations", " Parameterization vs Performance Best ROC and PRC In this section we will compare the normalized combined predictors (\\(calibrated + \\beta \\times random, \\beta=-1\\)) across all 3 model parameterizations/mutations we tested in this report for CASCADE 2.0: link operator mutations, topology mutations and both. We use the normalization parameter \\(\\beta=-1\\) for all combined predictors, as it was observed throughout the report that it approximately maximizes the performance of all Bliss-assessed, ensemble-wise combined synergy predictors in terms of ROC and PR AUC. The results are from the \\(150\\) simulation runs (\\(450\\) models). Why call \\(\\beta\\) a normalization parameter? What matters for the calculation of the ROC and PR points is the ranking of the synergy scores. Thus if we bring the predictor’s synergy scores to the exponential space, a value of \\(-1\\) for \\(\\beta\\) translates to a simple fold-change normalization technique: \\(calibrated + \\beta \\times random \\overset{\\beta = -1}{=} calibrated - random \\xrightarrow[\\text{same ranking}]{e(x) \\text{ monotonous}}\\) \\(exp(calibrated - random)=exp(calibrated)/exp(random)\\). # Link operator mutations results (`best_score2` has the results for β = -1, `best_score1` for β = -1.6) roc_link_res = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;best_score2&quot;, label_col = &quot;observed&quot;) pr_link_res = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(best_score2) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) # Topology mutations results roc_topo_res = get_roc_stats(df = pred_topo_ew_bliss, pred_col = &quot;best_score&quot;, label_col = &quot;observed&quot;) pr_topo_res = pr.curve(scores.class0 = pred_topo_ew_bliss %&gt;% pull(best_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_bliss %&gt;% pull(observed), curve = TRUE) # Both Link Operator and Topology mutations results roc_topolink_res = get_roc_stats(df = pred_topolink_ew_bliss, pred_col = &quot;best_score&quot;, label_col = &quot;observed&quot;) pr_topolink_res = pr.curve(scores.class0 = pred_topolink_ew_bliss %&gt;% pull(best_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_bliss %&gt;% pull(observed), curve = TRUE) # Plot best ROCs plot(x = roc_link_res$roc_stats$FPR, y = roc_link_res$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = TeX(&#39;ROC curves (Ensemble-wise), $calibrated + \\\\beta \\\\times random$&#39;), xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = roc_topo_res$roc_stats$FPR, y = roc_topo_res$roc_stats$TPR, lwd = 2, col = my_palette[2]) lines(x = roc_topolink_res$roc_stats$FPR, y = roc_topolink_res$roc_stats$TPR, lwd = 2.3, col = my_palette[3]) legend(&#39;bottomright&#39;, title = TeX(&#39;AUC ($\\\\beta$ = -1): Mutations&#39;), col = c(my_palette[1:3]), pch = 19, cex = 1.5, legend = c(paste(round(roc_link_res$AUC, digits = 2), &#39;Link Operator&#39;), paste(round(roc_topo_res$AUC, digits = 2), &#39;Topology&#39;), paste(round(roc_topolink_res$AUC, digits = 2), &#39;Both&#39;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) # Plot best PRCs plot(pr_link_res, main = TeX(&#39;PR curves (Ensemble-wise), $calibrated + \\\\beta \\\\times random$&#39;), auc.main = FALSE, color = my_palette[1], rand.plot = TRUE, lwd = 3) plot(pr_topo_res, add = TRUE, color = my_palette[2], lwd = 2) plot(pr_topolink_res, add = TRUE, color = my_palette[3], lwd = 2.3) legend(&#39;topright&#39;, title = TeX(&#39;AUC ($\\\\beta$ = -1): Mutations&#39;), col = c(my_palette[1:3]), pch = 19, cex = 1.3, legend = c(paste(round(pr_link_res$auc.davis.goadrich, digits = 2), &#39;Link Operator&#39;), paste(round(pr_topo_res$auc.davis.goadrich, digits = 2), &#39;Topology&#39;), paste(round(pr_topolink_res$auc.davis.goadrich, digits = 2), &#39; Both&#39;))) grid(lwd = 0.5) Figure 58: Comparing ROC and PR curves for combined predictors across 3 parameterization schemes (CASCADE 2.0, Bliss synergy method, Ensemble-wise results) We observe that if we had used the results for the link operator only combined predictor with \\(\\beta_{best}=-1.6\\) as was demonstrated here, we would have an AUC-ROC of \\(0.85\\) and AUC-PR of \\(0.27\\), which are pretty close to the results we see above for \\(\\beta=-1\\), using both link and topology mutations. Overall, this suggests that to parameterize our boolean models using topology mutations can increase the performance of our proposed synergy prediction approach much more than using either link operator (balance) mutations alone or combined with topology parameterization. Note that the difference in terms of ROC AUC is not significant compared to the difference of PR AUC scores and since the dataset we test our models on is fairly imbalanced, we base our conclusion on the information from the PR plots (Saito and Rehmsmeier 2015). Bootstrap Simulations Now we would like to statistically verify the previous conclusion (that topology is superior to the other two parameterization schemes and produces better predictive models for our dataset) and so we will run a bootstrap analysis. Simply put, we generate 3 large pools of calibrated to steady state models (\\(4500\\) models each). Each pool corresponds to the 3 parameterization schemes (i.e. it has models with either topology mutations only, link-operator mutations only, or models with both mutations). Then, we take several model samples from each pool (\\(25\\) samples, each sample containing \\(300\\) models) and run the drug response simulations for these calibrated model ensembles to get their predictions. Normalizing each calibrated simulation prediction output to the corresponding random (proliferative) model predictions (using a \\(\\beta=-1\\) as above), results in different ROC and PR AUCs for each parameterization scheme and chosen bootstrapped sample. See more details on reproducing the results on section Parameterization Bootstrap. The following code is used to load the results from the simulations (we have already saved the result for convenience): # lo = &#39;link-operator mutations&#39;, topo = &#39;topology mutations&#39;, both = &#39;link-operator and topology mutations&#39; data_dir_lo = &quot;/home/john/tmp/ags-paper/parameterization-comp/link-only/&quot; data_dir_topo = &quot;/home/john/tmp/ags-paper/parameterization-comp/topology-only/&quot; data_dir_both = &quot;/home/john/tmp/ags-paper/parameterization-comp/topo-and-link/&quot; # define `beta` value for normalization beta = -1 # define data list that is going to store all results data_list = list() index = 1 ## Link-operator only Mutations # random model predictions random_ew_scores_file_lo = paste0(data_dir_lo, &quot;cascade_2.0_rand_150sim_fixpoints_bliss_20200505_063817/cascade_2.0_rand_150sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) random_ew_scores_lo = emba::get_synergy_scores(random_ew_scores_file_lo) # calibrated bootstrap data for (res_dir in list.dirs(paste0(data_dir_lo, &quot;boot_res&quot;), recursive = FALSE)) { # check only the simulation (not the `models_batch_*`) directories if (stringr::str_detect(string = res_dir, pattern = &quot;cascade_2.0_ss_bliss_batch&quot;)) { ew_synergies_file = list.files(path = res_dir, pattern = &quot;ensemblewise_synergies&quot;, full.names = TRUE) ss_ew_scores = emba::get_synergy_scores(ew_synergies_file) # calculate normalized model performance (ROC-AUC and PR-AUC) pred = dplyr::bind_cols( random_ew_scores_lo %&gt;% select(score) %&gt;% rename(random_score = score), ss_ew_scores %&gt;% select(score) %&gt;% rename(ss_score = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) # get the normalized synergy scores pred = pred %&gt;% mutate(combined_score = ss_score + beta * random_score) res_roc = PRROC::roc.curve(scores.class0 = pred %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred %&gt;% pull(observed)) res_pr = PRROC::pr.curve(scores.class0 = pred %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred %&gt;% pull(observed)) # bind all to one (OneForAll) df = dplyr::bind_cols(roc_auc = res_roc$auc, pr_auc = res_pr$auc.davis.goadrich, param = &quot;link-only&quot;) data_list[[index]] = df index = index + 1 } } ## Topology-only mutations # random model predictions random_ew_scores_file_topo = paste0(data_dir_topo, &quot;cascade_2.0_rand_150sim_fixpoints_bliss_20200429_023822/cascade_2.0_rand_150sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) random_ew_scores_topo = emba::get_synergy_scores(random_ew_scores_file_topo) # calibrated bootstrap data for (res_dir in list.dirs(paste0(data_dir_topo, &quot;boot_res&quot;), recursive = FALSE)) { # check only the simulation (not the `models_batch_*`) directories if (stringr::str_detect(string = res_dir, pattern = &quot;cascade_2.0_ss_bliss_batch&quot;)) { ew_synergies_file = list.files(path = res_dir, pattern = &quot;ensemblewise_synergies&quot;, full.names = TRUE) ss_ew_scores = emba::get_synergy_scores(ew_synergies_file) # calculate normalized model performance (ROC-AUC and PR-AUC) pred = dplyr::bind_cols( random_ew_scores_topo %&gt;% select(score) %&gt;% rename(random_score = score), ss_ew_scores %&gt;% select(score) %&gt;% rename(ss_score = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) # get the normalized synergy scores pred = pred %&gt;% mutate(combined_score = ss_score + beta * random_score) res_roc = PRROC::roc.curve(scores.class0 = pred %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred %&gt;% pull(observed)) res_pr = PRROC::pr.curve(scores.class0 = pred %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred %&gt;% pull(observed)) # bind all to one (OneForAll) df = dplyr::bind_cols(roc_auc = res_roc$auc, pr_auc = res_pr$auc.davis.goadrich, param = &quot;topology-only&quot;) data_list[[index]] = df index = index + 1 } } ## Both Link-operator and Topology mutations # random model predictions random_ew_scores_file_both = paste0(data_dir_both, &quot;cascade_2.0_rand_150sim_fixpoints_bliss_20200430_122450/cascade_2.0_rand_150sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) random_ew_scores_both = emba::get_synergy_scores(random_ew_scores_file_both) # calibrated bootstrap data for (res_dir in list.dirs(paste0(data_dir_both, &quot;boot_res&quot;), recursive = FALSE)) { # check only the simulation (not the `models_batch_*`) directories if (stringr::str_detect(string = res_dir, pattern = &quot;cascade_2.0_ss_bliss_batch&quot;)) { ew_synergies_file = list.files(path = res_dir, pattern = &quot;ensemblewise_synergies&quot;, full.names = TRUE) ss_ew_scores = emba::get_synergy_scores(ew_synergies_file) # calculate normalized model performance (ROC-AUC and PR-AUC) pred = dplyr::bind_cols( random_ew_scores_both %&gt;% select(score) %&gt;% rename(random_score = score), ss_ew_scores %&gt;% select(score) %&gt;% rename(ss_score = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) # get the normalized synergy scores pred = pred %&gt;% mutate(combined_score = ss_score + beta * random_score) res_roc = PRROC::roc.curve(scores.class0 = pred %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred %&gt;% pull(observed)) res_pr = PRROC::pr.curve(scores.class0 = pred %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred %&gt;% pull(observed)) # bind all to one (OneForAll) df = dplyr::bind_cols(roc_auc = res_roc$auc, pr_auc = res_pr$auc.davis.goadrich, param = &quot;topo-and-link&quot;) data_list[[index]] = df index = index + 1 } } res = bind_rows(data_list) saveRDS(res, file = &quot;results/res_param_boot_aucs.rds&quot;) Compare all 3 schemes # load the data res = readRDS(file = &quot;results/res_param_boot_aucs.rds&quot;) # define group comparisons for statistics my_comparisons = list(c(&quot;link-only&quot;,&quot;topology-only&quot;), c(&quot;link-only&quot;,&quot;topo-and-link&quot;), c(&quot;topology-only&quot;,&quot;topo-and-link&quot;)) # ROC AUCs ggboxplot(data = res, x = &quot;param&quot;, y = &quot;roc_auc&quot;, fill = &quot;param&quot;, add = &quot;jitter&quot;, palette = &quot;Set1&quot;, xlab = &quot;Parameterization&quot;, ylab = &quot;ROC AUC&quot;, title = &quot;Parameterization vs Performance (ROC)&quot;) + stat_compare_means(comparisons = my_comparisons, method = &quot;wilcox.test&quot;, label = &quot;p.format&quot;) + theme(plot.title = element_text(hjust = 0.5)) + theme(legend.position = &quot;none&quot;) # PR AUCs ggboxplot(data = res, x = &quot;param&quot;, y = &quot;pr_auc&quot;, fill = &quot;param&quot;, add = &quot;jitter&quot;, palette = &quot;Set1&quot;, xlab = &quot;Parameterization&quot;, ylab = &quot;PR AUC&quot;, title = &quot;Parameterization vs Performance (Precision-Recall)&quot;) + stat_compare_means(comparisons = my_comparisons, method = &quot;wilcox.test&quot;, label = &quot;p.format&quot;) + theme(plot.title = element_text(hjust = 0.5)) + theme(legend.position = &quot;none&quot;) Figure 59: Comparing ROC and PR AUCs from bootstrapped calibrated model ensembles normalized to random model predictions across 3 parameterization schemes (CASCADE 2.0, Bliss synergy method, Ensemble-wise results) The topology mutations generate the best performing models in terms of PR AUC with statistical significance compared to the other two groups of model ensembles using different parameterization. In terms of ROC AUC performance we also note the larger variance of the topology mutated models. Compare Topology vs Link-operator Parameterization # load the data res = readRDS(file = &quot;results/res_param_boot_aucs.rds&quot;) # filter data res = res %&gt;% filter(param != &quot;topo-and-link&quot;) param_comp = list(c(&quot;link-only&quot;,&quot;topology-only&quot;)) stat_test_roc = res %&gt;% rstatix::wilcox_test(formula = roc_auc ~ param, comparisons = param_comp) %&gt;% rstatix::add_significance(&quot;p&quot;) # ROC AUCs ggboxplot(res, x = &quot;param&quot;, y = &quot;roc_auc&quot;, fill = &quot;param&quot;, palette = &quot;Set1&quot;, add = &quot;jitter&quot;, xlab = &quot;&quot;, ylab = &quot;ROC AUC&quot;, title = &quot;Parameterization vs Performance (ROC)&quot;) + scale_x_discrete(breaks = c(&quot;link-only&quot;,&quot;topology-only&quot;), labels = c(&quot;Link-Operator Mutations&quot;, &quot;Edge Mutations&quot;)) + ggpubr::stat_pvalue_manual(stat_test_roc, label = &quot;p = {p} ({p.signif})&quot;, y.position = c(1)) + ylim(c(0.2,1)) + theme_classic(base_size = 14) + theme(plot.title = element_text(hjust = 0.5), axis.text = element_text(size = 14)) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 2.1, y = 0.45, label=&quot;Random Predictions (AUC = 0.5)&quot;)) + theme(legend.position = &quot;none&quot;) stat_test_pr = res %&gt;% rstatix::wilcox_test(formula = pr_auc ~ param, comparisons = param_comp) %&gt;% rstatix::add_significance(&quot;p&quot;) %&gt;% rstatix::add_y_position() # PR AUCs ggboxplot(res, x = &quot;param&quot;, y = &quot;pr_auc&quot;, fill = &quot;param&quot;, palette = &quot;Set1&quot;, add = &quot;jitter&quot;, xlab = &quot;&quot;, ylab = &quot;PR AUC&quot;, title = &quot;Parameterization vs Performance (Precision-Recall)&quot;) + scale_x_discrete(breaks = c(&quot;link-only&quot;,&quot;topology-only&quot;), labels = c(&quot;Link-Operator Mutations&quot;, &quot;Edge Mutations&quot;)) + ggpubr::stat_pvalue_manual(stat_test_pr, label = &quot;p = {p} ({p.signif})&quot;) + theme_classic(base_size = 14) + theme(plot.title = element_text(hjust = 0.5), axis.text = element_text(size = 14)) + geom_hline(yintercept = 6/153, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 2.15, y = 0.08, label=&quot;Random Predictions (AUC = 0.04)&quot;)) + theme(legend.position = &quot;none&quot;) Figure 60: Comparing ROC and PR AUCs from bootstrapped calibrated model ensembles normalized to random model predictions - Topology vs Link-operator mutations (CASCADE 2.0, Bliss synergy method, Ensemble-wise results) "],["reproduce-data-simulation-results.html", "Reproduce Data &amp; Simulation Results ROC and PR curves, Fitness Evolution2 Fitness vs Performance Methods Random Model Bootstrap Parameterization Bootstrap Repo results structure", " Reproduce Data &amp; Simulation Results ROC and PR curves, Fitness Evolution2 Install the druglogics-synergy module and use the version 1.2.0: git checkout v1.2.0 Run the script run_druglogics_synergy.sh in the above repo. You can of course change several other parameters in the input files or the script itself (e.g. number of simulations to run - see here for a complete list of configuration options). To get the results for the topology mutations for CASCADE 2.0 you need to change the ags_cascade_2.0/config file option topology_mutations: 10 and balance_mutations: 0 (the default options are \\(0\\) topology mutations and \\(3\\) link-operator/balance mutations). If you wish to get the results using both kinds of mutation, set both topology_mutations and balance_mutations options to a non-zero value (\\(10\\) and \\(3\\) were used in the simulations). So, for example to get the simulation output directories for the Cascade 1.0 Analysis I just run the run_druglogics_synergy.sh script with the following options defined in the loops inside (no need to change any further configuration): cascade_version: 1.0 (which topology to use) train: ss rand (train to the AGS steady state or to a (random) proliferation phenotype)) sim_num: 50 (number of simulations) attr_tool: fixpoints (attractor tool, common across all report) synergy_method: hsa bliss (synergy calculation method used by drabme) Each subsequent druglogics-synergy execution results in an output directory and the files of interest (which are used to produce the ROC and PR curves in this report and the AUC sensitivity figures) are the modelwise_synergies.tab and the ensemble_synergies.tab respectively. For the fitness evolution figures we used the summary.txt file of the corresponding simulations. For the stable state and parameterization heatmaps we used the directory output with all the gitsbe generated models (\\(150\\) simulations, bliss synergy method, calibrated models, using the CASCADE 2.0 topology), as well as the AGS training steady state file. We have stored all the simulations results in an open-access repository provided by Zenodo: Specifically, the results described above are stored in the compressed file sim_res.tar.gz. When uncompressed, the sim_res.tar.gz file outputs 2 separate directories, one per different topology (CASCADE 1.0 and CASCADE 2.0). The directory with the CASCADE 2.0 related results has 3 subsequent directories, corresponding to the different parameterization that was used in the simulations (link mutations, topology mutations or both). Each further directory, specifies on its name the training type, simulation number, attractor tool and synergy assessment method. Fitness vs Performance Methods Generate the training data samples Use the gen_training_data.R script to produce the training data samples. In this script we first choose \\(11\\) numbers that represent the number of nodes that are going to be flipped in the AGS steady state. These numbers range from \\(1\\) (flip just one node) to \\(24\\) (flip all nodes, i.e. create a complete reversed steady state). Then, for each such number, we generate \\(20\\) new partially correct steady states, each one having the same amount of randomly-chosen flips in the steady state (e.g. \\(20\\) steady states where randomly-chosen sets of \\(3\\) nodes have been flipped). Thus, in total, \\(205\\) training data sample files are produced (\\(205 = 9 \\times 20 + 1 \\times 24 + 1 \\times 1\\), where from the \\(11\\) number of flips, the one flip happens for every node (\\(24\\) different steady states) and flipping all the nodes generates the unique completely reversed steady state). The training data files are stored in the Zenodo file training-data-files.tar.gz Run model ensembles simulations To generate the calibrated model ensembles and perform the drug response analysis on them we use the script run_druglogics_synergy_training.sh from the druglogics-synergy repository root (version 1.2.0: git checkout v1.2.0). Note that the training-data-files directory must be placed inside the druglogics-synergy/ags_cascade_2.0 directory before executing the aforementioned script. The end result we get is the simulation results for each of the training data files. The following changes need to be applied to the CASCADE 2.0 configuration file (druglogics-synergy/ags_cascade_2.0/config) before executing the script: If topology mutations are used, disable the balance mutations (balance_mutations: 0) and use topology_mutations: 10. Change the number of simulations to \\(20\\) (balance mutations) or to \\(50\\) for the topology mutated models. Change to Bliss synergy method (synergy_method: bliss) no matter the mutations used. The results of these simulations (when applying link-operator mutations) are stored in the Zenodo file fit-vs-performance-results-bliss.tar.gz, whereas when topology mutations are used, in the fit-vs-performance-results-bliss-topo.tar.gz file Also, we used the run_druglogics_synergy.sh script at the root of the druglogics-synergy (script config: {2.0, prolif, 150, fixpoints, bliss}) repo to get the ensemble results of the random (proliferative) models that we will use to normalize the calibrated model performance. The result of this simulation is also part of the results described above (see section above, also considering the necessary changes applied for the topology mutations-based simulations) and it’s available at the file sim_res.tar.gz in the Zenodo dataset . Random Model Bootstrap Install the druglogics-synergy module and use the version 1.2.0: git checkout v1.2.0 Run the the script run_gitsbe_random.sh inside the ags_cascade_2.0 directory of the druglogics-synergy repository. This creates a results directory which includes a models directory, with a total of \\(3000\\) gitsbe models which we are going to use for the bootstrapping. Place the models directory inside the ags_cascade_2.0 directory. Execute the bootstrap_models_drabme.sh inside the druglogics-synergy/ags_cascade_2.0 directory. Changing appropriately the config file to have synergy_method: bliss. The bootstrap configuration consists of \\(20\\) batches, each one consisting of a sample of \\(100\\) randomly selected models from the model directory pool. The results of the simulations executed via the above scripts are all stored in the random_model_bootstrap.tar.gz file of the Zenodo dataset . Parameterization Bootstrap Install the druglogics-synergy module and use the version 1.2.0: git checkout v1.2.0 To generate the \\(3\\) pools of calibrated models (fitting to the AGS steady state) subject to different normalization schemes, run the script run_gitsbe_param.sh inside the ags_cascade_2.0 directory of the druglogics-synergy repository root. This will generate the directories: gitsbe_link_only_cascade_2.0_ss gitsbe_topology_only_cascade_2.0_ss gitsbe_topo_and_link_cascade_2.0_ss, each of which have a models directory (the model pool) Repeat for each different pool (models directory): Place the models directory inside the ags_cascade_2.0 directory of the druglogics-synergy repository root. Use the bootstrap_models_drabme.sh script, while changing the following configuration: batches=25, batch_size=300 and the project variable name (input to eu.druglogics.drabme.Launcher) as one of the three: --project=link_only_cascade_2.0_ss_bliss_batch_${batch} --project=topology_only_cascade_2.0_ss_bliss_batch_${batch} --project=topo_and_link_cascade_2.0_ss_bliss_batch_${batch} , depending on the parameterization scheme that was used in the previous step to produce the models pool. The results of all these simulations are stored in the parameterization-comp.tar.gz file . When uncompressed, the parameterization-comp.tar.gz file outputs 3 separate directories, one per parameterization scheme. Each separate directory is structured so as to contain the gitsbe simulation results with the model pool inside (result of the script run_gitsbe_param.sh), a boot_res directory (includes the results of the bootstrap_models_drabme.sh script) and lastly the results of the random proliferative model simulations which can be reproduced following the guidelines above. Repo results structure We have gathered all the necessary output files from the above simulations (mostly relating to ROC, PR curves and AUC sensitivity figures) to the directory results for ease of use in our report. The results directory has 3 main sub-directories: link-only: results from the link-operator mutated models only (used in the sections Cascade 1.0 Analysis and CASCADE 2.0 Analysis (Link Operator Mutations)) topology-only: results from the topology-mutated models only (used in the section CASCADE 2.0 Analysis (Topology Mutations)) topo-and-link: results where both mutations applied to the generated boolean models (used in section CASCADE 2.0 Analysis (Topology and Link Operator Mutations)) Also, the results directory includes the following files/directories: observed_synergies_cascade_1.0: the gold-standard synergies for the CASCADE 1.0 topology (Flobak et al. 2015) observed_synergies_cascade_2.0: the gold-standard synergies for the CASCADE 2.0 topology (Flobak et al. 2019) steadystate: the AGS training data for the calibrated models bootstrap_rand_res.rds: a compressed file with a tibble object having the result data in a tidy format for the analysis related to the Bootstrap Random Model AUC section. res_fit_aucs.rds: a compressed file with a tibble object having the result data in a tidy format for the analysis related to the Fitness vs Ensemble Performance section (link operator mutations). res_fit_aucs_topo.rds: a compressed file with a tibble object having the result data in a tidy format for the analysis related to the Fitness vs Ensemble Performance section (topology mutations). res_param_boot_aucs.rds: a compressed file with a tibble object having the result data in a tidy format for the analysis related to the Bootstrap Simulations section. scrambled_topologies: a directory with a compressed file (scrambled_topologies.tar.gz), which includes all the topology .sif files generated by the script gen_scrambled_topologies.R The AUC sensitivity plots across the report are also included↩︎ "],["r-session-info.html", "R session info", " R session info xfun::session_info() R version 3.6.3 (2020-02-29) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 20.04.1 LTS Locale: LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C Package version: abind_1.4-5 assertthat_0.2.1 backports_1.1.10 base64enc_0.1.3 BH_1.72.0.3 bookdown_0.21 boot_1.3.25 broom_0.7.2 callr_3.5.1 car_3.0-10 carData_3.0-4 cellranger_1.1.0 circlize_0.4.10 Ckmeans.1d.dp_4.3.3 cli_2.1.0 clipr_0.7.1 clue_0.3-57 cluster_2.1.0 codetools_0.2-16 colorspace_1.4-1 compiler_3.6.3 ComplexHeatmap_2.2.0 conquer_1.0.2 corrplot_0.84 cowplot_1.1.0 cpp11_0.2.3 crayon_1.3.4 crosstalk_1.1.0.1 curl_4.3 data.table_1.13.2 desc_1.2.0 digest_0.6.26 dplyr_1.0.2 DT_0.16 ellipsis_0.3.1 emba_0.1.8 equatiomatic_0.1.0 evaluate_0.14 fansi_0.4.1 farver_2.0.3 forcats_0.5.0 foreach_1.5.1 foreign_0.8-75 gbRd_0.4-11 generics_0.0.2 GetoptLong_1.0.4 ggplot2_3.3.2 ggpubr_0.4.0 ggrepel_0.8.2 ggsci_2.9 ggsignif_0.6.0 glmnet_4.0-2 GlobalOptions_0.1.2 glue_1.4.2 graphics_3.6.3 grDevices_3.6.3 grid_3.6.3 gridExtra_2.3 gtable_0.3.0 haven_2.3.1 highr_0.8 hms_0.5.3 htmltools_0.5.0 htmlwidgets_1.5.2 igraph_1.2.6 isoband_0.2.2 iterators_1.0.13 jsonlite_1.7.1 knitr_1.30 labeling_0.4.2 later_1.1.0.1 latex2exp_0.4.0 lattice_0.20-41 lazyeval_0.2.2 lifecycle_0.2.0 lme4_1.1.25 magrittr_1.5 MAMSE_0.2-1 maptools_1.0.2 markdown_1.1 MASS_7.3.53 Matrix_1.2-18 MatrixModels_0.4.1 matrixStats_0.57.0 methods_3.6.3 mgcv_1.8.33 mime_0.9 minqa_1.2.4 munsell_0.5.0 nlme_3.1.149 nloptr_1.2.2.2 nnet_7.3.14 openxlsx_4.2.2 parallel_3.6.3 pbkrtest_0.4.8.6 pillar_1.4.6 pkgbuild_1.1.0 pkgconfig_2.0.3 pkgload_1.1.0 png_0.1-7 polynom_1.4.0 praise_1.0.0 prettyunits_1.1.1 processx_3.4.4 progress_1.2.2 promises_1.1.1 PRROC_1.3.1 ps_1.4.0 purrr_0.3.4 quantreg_5.74 R6_2.4.1 rbibutils_1.3 RColorBrewer_1.1-2 Rcpp_1.0.5 RcppArmadillo_0.10.1.0.0 RcppEigen_0.3.3.7.0 Rdpack_2.0 readr_1.4.0 readxl_1.3.1 rematch_1.0.1 rio_0.5.16 rje_1.10.16 rjson_0.2.20 rlang_0.4.8 rmarkdown_2.5 rprojroot_1.3.2 rstatix_0.6.0 rstudioapi_0.11 scales_1.1.1 shape_1.4.5 sp_1.4.4 SparseM_1.78 splines_3.6.3 statmod_1.4.35 stats_3.6.3 stringi_1.5.3 stringr_1.4.0 survival_3.2-7 testthat_2.3.2 tibble_3.0.4 tidyr_1.1.2 tidyselect_1.1.0 tinytex_0.26 tools_3.6.3 usefun_0.4.8 utf8_1.1.4 utils_3.6.3 vctrs_0.3.4 viridisLite_0.3.0 visNetwork_2.0.9 withr_2.3.0 xfun_0.18 xml2_1.3.2 yaml_2.2.1 zip_2.1.1 "],["references.html", "References", " References Flobak, Åsmund, Anaïs Baudot, Elisabeth Remy, Liv Thommesen, Denis Thieffry, Martin Kuiper, and Astrid Lægreid. 2015. “Discovery of Drug Synergies in Gastric Cancer Cells Predicted by Logical Modeling.” Edited by Ioannis Xenarios. PLOS Computational Biology 11 (8): e1004426. https://doi.org/10.1371/journal.pcbi.1004426. Flobak, Åsmund, Barbara Niederdorfer, Vu To Nakstad, Liv Thommesen, Geir Klinkenberg, and Astrid Lægreid. 2019. “A high-throughput drug combination screen of targeted small molecule inhibitors in cancer cell lines.” Scientific Data 6 (1): 237. https://doi.org/10.1038/s41597-019-0255-7. Friedman, Jerome, Trevor Hastie, Rob Tibshirani, Balasubramanian Narasimhan, Kenneth Tay, and Noah Simon. 2020. Glmnet: Lasso and Elastic-Net Regularized Generalized Linear Models. https://CRAN.R-project.org/package=glmnet. Grau, Jan, Ivo Grosse, and Jens Keilwagen. 2015. “PRROC: computing and visualizing precision-recall and receiver operating characteristic curves in R.” Bioinformatics 31 (15): 2595–7. https://doi.org/10.1093/bioinformatics/btv153. Gu, Zuguang, Roland Eils, and Matthias Schlesner. 2016. “Complex heatmaps reveal patterns and correlations in multidimensional genomic data.” Bioinformatics 32 (18): 2847–9. https://doi.org/10.1093/bioinformatics/btw313. Holland, John Henry. 1992. Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence. MIT press. Pepe, M. S. 2000. “Combining diagnostic test results to increase accuracy.” Biostatistics 1 (2): 123–40. https://doi.org/10.1093/biostatistics/1.2.123. Plante, Jean-Francois. 2017. MAMSE: Calculation of Minimum Averaged Mean Squared Error (Mamse) Weights. https://CRAN.R-project.org/package=MAMSE. Saito, Takaya, and Marc Rehmsmeier. 2015. “The Precision-Recall Plot Is More Informative than the ROC Plot When Evaluating Binary Classifiers on Imbalanced Datasets.” Edited by Guy Brock. PLOS ONE 10 (3): e0118432. https://doi.org/10.1371/journal.pone.0118432. Zobolas, John. 2020a. Rtemps: R Templates for Reproducible Data Analyses. https://github.com/bblodfon/rtemps. ———. 2020b. usefun: A Collection of Useful Functions by John. https://github.com/bblodfon/usefun. Zobolas, John, Martin Kuiper, and Åsmund Flobak. 2020. “Emba: R Package for Analysis and Visualization of Biomarkers in Boolean Model Ensembles.” Journal of Open Source Software 5 (53): 2583. https://doi.org/10.21105/joss.02583. "]]

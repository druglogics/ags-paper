[
["main.html", "AGS paper I simulation results Intro Input Cascade 1.0 Analysis Calibrated vs Random (HSA) Calibrated vs Random (Bliss) Correlation (ensemblewise vs modelwise) Fitness Evolution Cascade 2.0 Analysis Calibrated vs Random (HSA) Calibrated vs Random (Bliss) Fitness vs performance Reproduce simulation results ROC curves Random model results R session info References", " AGS paper I simulation results John Zobolas Last updated: 24 April, 2020 Intro This report has the AGS-Paper I data analysis and resulting figures. Input Loading libraries: library(DT) library(ggpubr) library(RColorBrewer) library(xfun) library(dplyr) library(tibble) library(emba) library(usefun) library(readr) library(stringr) library(latex2exp) Cascade 1.0 Analysis Performance of automatically parameterized models against published data in (Flobak et al. 2015) Calibrated vs Random (HSA) HSA refers to the synergy method used in Drabme to assess the synergies from Gitsbe We test performance using ROC AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state Random models: produced via abmlog (see here and used in Drabme with synergy_method: hsa Load results: # &#39;ss&#39; =&gt; calibrated models, &#39;random&#39; =&gt; random models ## HSA results ss_hsa_ensemblewise_file = paste0(&quot;results/hsa/cascade_1.0_ss_50sim_fixpoints_ensemblewise_synergies.tab&quot;) ss_hsa_modelwise_file = paste0(&quot;results/hsa/cascade_1.0_ss_50sim_fixpoints_modelwise_synergies.tab&quot;) random_hsa_ensemblewise_file = paste0(&quot;results/hsa/cascade_1.0_random_ensemblewise_synergies.tab&quot;) random_hsa_modelwise_file = paste0(&quot;results/hsa/cascade_1.0_random_modelwise_synergies.tab&quot;) ss_hsa_ensemblewise_synergies = emba::get_synergy_scores(ss_hsa_ensemblewise_file) ss_hsa_modelwise_synergies = emba::get_synergy_scores(ss_hsa_modelwise_file, file_type = &quot;modelwise&quot;) random_hsa_ensemblewise_synergies = emba::get_synergy_scores(random_hsa_ensemblewise_file) random_hsa_modelwise_synergies = emba::get_synergy_scores(random_hsa_modelwise_file, file_type = &quot;modelwise&quot;) # calculate probability of synergy in the modelwise results ss_hsa_modelwise_synergies = ss_hsa_modelwise_synergies %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) random_hsa_modelwise_synergies = random_hsa_modelwise_synergies %&gt;% mutate(synergy_prob_random = synergies/(synergies + `non-synergies`)) observed_synergies_file = paste0(&quot;results/observed_synergies_cascade_1.0&quot;) observed_synergies = get_observed_synergies(observed_synergies_file) # 1 (positive/observed synergy) or 0 (negative/not observed) for all tested drug combinations observed = sapply(random_hsa_modelwise_synergies$perturbation %in% observed_synergies, as.integer) ROC curves # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; model-wise pred_ew_hsa = bind_cols(ss_hsa_ensemblewise_synergies %&gt;% rename(ss_score = score), random_hsa_ensemblewise_synergies %&gt;% select(score) %&gt;% rename(random_score = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_mw_hsa = bind_cols( ss_hsa_modelwise_synergies %&gt;% select(perturbation, synergy_prob_ss), random_hsa_modelwise_synergies %&gt;% select(synergy_prob_random), as_tibble_col(observed, column_name = &quot;observed&quot;)) res_ss_ew = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;ss_score&quot;, label_col = &quot;observed&quot;) res_random_ew = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;random_score&quot;, label_col = &quot;observed&quot;) res_ss_mw = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_ss&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_random_mw = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_random&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs my_palette = RColorBrewer::brewer.pal(n = 9, name = &quot;Set1&quot;) plot(x = res_ss_ew$roc_stats$FPR, y = res_ss_ew$roc_stats$TPR, type = &#39;l&#39;, lwd = 2, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_random_ew$roc_stats$FPR, y = res_random_ew$roc_stats$TPR, lwd = 2, col = my_palette[2]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, legend = c(paste(round(res_ss_ew$AUC, digits = 3), &quot;Calibrated&quot;), paste(round(res_random_ew$AUC, digits = 3), &quot;Random&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;#FF726F&#39;, lty = 2) plot(x = res_ss_mw$roc_stats$FPR, y = res_ss_mw$roc_stats$TPR, type = &#39;l&#39;, lwd = 2, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_random_mw$roc_stats$FPR, y = res_random_mw$roc_stats$TPR, lwd = 2, col = my_palette[2]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, legend = c(paste(round(res_ss_mw$AUC, digits = 3), &quot;Calibrated&quot;), paste(round(res_random_mw$AUC, digits = 3), &quot;Random&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;#FF726F&#39;, lty = 2) ROC AUC sensitivity Investigate combining the synergy results of calibrated and random models How information from the ‘random’ models is augmenting calibrated (to steady state) results? Ensemble-wise scenario: \\(score = calibrated + \\beta \\times random\\) \\(\\beta \\rightarrow +\\infty\\): mostly random model predictions \\(\\beta \\rightarrow -\\infty\\): mostly reverse random model predictions Model-wise scenario: \\((1-w) \\times prob_{ss} + w \\times prob_{rand}, w \\in[0,1]\\) \\(w=0\\): only calibrated model predictions \\(w=1\\): only random model predictions # Ensemble-wise betas = seq(from = -20, to = 20, by = 0.1) auc_values_ew = sapply(betas, function(beta) { pred_ew_hsa = pred_ew_hsa %&gt;% mutate(combined_score = ss_score + beta * random_score) res = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;combined_score&quot;, label_col = &quot;observed&quot;) auc_value = res$AUC }) df_ew = as_tibble(cbind(betas, auc_values_ew)) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;auc_values_ew&quot;, numeric.x.axis = TRUE, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under ROC Curve)&quot;, title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter: $calibrated + \\\\beta \\\\times random$&quot;), color = my_palette[2]) + geom_vline(xintercept = 0) + grids() # Model-wise weights = seq(from = 0, to = 1, by = 0.05) auc_values_mw = sapply(weights, function(w) { pred_mw_hsa = pred_mw_hsa %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_hsa$synergy_prob_ss + w * pred_mw_hsa$synergy_prob_random) res = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;weighted_prob&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) auc_value = res$AUC }) df_mw = as_tibble(cbind(weights, auc_values_mw)) ggline(data = df_mw, x = &quot;weights&quot;, y = &quot;auc_values_mw&quot;, numeric.x.axis = TRUE, plot_type = &quot;l&quot;, xlab = TeX(&quot;weight $w$&quot;), ylab = &quot;AUC (Area Under ROC Curve)&quot;, title = TeX(&quot;AUC sensitivity to weighted average score: $(1-w) \\\\times prob_{ss} + w \\\\times prob_{rand}$&quot;), color = my_palette[3]) + grids() Symmetricity (Ensemble-wise): \\(AUC_{\\beta \\rightarrow +\\infty} + AUC_{\\beta \\rightarrow -\\infty} \\approx 1\\) Random models perform worse than calibrated ones There are \\(\\beta\\) values that can boost the predictive performance of the combined synergy classifier but no \\(w\\) weight in the model-wise case Calibrated vs Random (Bliss) Bliss refers to the synergy method used in Drabme to assess the synergies from Gitsbe We test performance using ROC AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state Random models: produced via abmlog (see here and used in Drabme with synergy_method: bliss Load results: # &#39;ss&#39; =&gt; calibrated models, &#39;random&#39; =&gt; random models ## Bliss results ss_bliss_ensemblewise_file = paste0(&quot;results/bliss/cascade_1.0_ss_50sim_fixpoints_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_file = paste0(&quot;results/bliss/cascade_1.0_ss_50sim_fixpoints_modelwise_synergies.tab&quot;) random_bliss_ensemblewise_file = paste0(&quot;results/bliss/cascade_1.0_random_bliss_ensemblewise_synergies.tab&quot;) random_bliss_modelwise_file = paste0(&quot;results/bliss/cascade_1.0_random_bliss_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_synergies = emba::get_synergy_scores(ss_bliss_ensemblewise_file) ss_bliss_modelwise_synergies = emba::get_synergy_scores(ss_bliss_modelwise_file, file_type = &quot;modelwise&quot;) random_bliss_ensemblewise_synergies = emba::get_synergy_scores(random_bliss_ensemblewise_file) random_bliss_modelwise_synergies = emba::get_synergy_scores(random_bliss_modelwise_file, file_type = &quot;modelwise&quot;) # calculate probability of synergy in the modelwise results ss_bliss_modelwise_synergies = ss_bliss_modelwise_synergies %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) random_bliss_modelwise_synergies = random_bliss_modelwise_synergies %&gt;% mutate(synergy_prob_random = synergies/(synergies + `non-synergies`)) ROC curves # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; model-wise pred_ew_bliss = bind_cols(ss_bliss_ensemblewise_synergies %&gt;% rename(ss_score = score), random_bliss_ensemblewise_synergies %&gt;% select(score) %&gt;% rename(random_score = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_mw_bliss = bind_cols( ss_bliss_modelwise_synergies %&gt;% select(perturbation, synergy_prob_ss), random_bliss_modelwise_synergies %&gt;% select(synergy_prob_random), as_tibble_col(observed, column_name = &quot;observed&quot;)) res_ss_ew = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score&quot;, label_col = &quot;observed&quot;) res_random_ew = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;random_score&quot;, label_col = &quot;observed&quot;) res_ss_mw = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_random_mw = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_random&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs plot(x = res_ss_ew$roc_stats$FPR, y = res_ss_ew$roc_stats$TPR, type = &#39;l&#39;, lwd = 2, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_random_ew$roc_stats$FPR, y = res_random_ew$roc_stats$TPR, lwd = 2, col = my_palette[2]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, legend = c(paste(round(res_ss_ew$AUC, digits = 3), &quot;Calibrated&quot;), paste(round(res_random_ew$AUC, digits = 3), &quot;Random&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;#FF726F&#39;, lty = 2) plot(x = res_ss_mw$roc_stats$FPR, y = res_ss_mw$roc_stats$TPR, type = &#39;l&#39;, lwd = 2, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_random_mw$roc_stats$FPR, y = res_random_mw$roc_stats$TPR, lwd = 2, col = my_palette[2]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, legend = c(paste(round(res_ss_mw$AUC, digits = 3), &quot;Calibrated&quot;), paste(round(res_random_mw$AUC, digits = 3), &quot;Random&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;#FF726F&#39;, lty = 2) ROC AUC sensitivity Investigate same thing as described in here. # Ensemble-wise betas = seq(from = -20, to = 20, by = 0.1) auc_values_ew = sapply(betas, function(beta) { pred_ew_bliss = pred_ew_bliss %&gt;% mutate(combined_score = ss_score + beta * random_score) res = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;combined_score&quot;, label_col = &quot;observed&quot;) auc_value = res$AUC }) df_ew = as_tibble(cbind(betas, auc_values_ew)) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;auc_values_ew&quot;, numeric.x.axis = TRUE, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under ROC Curve)&quot;, title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter: $calibrated + \\\\beta \\\\times random$&quot;), color = my_palette[2]) + geom_vline(xintercept = 0) + grids() # Model-wise weights = seq(from = 0, to = 1, by = 0.05) auc_values_mw = sapply(weights, function(w) { pred_mw_bliss = pred_mw_bliss %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_bliss$synergy_prob_ss + w * pred_mw_bliss$synergy_prob_random) res = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;weighted_prob&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) auc_value = res$AUC }) df_mw = as_tibble(cbind(weights, auc_values_mw)) ggline(data = df_mw, x = &quot;weights&quot;, y = &quot;auc_values_mw&quot;, numeric.x.axis = TRUE, plot_type = &quot;l&quot;, xlab = TeX(&quot;weight $w$&quot;), ylab = &quot;AUC (Area Under ROC Curve)&quot;, title = TeX(&quot;AUC sensitivity to weighted average score: $(1-w) \\\\times prob_{ss} + w \\\\times prob_{rand}$&quot;), color = my_palette[3]) + grids() Symmetricity (Ensemble-wise): \\(AUC_{\\beta \\rightarrow +\\infty} + AUC_{\\beta \\rightarrow -\\infty} \\approx 1\\) Random models perform worse than calibrated ones There are \\(\\beta\\) values that can boost the predictive performance of the combined synergy classifier but no \\(w\\) weight in the model-wise case Correlation (ensemblewise vs modelwise) data_hsa = bind_cols(as_tibble(1 - normalize_to_range(pred_ew_hsa$ss_score)), pred_mw_hsa %&gt;% select(synergy_prob_ss)) colnames(data_hsa) = c(&quot;ensemblewise&quot;, &quot;modelwise&quot;) ggscatter(data = data_hsa, x = &quot;ensemblewise&quot;, y = &quot;modelwise&quot;, add = &quot;reg.line&quot;, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), title = &quot;Correlation (Ensemble-wise vs Model-wise results, HSA)&quot;, conf.int = TRUE, cor.coef = TRUE, cor.coeff.args = list(method = &quot;pearson&quot;)) data_bliss = bind_cols(as_tibble(1 - normalize_to_range(pred_ew_bliss$ss_score)), pred_mw_bliss %&gt;% select(synergy_prob_ss)) colnames(data_bliss) = c(&quot;ensemblewise&quot;, &quot;modelwise&quot;) ggscatter(data = data_bliss, x = &quot;ensemblewise&quot;, y = &quot;modelwise&quot;, add = &quot;reg.line&quot;, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), title = &quot;Correlation (Ensemble-wise vs Model-wise results, Bliss)&quot;, conf.int = TRUE, cor.coef = TRUE, cor.coeff.args = list(method = &quot;pearson&quot;)) No strong correlation Lots of \\(0\\)’s modelwise + small number of tested perturbations affect the correlation Fitness Evolution Results are from the simulation result with \\(50\\) Gitsbe simulations, fitting to steady state (calibrated models) and HSA Drabme synergy assessment. We show only \\(10\\) simulations - the first ones that spanned the maximum defined generations in the configuration (\\(20\\)), meaning that they did not surpass the target fitness threhold specified (\\(0.99\\)). Each data point is the average fitness in that generation out of \\(20\\) models. fitness_summary_file = paste0(&quot;results/hsa/cascade_1.0_ss_50sim_fixpoints_summary.txt&quot;) read_summary_file = function(file_name) { lines = readr::read_lines(file = fitness_summary_file, skip = 5, skip_empty_rows = TRUE) data_list = list() index = 1 gen_fit_list = list() gen_index = 1 for (line_index in 1:length(lines)) { line = lines[line_index] if (stringr::str_detect(string = line, pattern = &quot;Simulation&quot;)) { data_list[[index]] = bind_cols(gen_fit_list) index = index + 1 gen_fit_list = list() gen_index = 1 } else { # read fitness values gen_fit_list[[gen_index]] = as_tibble_col(as.numeric(unlist(strsplit(line, split = &#39;\\t&#39;)))) gen_index = gen_index + 1 } } # add the last simulation&#39;s values data_list[[index]] = bind_cols(gen_fit_list) return(data_list) } fit_res = read_summary_file(file_name = fitness_summary_file) first_sim_data = colMeans(fit_res[[1]]) plot(1:length(first_sim_data), y = first_sim_data, ylim = c(0,1), xlim = c(0,20), type = &#39;l&#39;, lwd = 1.5, main = &#39;Fitness vs Generation (10 Simulations)&#39;, xlab = &#39;Generations&#39;, ylab = &#39;Average Fitness&#39;, col = usefun:::colors.100[1]) index = 2 for (fit_data in fit_res) { if (index &gt; 10) break if (ncol(fit_data) != 20) next mean_fit_per_gen = colMeans(fit_data) lines(x = 1:length(mean_fit_per_gen), y = mean_fit_per_gen, lwd = 1.5, col = usefun:::colors.100[index]) index = index + 1 } grid(lwd = 0.5) Cascade 2.0 Analysis Performance of automatically parameterized models against a new dataset (SINTEF, AGS only) Calibrated vs Random (HSA) HSA refers to the synergy method used in Drabme to assess the synergies from Gitsbe We test performance using ROC AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state Random models: produced via abmlog (see here and used in Drabme with synergy_method: hsa Load results: # &#39;ss&#39; =&gt; calibrated models, &#39;random&#39; =&gt; random models ## HSA results ss_hsa_ensemblewise_5sim_file = paste0(&quot;results/hsa/cascade_2.0_ss_5sim_fixpoints_ensemblewise_synergies.tab&quot;) ss_hsa_modelwise_5sim_file = paste0(&quot;results/hsa/cascade_2.0_ss_5sim_fixpoints_modelwise_synergies.tab&quot;) ss_hsa_ensemblewise_50sim_file = paste0(&quot;results/hsa/cascade_2.0_ss_50sim_fixpoints_ensemblewise_synergies.tab&quot;) ss_hsa_modelwise_50sim_file = paste0(&quot;results/hsa/cascade_2.0_ss_50sim_fixpoints_modelwise_synergies.tab&quot;) random_hsa_ensemblewise_file = paste0(&quot;results/hsa/cascade_2.0_random_ensemblewise_synergies.tab&quot;) random_hsa_modelwise_file = paste0(&quot;results/hsa/cascade_2.0_random_modelwise_synergies.tab&quot;) ss_hsa_ensemblewise_synergies_5sim = emba::get_synergy_scores(ss_hsa_ensemblewise_5sim_file) ss_hsa_modelwise_synergies_5sim = emba::get_synergy_scores(ss_hsa_modelwise_5sim_file, file_type = &quot;modelwise&quot;) ss_hsa_ensemblewise_synergies_50sim = emba::get_synergy_scores(ss_hsa_ensemblewise_50sim_file) ss_hsa_modelwise_synergies_50sim = emba::get_synergy_scores(ss_hsa_modelwise_50sim_file, file_type = &quot;modelwise&quot;) random_hsa_ensemblewise_synergies = emba::get_synergy_scores(random_hsa_ensemblewise_file) random_hsa_modelwise_synergies = emba::get_synergy_scores(random_hsa_modelwise_file, file_type = &quot;modelwise&quot;) # calculate probability of synergy in the modelwise results ss_hsa_modelwise_synergies_5sim = ss_hsa_modelwise_synergies_5sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_hsa_modelwise_synergies_50sim = ss_hsa_modelwise_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) random_hsa_modelwise_synergies = random_hsa_modelwise_synergies %&gt;% mutate(synergy_prob_random = synergies/(synergies + `non-synergies`)) observed_synergies_file = paste0(&quot;results/observed_synergies_cascade_2.0&quot;) observed_synergies = get_observed_synergies(observed_synergies_file) # 1 (positive/observed synergy) or 0 (negative/not observed) for all tested drug combinations observed = sapply(random_hsa_modelwise_synergies$perturbation %in% observed_synergies, as.integer) ROC curves # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; model-wise pred_ew_hsa = bind_cols(ss_hsa_ensemblewise_synergies_5sim %&gt;% rename(ss_score_5sim = score), ss_hsa_ensemblewise_synergies_50sim %&gt;% select(score) %&gt;% rename(ss_score_50sim = score), random_hsa_ensemblewise_synergies %&gt;% select(score) %&gt;% rename(random_score = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_mw_hsa = bind_cols( ss_hsa_modelwise_synergies_5sim %&gt;% select(perturbation, synergy_prob_ss) %&gt;% rename(synergy_prob_ss_5sim = synergy_prob_ss), ss_hsa_modelwise_synergies_50sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_50sim = synergy_prob_ss), random_hsa_modelwise_synergies %&gt;% select(synergy_prob_random), as_tibble_col(observed, column_name = &quot;observed&quot;)) res_ss_ew_5sim = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;ss_score_5sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_50sim = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;ss_score_50sim&quot;, label_col = &quot;observed&quot;) res_random_ew = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;random_score&quot;, label_col = &quot;observed&quot;) res_ss_mw_5sim = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_ss_5sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_50sim = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_ss_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_random_mw = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_random&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs my_palette = RColorBrewer::brewer.pal(n = 9, name = &quot;Set1&quot;) plot(x = res_ss_ew_5sim$roc_stats$FPR, y = res_ss_ew_5sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 2, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_ss_ew_50sim$roc_stats$FPR, y = res_ss_ew_50sim$roc_stats$TPR, lwd = 2, col = my_palette[2]) lines(x = res_random_ew$roc_stats$FPR, y = res_random_ew$roc_stats$TPR, lwd = 2, col = my_palette[3]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:3], pch = 19, legend = c(paste(round(res_ss_ew_5sim$AUC, digits = 3), &quot;Calibrated (5 sim)&quot;), paste(round(res_ss_ew_50sim$AUC, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(res_random_ew$AUC, digits = 3), &quot;Random&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;#FF726F&#39;, lty = 2) plot(x = res_ss_mw_5sim$roc_stats$FPR, y = res_ss_mw_5sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 2, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_ss_mw_50sim$roc_stats$FPR, y = res_ss_mw_50sim$roc_stats$TPR, lwd = 2, col = my_palette[2]) lines(x = res_random_mw$roc_stats$FPR, y = res_random_mw$roc_stats$TPR, lwd = 2, col = my_palette[3]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:3], pch = 19, legend = c(paste(round(res_ss_mw_5sim$AUC, digits = 3), &quot;Calibrated (5 sim)&quot;), paste(round(res_ss_mw_50sim$AUC, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(res_random_mw$AUC, digits = 3), &quot;Random&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;#FF726F&#39;, lty = 2) ROC AUC sensitivity Investigate same thing as described in here. We will combine the synergy scores from the random simulations with the results from the \\(50\\) Gitsbe simulations. # Ensemble-wise betas = seq(from = -10, to = 10, by = 0.1) auc_values_ew = sapply(betas, function(beta) { pred_ew_hsa = pred_ew_hsa %&gt;% mutate(combined_score = ss_score_50sim + beta * random_score) res = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;combined_score&quot;, label_col = &quot;observed&quot;) auc_value = res$AUC }) df_ew = as_tibble(cbind(betas, auc_values_ew)) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;auc_values_ew&quot;, numeric.x.axis = TRUE, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under ROC Curve)&quot;, title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter: $calibrated + \\\\beta \\\\times random$&quot;), color = my_palette[2]) + geom_vline(xintercept = 0) + grids() # Model-wise weights = seq(from = 0, to = 1, by = 0.05) auc_values_mw = sapply(weights, function(w) { pred_mw_hsa = pred_mw_hsa %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_hsa$synergy_prob_ss_50sim + w * pred_mw_hsa$synergy_prob_random) res = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;weighted_prob&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) auc_value = res$AUC }) df_mw = as_tibble(cbind(weights, auc_values_mw)) ggline(data = df_mw, x = &quot;weights&quot;, y = &quot;auc_values_mw&quot;, numeric.x.axis = TRUE, plot_type = &quot;l&quot;, xlab = TeX(&quot;weight $w$&quot;), ylab = &quot;AUC (Area Under ROC Curve)&quot;, title = TeX(&quot;AUC sensitivity to weighted average score: $(1-w) \\\\times prob_{ss} + w \\\\times prob_{rand}$&quot;), color = my_palette[3]) + grids() #+ ylim(0.4, 0.9) Symmetricity (Ensemble-wise): \\(AUC_{\\beta \\rightarrow +\\infty} + AUC_{\\beta \\rightarrow -\\infty} \\approx 1\\) Random models perform worse than calibrated ones (though difference is very small) There are \\(\\beta\\) values that can boost the predictive performance of the combined synergy classifier and a \\(w\\) weight in the model-wise case (though the significance in performance gain is negligible). Calibrated vs Random (Bliss) Bliss refers to the synergy method used in Drabme to assess the synergies from Gitsbe We test performance using ROC AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state Random models: produced via abmlog (see here and used in Drabme with synergy_method: bliss Load results: # &#39;ss&#39; =&gt; calibrated models, &#39;random&#39; =&gt; random models ## Bliss results ss_bliss_ensemblewise_10sim_file = paste0(&quot;results/bliss/cascade_2.0_ss_10sim_fixpoints_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_10sim_file = paste0(&quot;results/bliss/cascade_2.0_ss_10sim_fixpoints_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_30sim_file = paste0(&quot;results/bliss/cascade_2.0_ss_30sim_fixpoints_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_30sim_file = paste0(&quot;results/bliss/cascade_2.0_ss_30sim_fixpoints_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_50sim_file = paste0(&quot;results/bliss/cascade_2.0_ss_50sim_fixpoints_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_50sim_file = paste0(&quot;results/bliss/cascade_2.0_ss_50sim_fixpoints_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_70sim_file = paste0(&quot;results/bliss/cascade_2.0_ss_70sim_fixpoints_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_70sim_file = paste0(&quot;results/bliss/cascade_2.0_ss_70sim_fixpoints_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_100sim_file = paste0(&quot;results/bliss/cascade_2.0_ss_100sim_fixpoints_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_100sim_file = paste0(&quot;results/bliss/cascade_2.0_ss_100sim_fixpoints_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_150sim_file = paste0(&quot;results/bliss/cascade_2.0_ss_150sim_fixpoints_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_150sim_file = paste0(&quot;results/bliss/cascade_2.0_ss_150sim_fixpoints_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_200sim_file = paste0(&quot;results/bliss/cascade_2.0_ss_200sim_fixpoints_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_200sim_file = paste0(&quot;results/bliss/cascade_2.0_ss_200sim_fixpoints_modelwise_synergies.tab&quot;) random_bliss_ensemblewise_file = paste0(&quot;results/bliss/cascade_2.0_random_bliss_ensemblewise_synergies.tab&quot;) random_bliss_modelwise_file = paste0(&quot;results/bliss/cascade_2.0_random_bliss_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_synergies_10sim = emba::get_synergy_scores(ss_bliss_ensemblewise_10sim_file) ss_bliss_modelwise_synergies_10sim = emba::get_synergy_scores(ss_bliss_modelwise_10sim_file, file_type = &quot;modelwise&quot;) ss_bliss_ensemblewise_synergies_30sim = emba::get_synergy_scores(ss_bliss_ensemblewise_30sim_file) ss_bliss_modelwise_synergies_30sim = emba::get_synergy_scores(ss_bliss_modelwise_30sim_file, file_type = &quot;modelwise&quot;) ss_bliss_ensemblewise_synergies_50sim = emba::get_synergy_scores(ss_bliss_ensemblewise_50sim_file) ss_bliss_modelwise_synergies_50sim = emba::get_synergy_scores(ss_bliss_modelwise_50sim_file, file_type = &quot;modelwise&quot;) ss_bliss_ensemblewise_synergies_70sim = emba::get_synergy_scores(ss_bliss_ensemblewise_70sim_file) ss_bliss_modelwise_synergies_70sim = emba::get_synergy_scores(ss_bliss_modelwise_70sim_file, file_type = &quot;modelwise&quot;) ss_bliss_ensemblewise_synergies_100sim = emba::get_synergy_scores(ss_bliss_ensemblewise_100sim_file) ss_bliss_modelwise_synergies_100sim = emba::get_synergy_scores(ss_bliss_modelwise_100sim_file, file_type = &quot;modelwise&quot;) ss_bliss_ensemblewise_synergies_150sim = emba::get_synergy_scores(ss_bliss_ensemblewise_150sim_file) ss_bliss_modelwise_synergies_150sim = emba::get_synergy_scores(ss_bliss_modelwise_150sim_file, file_type = &quot;modelwise&quot;) ss_bliss_ensemblewise_synergies_200sim = emba::get_synergy_scores(ss_bliss_ensemblewise_200sim_file) ss_bliss_modelwise_synergies_200sim = emba::get_synergy_scores(ss_bliss_modelwise_200sim_file, file_type = &quot;modelwise&quot;) random_bliss_ensemblewise_synergies = emba::get_synergy_scores(random_bliss_ensemblewise_file) random_bliss_modelwise_synergies = emba::get_synergy_scores(random_bliss_modelwise_file, file_type = &quot;modelwise&quot;) # calculate probability of synergy in the modelwise results ss_bliss_modelwise_synergies_10sim = ss_bliss_modelwise_synergies_10sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_bliss_modelwise_synergies_30sim = ss_bliss_modelwise_synergies_30sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_bliss_modelwise_synergies_50sim = ss_bliss_modelwise_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_bliss_modelwise_synergies_70sim = ss_bliss_modelwise_synergies_70sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_bliss_modelwise_synergies_100sim = ss_bliss_modelwise_synergies_100sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_bliss_modelwise_synergies_150sim = ss_bliss_modelwise_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_bliss_modelwise_synergies_200sim = ss_bliss_modelwise_synergies_200sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) random_bliss_modelwise_synergies = random_bliss_modelwise_synergies %&gt;% mutate(synergy_prob_random = synergies/(synergies + `non-synergies`)) ROC curves # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; model-wise pred_ew_bliss = bind_cols(ss_bliss_ensemblewise_synergies_10sim %&gt;% rename(ss_score_10sim = score), ss_bliss_ensemblewise_synergies_30sim %&gt;% select(score) %&gt;% rename(ss_score_30sim = score), ss_bliss_ensemblewise_synergies_50sim %&gt;% select(score) %&gt;% rename(ss_score_50sim = score), ss_bliss_ensemblewise_synergies_70sim %&gt;% select(score) %&gt;% rename(ss_score_70sim = score), ss_bliss_ensemblewise_synergies_100sim %&gt;% select(score) %&gt;% rename(ss_score_100sim = score), ss_bliss_ensemblewise_synergies_150sim %&gt;% select(score) %&gt;% rename(ss_score_150sim = score), ss_bliss_ensemblewise_synergies_200sim %&gt;% select(score) %&gt;% rename(ss_score_200sim = score), random_bliss_ensemblewise_synergies %&gt;% select(score) %&gt;% rename(random_score = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_mw_bliss = bind_cols( ss_bliss_modelwise_synergies_10sim %&gt;% select(perturbation, synergy_prob_ss) %&gt;% rename(synergy_prob_ss_10sim = synergy_prob_ss), ss_bliss_modelwise_synergies_30sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_30sim = synergy_prob_ss), ss_bliss_modelwise_synergies_50sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_50sim = synergy_prob_ss), ss_bliss_modelwise_synergies_70sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_70sim = synergy_prob_ss), ss_bliss_modelwise_synergies_100sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_100sim = synergy_prob_ss), ss_bliss_modelwise_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_150sim = synergy_prob_ss), ss_bliss_modelwise_synergies_200sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_200sim = synergy_prob_ss), random_bliss_modelwise_synergies %&gt;% select(synergy_prob_random), as_tibble_col(observed, column_name = &quot;observed&quot;)) res_ss_ew_10sim = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score_10sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_30sim = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score_30sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_50sim = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score_50sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_70sim = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score_70sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_100sim = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score_100sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_150sim = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score_150sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_200sim = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score_200sim&quot;, label_col = &quot;observed&quot;) res_random_ew = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;random_score&quot;, label_col = &quot;observed&quot;) res_ss_mw_10sim = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss_10sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_30sim = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss_30sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_50sim = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_70sim = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss_70sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_100sim = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss_100sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_150sim = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_200sim = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss_200sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_random_mw = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_random&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs plot(x = res_ss_ew_10sim$roc_stats$FPR, y = res_ss_ew_10sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 2, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_ss_ew_30sim$roc_stats$FPR, y = res_ss_ew_30sim$roc_stats$TPR, lwd = 2, col = my_palette[2]) lines(x = res_ss_ew_50sim$roc_stats$FPR, y = res_ss_ew_50sim$roc_stats$TPR, lwd = 2, col = my_palette[3]) lines(x = res_ss_ew_70sim$roc_stats$FPR, y = res_ss_ew_70sim$roc_stats$TPR, lwd = 2, col = my_palette[4]) lines(x = res_ss_ew_100sim$roc_stats$FPR, y = res_ss_ew_100sim$roc_stats$TPR, lwd = 2, col = my_palette[5]) lines(x = res_ss_ew_150sim$roc_stats$FPR, y = res_ss_ew_150sim$roc_stats$TPR, lwd = 2, col = my_palette[6]) lines(x = res_ss_ew_200sim$roc_stats$FPR, y = res_ss_ew_200sim$roc_stats$TPR, lwd = 2, col = my_palette[7]) lines(x = res_random_ew$roc_stats$FPR, y = res_random_ew$roc_stats$TPR, lwd = 2, col = my_palette[8]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:8], pch = 19, legend = c(paste(round(res_ss_ew_10sim$AUC, digits = 2), &quot;Calibrated (10 sim)&quot;), paste(round(res_ss_ew_30sim$AUC, digits = 2), &quot;Calibrated (30 sim)&quot;), paste(round(res_ss_ew_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(res_ss_ew_70sim$AUC, digits = 2), &quot;Calibrated (70 sim)&quot;), paste(round(res_ss_ew_100sim$AUC, digits = 2), &quot;Calibrated (100 sim)&quot;), paste(round(res_ss_ew_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(res_ss_ew_200sim$AUC, digits = 2), &quot;Calibrated (200 sim)&quot;), paste(round(res_random_ew$AUC, digits = 2), &quot;Random&quot;)), cex = 0.7) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;#FF726F&#39;, lty = 2) plot(x = res_ss_mw_10sim$roc_stats$FPR, y = res_ss_mw_10sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 2, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_ss_mw_30sim$roc_stats$FPR, y = res_ss_mw_30sim$roc_stats$TPR, lwd = 2, col = my_palette[2]) lines(x = res_ss_mw_50sim$roc_stats$FPR, y = res_ss_mw_50sim$roc_stats$TPR, lwd = 2, col = my_palette[3]) lines(x = res_ss_mw_70sim$roc_stats$FPR, y = res_ss_mw_70sim$roc_stats$TPR, lwd = 2, col = my_palette[4]) lines(x = res_ss_mw_100sim$roc_stats$FPR, y = res_ss_mw_100sim$roc_stats$TPR, lwd = 2, col = my_palette[5]) lines(x = res_ss_mw_150sim$roc_stats$FPR, y = res_ss_mw_150sim$roc_stats$TPR, lwd = 2, col = my_palette[6]) lines(x = res_ss_mw_200sim$roc_stats$FPR, y = res_ss_mw_200sim$roc_stats$TPR, lwd = 2, col = my_palette[7]) lines(x = res_random_mw$roc_stats$FPR, y = res_random_mw$roc_stats$TPR, lwd = 2, col = my_palette[8]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:8], pch = 19, legend = c(paste(round(res_ss_mw_10sim$AUC, digits = 2), &quot;Calibrated (10 sim)&quot;), paste(round(res_ss_mw_30sim$AUC, digits = 2), &quot;Calibrated (30 sim)&quot;), paste(round(res_ss_mw_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(res_ss_mw_70sim$AUC, digits = 2), &quot;Calibrated (70 sim)&quot;), paste(round(res_ss_mw_100sim$AUC, digits = 2), &quot;Calibrated (100 sim)&quot;), paste(round(res_ss_mw_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(res_ss_mw_200sim$AUC, digits = 2), &quot;Calibrated (200 sim)&quot;), paste(round(res_random_mw$AUC, digits = 2), &quot;Random&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;#FF726F&#39;, lty = 2) ROC AUC sensitivity Investigate same thing as described in here. We will combine the synergy scores from the random simulations with the results from the \\(50\\) Gitsbe simulations. # Ensemble-wise betas = seq(from = -20, to = 20, by = 0.1) auc_values_ew = sapply(betas, function(beta) { pred_ew_bliss = pred_ew_bliss %&gt;% mutate(combined_score = ss_score_50sim + beta * random_score) res = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;combined_score&quot;, label_col = &quot;observed&quot;) auc_value = res$AUC }) df_ew = as_tibble(cbind(betas, auc_values_ew)) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;auc_values_ew&quot;, numeric.x.axis = TRUE, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under ROC Curve)&quot;, title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter: $calibrated + \\\\beta \\\\times random$&quot;), color = my_palette[2]) + geom_vline(xintercept = 0) + grids() # Model-wise weights = seq(from = 0, to = 1, by = 0.05) auc_values_mw = sapply(weights, function(w) { pred_mw_bliss = pred_mw_bliss %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_bliss$synergy_prob_ss_50sim + w * pred_mw_bliss$synergy_prob_random) res = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;weighted_prob&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) auc_value = res$AUC }) df_mw = as_tibble(cbind(weights, auc_values_mw)) ggline(data = df_mw, x = &quot;weights&quot;, y = &quot;auc_values_mw&quot;, numeric.x.axis = TRUE, plot_type = &quot;l&quot;, xlab = TeX(&quot;weight $w$&quot;), ylab = &quot;AUC (Area Under ROC Curve)&quot;, title = TeX(&quot;AUC sensitivity to weighted average score: $(1-w) \\\\times prob_{ss} + w \\\\times prob_{rand}$&quot;), color = my_palette[3]) + grids() Symmetricity (Ensemble-wise): \\(AUC_{\\beta \\rightarrow +\\infty} + AUC_{\\beta \\rightarrow -\\infty} \\approx 1\\) Random models perform better than calibrated ones Combining the synergy results using the weighted probability score does not bring any significant difference in performance Using the \\(\\beta\\) parameter to boost the ensemble synergy results works only for the HSA results (not the Bliss-based ones) Fitness vs performance The idea here is to generate many training data files from the steady state as used in the simulations above for the AGS, where some of the nodes will have their states flipped to the opposite state (\\(0\\) to \\(1\\) and vice versa). That way, we can train models to different steady states, ranging from ones that differ to just a few nodes states up to a steady state that is the complete reversed version of the one used in the simulations above. Using the gen_training_data.R script, we first choose a few number of flips (\\(11\\) flips) ranging from \\(1\\) to \\(24\\) (all nodes) in the steady state. Then, for each such flipping-nodes value, we generated \\(20\\) new steady states with a randomly chosen set of nodes whose value is going to flip. Thus, in total, \\(205\\) training data files were produced (\\(205 = 9 \\times 20 + 24 + 1\\), where from the \\(11\\) number of flips, the one flip happens for every node and flipping all the nodes simultaneously happens once). Running the script run_druglogics_synergy_training.sh from the druglogics-synergy repository root, we get the simulation results for each of these training data files. The only difference in the cascade 2.0 configuration file was the number of simulations (\\(15\\)) for each training data file and the attractor tool used (biolqm_stable_states). We now load the data from these simulations: Reproduce simulation results ROC curves Install druglogics-synergy Run the script run_druglogics_synergy.sh in the above repo using the configuration settings: simulations: 50 attractor_tool: biolqm_stable_states synergy_method: hsa (also rerun the script chaning the synergy method bliss) Thus you will get a directory per simulation and inside will be several result files. To generate the ROC curves, we use the ensemble-wise and model-wise synergies found in each respective simulation. Random model results The CASCADE 1.0 and 2.0 .sif network files can be found at the directories ags_cascade_1.0 and ags_cascade_2.0 on the druglogics-synergy repository. Run the abmlog for the CASCADE 2.0 topology: java -cp target/abmlog-1.5.0-jar-with-dependencies.jar eu.druglogics.abmlog.RandomBooleanModelGenerator --file=test/cascade_2_0.sif --num=3000 Next, prune the resulting models to only the ones that have 1 stable state (\\(1292\\)) using a simple bash script, while renaming the modelnames inside the files so that they have the string _run_ (mimicking thus the files generated by gitsbe - otherwise drabme fails!) - use the script process_models.sh inside the generated models directory from abmlog. cd pathTo/druglogics-synergy/ags_cascade_2.0 Move the models dir inside the ags_cascade_2.0 dir Use attractor_tool: biolqm_stable_states in the config file Use either synergy_method: hsa or synergy_method: bliss Run drabme via druglogics-synergy: java -cp ../target/synergy-1.2.0-jar-with-dependencies.jar eu.druglogics.drabme.Launcher --project=cascade_2.0_random_hsa --modelsDir=models --drugs=drugpanel --perturbations=perturbations --config=config --modeloutputs=modeloutputs java -cp ../target/synergy-1.2.0-jar-with-dependencies.jar eu.druglogics.drabme.Launcher --project=cascade_2.0_random_bliss --modelsDir=models --drugs=drugpanel --perturbations=perturbations --config=config --modeloutputs=modeloutputs The above procedure is the same for CASCADE 1.0. Changes: Network file is now the cascade_1_0.sif The process_models.sh needs a small name change (documented inside the script) The models directory should be put inside the ags_cascade_1.0 of druglogics-synergy The drabme command should be run with --project=cascade_1.0_random_hsa and --project=cascade_1.0_random_bliss respectively R session info xfun::session_info() R version 3.6.3 (2020-02-29) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 18.04.4 LTS Locale: LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C Package version: assertthat_0.2.1 backports_1.1.6 base64enc_0.1.3 BH_1.72.0.3 bibtex_0.4.2.2 bookdown_0.18 callr_3.4.3 Ckmeans.1d.dp_4.3.2 cli_2.0.2 clipr_0.7.0 colorspace_1.4-1 compiler_3.6.3 cowplot_1.0.0 crayon_1.3.4 crosstalk_1.1.0.1 desc_1.2.0 digest_0.6.25 dplyr_0.8.5 DT_0.13 ellipsis_0.3.0 emba_0.1.4 evaluate_0.14 fansi_0.4.1 farver_2.0.3 gbRd_0.4-11 ggplot2_3.3.0 ggpubr_0.2.5 ggrepel_0.8.2 ggsci_2.9 ggsignif_0.6.0 glue_1.4.0 graphics_3.6.3 grDevices_3.6.3 grid_3.6.3 gridExtra_2.3 gtable_0.3.0 highr_0.8 hms_0.5.3 htmltools_0.4.0 htmlwidgets_1.5.1 igraph_1.2.5 isoband_0.2.1 jsonlite_1.6.1 knitr_1.28 labeling_0.3 later_1.0.0 latex2exp_0.4.0 lattice_0.20-41 lazyeval_0.2.2 lifecycle_0.2.0 magrittr_1.5 markdown_1.1 MASS_7.3.51.5 Matrix_1.2-18 methods_3.6.3 mgcv_1.8-31 mime_0.9 munsell_0.5.0 nlme_3.1-145 pillar_1.4.3 pkgbuild_1.0.6 pkgconfig_2.0.3 pkgload_1.0.2 plogr_0.2.0 polynom_1.4.0 praise_1.0.0 prettyunits_1.1.1 processx_3.4.2 promises_1.1.0 ps_1.3.2 purrr_0.3.3 R6_2.4.1 RColorBrewer_1.1-2 Rcpp_1.0.4.6 Rdpack_0.11-1 readr_1.3.1 rje_1.10.15 rlang_0.4.5 rmarkdown_2.1 rprojroot_1.3.2 rstudioapi_0.11 scales_1.1.0 splines_3.6.3 stats_3.6.3 stringi_1.4.6 stringr_1.4.0 testthat_2.3.2 tibble_3.0.0 tidyr_1.0.2 tidyselect_1.0.0 tinytex_0.21 tools_3.6.3 usefun_0.4.5 utf8_1.1.4 utils_3.6.3 vctrs_0.2.4 viridisLite_0.3.0 visNetwork_2.0.9 withr_2.1.2 xfun_0.12 yaml_2.2.1 References Flobak, Åsmund, Anaïs Baudot, Elisabeth Remy, Liv Thommesen, Denis Thieffry, Martin Kuiper, and Astrid Lægreid. 2015. “Discovery of Drug Synergies in Gastric Cancer Cells Predicted by Logical Modeling.” Edited by Ioannis Xenarios. PLOS Computational Biology 11 (8): e1004426. https://doi.org/10.1371/journal.pcbi.1004426. "]
]

[["index.html", "AGS paper - Supplementary Information (SI) Intro Methodology/Input Overview Summary", " AGS paper - Supplementary Information (SI) John Zobolas Last updated: 11 January, 2021 Intro This report is the supplementary material for the AGS paper and has all the simulation results and investigations related to that paper, as well as instructions for reproducing the results. Methodology/Input Overview A list of things that change between the simulations and the presented figures are: The number of Gitsbe simulations: more simulations, more models generated. The type of mutation that Gitsbe models have: unless otherwise specified, the Gitsbe models have only link operator mutations. Topology mutations were also tested as well as a combination of topology and link operator mutations. The training data for the Gitsbe models: steady state (calibrated models) vs proliferative profile (random models). The type of mathematical model (HSA or Bliss) used in Drabme to evaluate the synergies either from the (Flobak et al. 2015) for the CASCADE 1.0 analysis or from the (Flobak et al. 2019) dataset for the CASCADE 2.0 analysis. More info on the calculations that Drabme does see here. The type of output used from Drabme: ensemble-wise or model-wise synergy results. Summary Observing the results across the whole report, we reach the following conclusions: To minimize the expected performance variance, executing \\(150\\) Gitsbe simulations (~\\(500\\) best-fitted models) is a good choice (no need for more, no matter the other input parameters). Ensemble-wise results do not correlate with model-wise results (see correlation results for CASCADE 1.0 and CASCADE 2.0). This happens because some drug perturbed models do not have stable states and thus cannot be evaluated for synergy.1 Model-wise ROC results are always better compared to ensemble-wise ROC results for the single predictor models (e.g. the calibrated non-normalized model results). When using a combined model predictor (see here) to augment/correct the calibrated models results, Drabme’s Bliss synergy assessment always brings significant performance benefit for the ensemble-wise results. When using HSA, that is not always the case (see one example and another). The model-wise results do not bring any performance benefit when used in a combined predictor. The value of \\(\\beta = -1\\) is a good estimation for the value that maximizes the combined predictor’s performance (\\(calibrated + \\beta \\times random\\)) across all of the report’s relevant investigations. Comparing the different parameterization schemes for the CASCADE 2.0 analysis (using the combined predictors with \\(\\beta = -1\\)), we observe that topology mutations outperform link operator mutations. There is correlation between fitness to the AGS steady state and normalized ensemble prediction performance. This is observed for the link operator mutated CASCADE 2.0 models here and a little bit more for the topology mutated ones. Same trend was shown for the CASCADE 1.0 link-operator mutated models analysis. Any type of scrambling in the curated CASCADE topology reduces ensemble model prediction performance. See results for CASCADE 1.0 here and CASCADE 2.0 here. Using minimal trapspaces, where there is almost always an attractor found and the global output of the model can be calculated, we observed higher correlation between ensemble-wise and model-wise results (as expected)↩︎ "],["r-libraries.html", "R Libraries", " R Libraries For the ROC curves we used the function get_roc_stats() from the usefun R package (Zobolas 2020b) and for the PR curves the pr.curve() from the PRROC package (Grau, Grosse, and Keilwagen 2015). Several functions from the emba R package (Zobolas, Kuiper, and Flobak 2020) are also used to load the simulation results. The AUC sensitivity analysis (for a description see here) was inspired by work from (Pepe 2000). The heatmaps are generated with the ComplexHeatmap R package (Gu, Eils, and Schlesner 2016). The report template is from the rtemps R package (Zobolas 2020a). Loading libraries that are used in this report: library(DT) library(ggpubr) library(RColorBrewer) library(xfun) library(dplyr) library(tidyr) library(tibble) library(emba) library(usefun) library(readr) library(stringr) library(latex2exp) library(corrplot) library(PRROC) library(equatiomatic) library(glmnet) library(knitr) library(MAMSE) library(circlize) library(ComplexHeatmap) library(rstatix) "],["cascade-1-0-analysis.html", "CASCADE 1.0 Analysis HSA results Bliss results Best ROC and PRC Correlation Fitness Evolution Fitness vs Ensemble Performance Scrambled Topologies Investigation", " CASCADE 1.0 Analysis Performance of automatically parameterized models against published data in (Flobak et al. 2015) HSA results HSA refers to the synergy method used in Drabme to assess the synergies from the gitsbe models We test performance using ROC and PR AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state (\\(50\\) simulations) Random models: fitted to proliferation profile (\\(50\\) simulations) Gitsbe models have mutations on link operator only Load results: # &#39;ss&#39; =&gt; calibrated models, &#39;prolif&#39; =&gt; proliferative random models # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; model-wise ## HSA results ss_hsa_ew_file = paste0(&quot;results/link-only/cascade_1.0_ss_50sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) ss_hsa_mw_file = paste0(&quot;results/link-only/cascade_1.0_ss_50sim_fixpoints_hsa_modelwise_synergies.tab&quot;) prolif_hsa_ew_file = paste0(&quot;results/link-only/cascade_1.0_rand_50sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) prolif_hsa_mw_file = paste0(&quot;results/link-only/cascade_1.0_rand_50sim_fixpoints_hsa_modelwise_synergies.tab&quot;) ss_hsa_ensemblewise_synergies = emba::get_synergy_scores(ss_hsa_ew_file) ss_hsa_modelwise_synergies = emba::get_synergy_scores(ss_hsa_mw_file, file_type = &quot;modelwise&quot;) prolif_hsa_ensemblewise_synergies = emba::get_synergy_scores(prolif_hsa_ew_file) prolif_hsa_modelwise_synergies = emba::get_synergy_scores(prolif_hsa_mw_file, file_type = &quot;modelwise&quot;) # calculate probability of synergy in the modelwise results ss_hsa_modelwise_synergies = ss_hsa_modelwise_synergies %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) prolif_hsa_modelwise_synergies = prolif_hsa_modelwise_synergies %&gt;% mutate(synergy_prob_prolif = synergies/(synergies + `non-synergies`)) observed_synergies_file = &#39;data/observed_synergies_cascade_1.0&#39; observed_synergies = emba::get_observed_synergies(observed_synergies_file) # 1 (positive/observed synergy) or 0 (negative/not observed) for all tested drug combinations observed = sapply(prolif_hsa_modelwise_synergies$perturbation %in% observed_synergies, as.integer) # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; model-wise pred_ew_hsa = bind_cols(ss_hsa_ensemblewise_synergies %&gt;% rename(ss_score = score), prolif_hsa_ensemblewise_synergies %&gt;% select(score) %&gt;% rename(prolif_score = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_mw_hsa = bind_cols( ss_hsa_modelwise_synergies %&gt;% select(perturbation, synergy_prob_ss), prolif_hsa_modelwise_synergies %&gt;% select(synergy_prob_prolif), as_tibble_col(observed, column_name = &quot;observed&quot;)) ROC curves res_ss_ew = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;ss_score&quot;, label_col = &quot;observed&quot;) res_prolif_ew = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;prolif_score&quot;, label_col = &quot;observed&quot;) res_ss_mw = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_ss&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_prolif_mw = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_prolif&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs my_palette = RColorBrewer::brewer.pal(n = 9, name = &quot;Set1&quot;) plot(x = res_ss_ew$roc_stats$FPR, y = res_ss_ew$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_prolif_ew$roc_stats$FPR, y = res_prolif_ew$roc_stats$TPR, lwd = 3, col = my_palette[2]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, legend = c(paste(round(res_ss_ew$AUC, digits = 3), &quot;Calibrated&quot;), paste(round(res_prolif_ew$AUC, digits = 3), &quot;Random&quot;)), cex = 1.3) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) plot(x = res_ss_mw$roc_stats$FPR, y = res_ss_mw$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_prolif_mw$roc_stats$FPR, y = res_prolif_mw$roc_stats$TPR, lwd = 3, col = my_palette[2]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:3], pch = 19, legend = c(paste(round(res_ss_mw$AUC, digits = 3), &quot;Calibrated&quot;), paste(round(res_prolif_mw$AUC, digits = 3), &quot;Random&quot;)), cex = 1.3) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) Figure 1: ROC curves (CASCADE 1.0, HSA synergy method) PR curves pr_ss_ew_hsa = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(ss_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_prolif_ew_hsa = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(prolif_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_ss_mw_hsa = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(synergy_prob_ss), weights.class0 = pred_mw_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_prolif_mw_hsa = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(synergy_prob_prolif), weights.class0 = pred_mw_hsa %&gt;% pull(observed), curve = TRUE) plot(pr_ss_ew_hsa, main = &#39;PR curve, Ensemble-wise synergies (HSA)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_prolif_ew_hsa, add = TRUE, color = my_palette[2]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, legend = c(paste(round(pr_ss_ew_hsa$auc.davis.goadrich, digits = 3), &quot;Calibrated&quot;), paste(round(pr_prolif_ew_hsa$auc.davis.goadrich, digits = 3), &quot;Random&quot;))) grid(lwd = 0.5) plot(pr_ss_mw_hsa, main = &#39;PR curve, Model-wise synergies (HSA)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_prolif_mw_hsa, add = TRUE, color = my_palette[2]) legend(&#39;left&#39;, title = &#39;AUC&#39;, col = my_palette[1:3], pch = 19, legend = c(paste(round(pr_ss_mw_hsa$auc.davis.goadrich, digits = 3), &quot;Calibrated&quot;), paste(round(pr_prolif_mw_hsa$auc.davis.goadrich, digits = 3), &quot;Random&quot;))) grid(lwd = 0.5) Figure 2: PR curves (CASCADE 1.0, HSA synergy method) Calibrated models perform a lot better than the random ones AUC sensitivity Investigate combining the synergy results of calibrated and proliferative (random) models Quantify the amount of information from the proliferative (random) models that can be used to augment the calibrated results? Ensemble-wise scenario: \\(score = calibrated + \\beta \\times random\\) \\(\\beta \\rightarrow +\\infty\\): mostly proliferative (random) model predictions \\(\\beta \\rightarrow -\\infty\\): mostly reverse proliferative (random) model predictions \\(\\beta \\simeq -1\\): calibrated models are normalized against proliferative (random) model predictions. Model-wise scenario: \\((1-w) \\times prob_{cal} + w \\times prob_{rand}, w \\in[0,1]\\) \\(w=0\\): only calibrated model predictions \\(w=1\\): only proliferative (random) model predictions # Ensemble-wise betas = seq(from = -12, to = 12, by = 0.1) prolif_roc = sapply(betas, function(beta) { pred_ew_hsa = pred_ew_hsa %&gt;% mutate(combined_score = ss_score + beta * prolif_score) res = roc.curve(scores.class0 = pred_ew_hsa %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr = sapply(betas, function(beta) { pred_ew_hsa = pred_ew_hsa %&gt;% mutate(combined_score = ss_score + beta * prolif_score) res = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_ew = as_tibble(cbind(betas, prolif_roc, prolif_pr)) df_ew = df_ew %&gt;% tidyr::pivot_longer(-betas, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter (HSA, CASCADE 1.0)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + geom_vline(xintercept = 0) + geom_vline(xintercept = -1, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_text(aes(x=-2, label=&quot;β = -1&quot;, y=0.25), colour=&quot;black&quot;, angle=90) + grids() Figure 3: AUC sensitivity (CASCADE 1.0, HSA synergy method, Ensemble-wise results) # Model-wise weights = seq(from = 0, to = 1, by = 0.05) prolif_roc_mw = sapply(weights, function(w) { pred_mw_hsa = pred_mw_hsa %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_hsa$synergy_prob_ss + w * pred_mw_hsa$synergy_prob_prolif) res = roc.curve(scores.class0 = pred_mw_hsa %&gt;% pull(weighted_prob), weights.class0 = pred_mw_hsa %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr_mw = sapply(weights, function(w) { pred_mw_hsa = pred_mw_hsa %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_hsa$synergy_prob_ss + w * pred_mw_hsa$synergy_prob_prolif) res = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(weighted_prob), weights.class0 = pred_mw_hsa %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_mw = as_tibble(cbind(weights, prolif_roc_mw, prolif_pr_mw)) df_mw = df_mw %&gt;% tidyr::pivot_longer(-weights, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_mw, x = &quot;weights&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;weight $w$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title.position = &quot;center&quot;, title = TeX(&quot;AUC sensitivity to weighted average score (HSA, CASCADE 1.0)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + grids() Figure 4: AUC sensitivity (CASCADE 1.0, HSA synergy method, Model-wise results) There are \\(\\beta\\) values that can boost the predictive performance of the calibrated models (ensemble-wise) but no \\(w\\) weight in the model-wise case. \\(\\beta=-1\\) seems to be a common value that maximizes both the ROC-AUC and the PR-AUC. The PR-AUC is more sensitive than the ROC-AUC, so a better indicator of performance. Bliss results Bliss refers to the synergy method used in Drabme to assess the synergies from the gitsbe models We test performance using ROC and PR AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state (\\(50\\) simulations) Random models: fitted to proliferation profile (\\(50\\) simulations) Gitsbe models have mutations on link operator only Load results: # &#39;ss&#39; =&gt; calibrated models, &#39;prolif&#39; =&gt; random models ## Bliss results ss_bliss_ensemblewise_file = paste0(&quot;results/link-only/cascade_1.0_ss_50sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_file = paste0(&quot;results/link-only/cascade_1.0_ss_50sim_fixpoints_bliss_modelwise_synergies.tab&quot;) prolif_bliss_ensemblewise_file = paste0(&quot;results/link-only/cascade_1.0_rand_50sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) prolif_bliss_modelwise_file = paste0(&quot;results/link-only/cascade_1.0_rand_50sim_fixpoints_bliss_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_synergies = emba::get_synergy_scores(ss_bliss_ensemblewise_file) ss_bliss_modelwise_synergies = emba::get_synergy_scores(ss_bliss_modelwise_file, file_type = &quot;modelwise&quot;) prolif_bliss_ensemblewise_synergies = emba::get_synergy_scores(prolif_bliss_ensemblewise_file) prolif_bliss_modelwise_synergies = emba::get_synergy_scores(prolif_bliss_modelwise_file, file_type = &quot;modelwise&quot;) # calculate probability of synergy in the modelwise results ss_bliss_modelwise_synergies = ss_bliss_modelwise_synergies %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) prolif_bliss_modelwise_synergies = prolif_bliss_modelwise_synergies %&gt;% mutate(synergy_prob_prolif = synergies/(synergies + `non-synergies`)) # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; model-wise pred_ew_bliss = bind_cols(ss_bliss_ensemblewise_synergies %&gt;% rename(ss_score = score), prolif_bliss_ensemblewise_synergies %&gt;% select(score) %&gt;% rename(prolif_score = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_mw_bliss = bind_cols( ss_bliss_modelwise_synergies %&gt;% select(perturbation, synergy_prob_ss), prolif_bliss_modelwise_synergies %&gt;% select(synergy_prob_prolif), as_tibble_col(observed, column_name = &quot;observed&quot;)) ROC curves res_ss_ew = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score&quot;, label_col = &quot;observed&quot;) res_prolif_ew = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;prolif_score&quot;, label_col = &quot;observed&quot;) res_ss_mw = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_prolif_mw = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_prolif&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs plot(x = res_ss_ew$roc_stats$FPR, y = res_ss_ew$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_prolif_ew$roc_stats$FPR, y = res_prolif_ew$roc_stats$TPR, lwd = 3, col = my_palette[2]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, legend = c(paste(round(res_ss_ew$AUC, digits = 3), &quot;Calibrated&quot;), paste(round(res_prolif_ew$AUC, digits = 3), &quot;Random&quot;)), cex = 1.3) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) plot(x = res_ss_mw$roc_stats$FPR, y = res_ss_mw$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_prolif_mw$roc_stats$FPR, y = res_prolif_mw$roc_stats$TPR, lwd = 3, col = my_palette[2]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, legend = c(paste(round(res_ss_mw$AUC, digits = 3), &quot;Calibrated&quot;), paste(round(res_prolif_mw$AUC, digits = 3), &quot;Random&quot;)), cex = 1.3) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) Figure 5: ROC curves (CASCADE 1.0, Bliss synergy method) The ROC statistics data for the calibrated models are as follows: DT::datatable(data = res_ss_ew$roc_stats, options = list(pageLength = 5, lengthMenu = c(5, 10, 16), searching = FALSE)) %&gt;% formatRound(c(1,6,7,8,9), digits = 3) Figure 6: ROC data for Calibrated Models (CASCADE 1.0, Bliss synergy method) # investigate the average threshold as a synergy classification index # thres = res_ss_ew$roc_stats %&gt;% pull(threshold) # thres = thres[is.finite(thres)] # remove Inf&#39;s # res_ss_ew$roc_stats %&gt;% # filter(threshold &lt; mean(thres)) %&gt;% # slice(n()) %&gt;% kable() PR curves pr_ss_ew_bliss = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(ss_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_prolif_ew_bliss = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(prolif_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_ss_mw_bliss = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(synergy_prob_ss), weights.class0 = pred_mw_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_prolif_mw_bliss = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(synergy_prob_prolif), weights.class0 = pred_mw_bliss %&gt;% pull(observed), curve = TRUE) plot(pr_ss_ew_bliss, main = &#39;PR curve, Ensemble-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_prolif_ew_bliss, add = TRUE, color = my_palette[2]) legend(x = 0, y = 0.9, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, cex = 1.3, legend = c(paste(round(pr_ss_ew_bliss$auc.davis.goadrich, digits = 3), &quot;Calibrated&quot;), paste(round(pr_prolif_ew_bliss$auc.davis.goadrich, digits = 3), &quot;Random&quot;))) grid(lwd = 0.5) plot(pr_ss_mw_bliss, main = &#39;PR curve, Model-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_prolif_mw_bliss, add = TRUE, color = my_palette[2]) legend(x = 0, y = 0.9, title = &#39;AUC&#39;, col = my_palette[1:3], pch = 19, cex = 1.3, legend = c(paste(round(pr_ss_mw_bliss$auc.davis.goadrich, digits = 3), &quot;Calibrated&quot;), paste(round(pr_prolif_mw_bliss$auc.davis.goadrich, digits = 3), &quot;Random&quot;))) grid(lwd = 0.5) Figure 7: PR curves (CASCADE 1.0, Bliss synergy method) Calibrated models perform a lot better than the random ones AUC sensitivity Investigate same thing as described in here. # Ensemble-wise betas = seq(from = -12, to = 12, by = 0.1) prolif_roc = sapply(betas, function(beta) { pred_ew_bliss = pred_ew_bliss %&gt;% mutate(combined_score = ss_score + beta * prolif_score) res = roc.curve(scores.class0 = pred_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr = sapply(betas, function(beta) { pred_ew_bliss = pred_ew_bliss %&gt;% mutate(combined_score = ss_score + beta * prolif_score) res = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_ew = as_tibble(cbind(betas, prolif_roc, prolif_pr)) df_ew = df_ew %&gt;% tidyr::pivot_longer(-betas, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter (Bliss, CASCADE 1.0)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + geom_vline(xintercept = 0) + geom_vline(xintercept = -1, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_text(aes(x=-2, label=&quot;β = -1&quot;, y=0.25), colour=&quot;black&quot;, angle=90) + grids() Figure 8: AUC sensitivity (CASCADE 1.0, Bliss synergy method, Ensemble-wise results) # Model-wise weights = seq(from = 0, to = 1, by = 0.05) prolif_roc_mw = sapply(weights, function(w) { pred_mw_bliss = pred_mw_bliss %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_bliss$synergy_prob_ss + w * pred_mw_bliss$synergy_prob_prolif) res = roc.curve(scores.class0 = pred_mw_bliss %&gt;% pull(weighted_prob), weights.class0 = pred_mw_bliss %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr_mw = sapply(weights, function(w) { pred_mw_bliss = pred_mw_bliss %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_bliss$synergy_prob_ss + w * pred_mw_bliss$synergy_prob_prolif) res = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(weighted_prob), weights.class0 = pred_mw_bliss %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_mw = as_tibble(cbind(weights, prolif_roc_mw, prolif_pr_mw)) df_mw = df_mw %&gt;% tidyr::pivot_longer(-weights, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_mw, x = &quot;weights&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;weight $w$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title.position = &quot;center&quot;, title = TeX(&quot;AUC sensitivity to weighted average score (Bliss, CASCADE 1.0)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + grids() Figure 9: AUC sensitivity (CASCADE 1.0, Bliss synergy method, Model-wise results) There are \\(\\beta\\) values that can boost the predictive performance of the calibrated models (ensemble-wise) but no \\(w\\) weight in the model-wise case. The PR-AUC is more sensitive than the ROC-AUC, so a better indicator of performance. A value very close to \\(\\beta=-1\\) seems to be the one maximizes both the ROC-AUC and the PR-AUC. The ROC ensemble-wise statistics data for the combined predictor \\(calibrated + \\beta \\times random, \\beta=-1\\) are: beta = -1 pred_ew_bliss = pred_ew_bliss %&gt;% mutate(combined_score = ss_score + beta * prolif_score) res_comb_pred = usefun::get_roc_stats(df = pred_ew_bliss, pred_col = &quot;combined_score&quot;, label_col = &quot;observed&quot;) DT::datatable(data = res_comb_pred$roc_stats, options = list(pageLength = 5, lengthMenu = c(5, 10, 16), searching = FALSE)) %&gt;% DT::formatRound(c(1,6,7,8,9), digits = 3) Figure 10: ROC data for Combined Predictor (CASCADE 1.0, Bliss synergy method) # All observed synergies are in top 6 # pred_ew_bliss %&gt;% arrange(combined_score) Best ROC and PRC Only for the next plot, Calibrated stands for the combined predictor results, i.e. \\(calibrated + \\beta \\times random, \\beta=-1\\). plot(x = res_comb_pred$roc_stats$FPR, y = res_comb_pred$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_prolif_ew$roc_stats$FPR, y = res_prolif_ew$roc_stats$TPR, lwd = 3, col = my_palette[2]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, legend = c(paste(round(res_comb_pred$AUC, digits = 3), &quot;Calibrated&quot;), paste(round(res_prolif_ew$AUC, digits = 3), &quot;Random&quot;)), cex = 1.3) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) res_comb_pred_pr = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) plot(res_comb_pred_pr, main = &#39;PR curve, Ensemble-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_prolif_ew_bliss, add = TRUE, color = my_palette[2]) legend(x = 0, y = 0.9, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, cex = 1.3, legend = c(paste(round(res_comb_pred_pr$auc.davis.goadrich, digits = 3), &quot;Calibrated&quot;), paste(round(pr_prolif_ew_bliss$auc.davis.goadrich, digits = 3), &quot;Random&quot;))) grid(lwd = 0.5) Figure 11: ROC and PR curves for Random and Best Combined Predictor (CASCADE 1.0, Bliss synergy method) Correlation We test for correlation between all the synergy predictor results shown in the previous curves. This means ensemble-wise vs model-wise, random proliferative models vs calibrated models and HSA vs Bliss synergy assessment. P-values are represented at 3 significant levels: \\(0.05, 0.01, 0.001\\) (*, **, ***) and the correlation coefficient is calculated using Kendall’s tau statistic. synergy_scores = bind_cols( pred_ew_hsa %&gt;% select(ss_score, prolif_score) %&gt;% rename(cal_ew_hsa = ss_score, random_ew_hsa = prolif_score), pred_ew_bliss %&gt;% select(ss_score, prolif_score) %&gt;% rename(cal_ew_bliss = ss_score, random_ew_bliss = prolif_score), pred_mw_hsa %&gt;% select(synergy_prob_ss, synergy_prob_prolif) %&gt;% rename(cal_mw_hsa = synergy_prob_ss, random_mw_hsa = synergy_prob_prolif), pred_mw_bliss %&gt;% select(synergy_prob_ss, synergy_prob_prolif) %&gt;% rename(cal_mw_bliss = synergy_prob_ss, random_mw_bliss = synergy_prob_prolif) ) M = cor(synergy_scores, method = &quot;kendall&quot;) res = cor.mtest(synergy_scores, method = &quot;kendall&quot;) corrplot(corr = M, type = &quot;upper&quot;, p.mat = res$p, sig.level = c(.001, .01, .05), pch.cex = 1, pch.col = &quot;white&quot;, insig = &quot;label_sig&quot;, tl.col = &quot;black&quot;, tl.srt = 45) Figure 12: Correlation Plot for CASCADE 1.0 Results Model-wise don’t correlate a lot with ensemble-wise results (topright part of the correlation plot). HSA and Bliss results correlate, higher for the model-wise (bottomright) than the ensemble-wise results (topleft). Calibrated results also show some correlation with the random results Fitness Evolution We did a test run of Gitsbe with \\(1000\\) simulations, fitting to steady state (generating thus calibrated models). The only difference between the following results and the ones above is the total number of simulations specified in the configuration and that the option bootstrap_mutations_factor was set to \\(1\\) (to avoid reaching good fitness models in the earlier generations). Firstly, we show the fitness evolution of the first \\(20\\) simulations. Each data point is the average fitness in that generation out of \\(20\\) models. Note that some simulations end because the target fitness is reached by some of the models (\\(0.99\\)). read_summary_file = function(file_name) { lines = readr::read_lines(file = file_name, skip = 5, skip_empty_rows = TRUE) data_list = list() index = 1 gen_fit_list = list() gen_index = 1 for (line_index in 1:length(lines)) { line = lines[line_index] if (stringr::str_detect(string = line, pattern = &quot;Simulation&quot;)) { data_list[[index]] = dplyr::bind_cols(gen_fit_list) index = index + 1 gen_fit_list = list() gen_index = 1 } else { # read fitness values gen_fit_list[[gen_index]] = tibble::as_tibble_col(as.numeric(unlist(strsplit(line, split = &#39;\\t&#39;))), column_name = paste0(gen_index)) gen_index = gen_index + 1 } } # add the last simulation&#39;s values data_list[[index]] = dplyr::bind_cols(gen_fit_list) return(data_list) } fitness_summary_file = &quot;results/link-only/cascade_1.0_ss_1000sim_fixpoints_hsa_summary.txt&quot; # `fit_res` is a list of tibbles # Each tibble has the fitness results of a simulation # Rows represent the models and columns are the generations fit_res = read_summary_file(file_name = fitness_summary_file) first_sim_data = colMeans(fit_res[[1]]) plot(1:length(first_sim_data), y = first_sim_data, ylim = c(0,1), xlim = c(0,20), type = &#39;l&#39;, lwd = 1.5, main = &#39;Fitness Evolution across Generations&#39;, xlab = &#39;Generations&#39;, ylab = &#39;Average Fitness&#39;, col = usefun:::colors.100[1]) index = 2 for (fit_data in fit_res) { if (index &gt; 20) break #if (ncol(fit_data) != 20) next mean_fit_per_gen = colMeans(fit_data) lines(x = 1:length(mean_fit_per_gen), y = mean_fit_per_gen, lwd = 1.5, col = usefun:::colors.100[index]) index = index + 1 } grid(lwd = 0.5) Figure 13: Fitness Evolution (20 simulations, CASCADE 1.0) Next, we plot the average fitness + standard deviation per generation across all \\(1000\\) simulations: # `avg_fit` is a tibble with rows the number of simulations and # columns the generations. Each value in a (sim,gen) cell is the average # fitness of models in that particular (sim,gen) combination avg_fit = do.call(dplyr::bind_rows, sapply(fit_res, colMeans)) avg_fit_long = avg_fit %&gt;% pivot_longer(cols = everything()) %&gt;% mutate(name = as.integer(name)) ggline(data = avg_fit_long, x = &quot;name&quot;, y = &quot;value&quot;, color = my_palette[2], add = &quot;mean_sd&quot;, add.params = list(color = &quot;black&quot;), ylim = c(0, 1), main = &quot;Fitness Evolution across Generations&quot;, xlab = &quot;Generations&quot;, ylab = &quot;Fitness&quot;) + theme(plot.title = element_text(hjust = 0.5)) + grids() Figure 14: Fitness Evolution (1000 simulations, CASCADE 1.0) # DIY way: # df = avg_fit_long %&gt;% group_by(name) %&gt;% # summarise(median = median(value, na.rm = TRUE), # mean = mean(value, na.rm = TRUE), # sd = sd(value, na.rm = TRUE)) # # ggplot(data = df, aes(x=name, y=mean)) + # ggtitle(&quot;Fitness Evolution across Generations&quot;) + # xlab(&quot;Generations&quot;) + ylab(&quot;Fitness&quot;) + # geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2) + # geom_line(color=&#39;steelblue&#39;) + # geom_point(color=&#39;steelblue&#39;) + # theme_pubr() + theme(plot.title = element_text(hjust = 0.5)) + # grids() The average fitness stabilizes after \\(\\approx 10-15\\) generations but also the standard deviation: new models are still being created through the crossover genetic algorithm phase to explore various model parameterization while keeping the fitness score relatively high. The S-shaped (sigmoid) curve is in agreement with Holland’s schema theorem (Holland 1992). Fitness vs Ensemble Performance We check for correlation between the calibrated models fitness to the AGS steady state and their ensemble performance subject to normalization to the random model predictions. The main idea here is that we generate different training data samples, in which the boolean steady state nodes have their values flipped (so they are only partially correct) and we fit models to these (\\(50\\) simulations =&gt; \\(150\\) models per training data, \\(205\\) training data samples in total). These calibrated model ensembles can then be tested for their prediction performance. Then we use the ensemble-wise random proliferative model predictions (\\(50\\) simulations) to normalize (\\(\\beta=-1\\)) against the calibrated model predictions and compute the AUC ROC and AUC PR for each model ensemble. Check how to generate the appropriate data, run the simulations and tidy up the results in the section Fitness vs Performance Methods. Load the already-stored result: res = readRDS(file = &quot;data/res_fit_aucs_cascade1.rds&quot;) We check if our data is normally distributed using the Shapiro-Wilk normality test: shapiro.test(x = res$roc_auc) Shapiro-Wilk normality test data: res$roc_auc W = 0.95822, p-value = 9.995e-06 shapiro.test(x = res$pr_auc) Shapiro-Wilk normality test data: res$pr_auc W = 0.86074, p-value = 9.719e-13 shapiro.test(x = res$avg_fit) Shapiro-Wilk normality test data: res$avg_fit W = 0.87328, p-value = 4.518e-12 We observe from the low p-values that the data is not normally distributed. Thus, we are going to use a non-parametric correlation metric, namely the Kendall rank-based test (and it’s respective coefficient, \\(\\tau\\)), to check for correlation between the ensemble model performance (ROC-AUC, PR-AUC) and the fitness to the AGS steady state: ggscatter(data = res, x = &quot;avg_fit&quot;, y = &quot;roc_auc&quot;, xlab = &quot;Average Fitness per Model Ensemble&quot;, title = &quot;Fitness to AGS Steady State vs Performance (ROC)&quot;, ylab = &quot;ROC AUC&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, label.y.npc = &quot;top&quot;, size = 6, cor.coef.name = &quot;tau&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 15: Fitness to AGS Steady State vs ROC-AUC Performance (CASCADE 1.0, Bliss synergy method, Ensemble-wise normalized results) ggscatter(data = res, x = &quot;avg_fit&quot;, y = &quot;pr_auc&quot;, xlab = &quot;Average Fitness per Model Ensemble&quot;, title = &quot;Fitness to AGS Steady State vs Performance (Precision-Recall)&quot;, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), ylab = &quot;PR AUC&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, size = 6, cor.coef.name = &quot;tau&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 16: Fitness to AGS Steady State vs PR-AUC Performance (CASCADE 1.0, Bliss synergy method, Ensemble-wise normalized results) We observe that there exists some correlation between the normalized ensemble model performance vs the models fitness to the training steady state data. The performance as measured by the ROC AUC is less sensitive to changes in the training data but there is better correlation with regards to the PR AUC, which is a more informative measure for our imbalanced dataset (Saito and Rehmsmeier 2015). Scrambled Topologies Investigation We create several scrambled topologies from the CASCADE 1.0 one, in order to assess the tolerance of the curated network topology to random edge changes with regards to model ensemble performance. We introduce \\(4\\) types of topology scrambling that are performed in a varying number of edges. The more edges are changed, the more scrambled/randomized is the resulting topology. The \\(4\\) types of scrambling are: Randomly permutating the source nodes of the edges (source) Randomly permutating the target nodes of the edges (target) Randomly changing the interaction effect from inhibition to activation and vice-versa (Sign Inversion) Combining all the above (all) Note that each type of scrambling produces a topology with the same input and output degree distribution as the original one and as such, the scale-free property of the CASCADE 1.0 topology remains unchanged in the scrambled topologies. For each different type of scrambling, we make \\(10\\) random topologies for each expected similarity score between the randomized and the curated topology, ranging from \\(0\\) similarity to \\(0.98\\) with a total of \\(22\\) steps, thus \\(10\\times22=220\\) random topologies per different type of scrambling. See more details on how to generate these topologies in the script gen_scrambled_topologies_cascade1.R. To get the drug combination predictions for each scrambled topology, we executed the druglogics-synergy module with the default configuration (\\(50\\) simulations per topology, for both calibrated to steady state and random proliferative models, using the Bliss synergy assessment method in Drabme) - see more info on the run_druglogics_synergy_scrambled_topo_cascade1.sh script. We calculate the normalized predictor performance (\\(calibrated - random\\)) for each topology-specific simulation and tidy up the result data in get_syn_res_scrambled_topo_cascade1.R. Next, we load the data results and add the ROC and PR AUC results of the combined predictor (termed Calibrated) for the curated CASCADE 1.0 topology (see above). Note that the topology scrambling type is set to none for the results that used the original/curated CASCADE 1.0 topology. scrambled_topo_res = readRDS(file = &#39;data/scrambled_topo_res_cascade1.rds&#39;) # the un-scrambled topology results have a similarity score equal to 1, &#39;none&#39; # scrambling whatsoever as `scramble_type`, and the ROC and PR AUC values have been previously # calculated and shown in the figures above but we re-do them here anyway :) res_comb_roc = PRROC::roc.curve(scores.class0 = pred_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed)) res_comb_pr = PRROC::pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed)) scrambled_topo_res = dplyr::bind_rows(scrambled_topo_res, tibble::tibble(sim = 1, scramble_type = &#39;none&#39;, roc_auc = res_comb_roc$auc, pr_auc = res_comb_pr$auc.davis.goadrich)) Interestingly, there were some scrambled topologies which didn’t produce not even \\(1\\) boolean model with a stable state when using the genetic algorithm of Gitsbe (so no predictions could be made for these topologies): ordered_types = c(&#39;none&#39;, &#39;source&#39;, &#39;target&#39;, &#39;sign&#39;, &#39;all&#39;) scrambled_topo_res %&gt;% mutate(scramble_type = replace(x = scramble_type, list = scramble_type == &#39;effect&#39;, values = &#39;sign&#39;)) %&gt;% group_by(scramble_type) %&gt;% summarise(percent = sum(is.na(roc_auc))/n(), .groups = &#39;drop&#39;) %&gt;% mutate(scramble_type = factor(scramble_type, levels = ordered_types)) %&gt;% ggplot(aes(x = scramble_type, y = percent, fill = scramble_type)) + geom_col() + geom_text(aes(label = scales::percent(percent, accuracy = 1)), vjust = -0.5, size = 8) + scale_y_continuous(labels = scales::percent, limits = c(0,0.3)) + scale_fill_brewer(palette = &quot;Set1&quot;) + guides(fill = guide_legend(title = latex2exp::TeX(&quot;Scramble Type&quot;))) + labs(x = &quot;&quot;, title = &quot;Topologies with zero-stable-state boolean models&quot;, y = &quot;&quot;) + theme_classic(base_size = 14) + theme(axis.text.x = element_text(size = 18)) Figure 17: Percentage of topologies that did not have any boolean model with a stable state after simulations with Gitsbe ended. Every possible topology scrambling type is represented. So potentially tweaking the source nodes of each edge in the curated topology, resulted in \\(11\\%\\) of the produced topologies to have a network configuration that wouldn’t allow the existence of attractor stability in the explored link-operator parameterization space of the Gitsbe algorithm. Tweaking the target nodes results in less topologies having this property (\\(5\\%\\)). Lastly, tweaking the effect (activation vs inhibition), we always get topologies that can be translated to boolean models with a stable state attractor. Source Scrambling In the next figures, the red dot/point is the result from using the original/unscrambled/curated CASCADE 1.0 topology: ggpubr::ggscatter(data = scrambled_topo_res %&gt;% filter(scramble_type == &#39;source&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)), x = &quot;sim&quot;, y = &quot;roc_auc&quot;, color = &quot;scramble_type&quot;, palette = c(&#39;red&#39;, &#39;black&#39;), xlab = &quot;Similarity Score&quot;, title = &quot;Source node Scrambling vs Performance (ROC)&quot;, ylab = &quot;ROC AUC&quot;) + #, add = &quot;reg.line&quot;, conf.int = TRUE, #add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), #cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, label.y.npc = &quot;top&quot;, size = 6, cor.coef.name = &quot;tau&quot;) + ylim(c(0,1)) + geom_text(x = 0.95, y = 1, label = &quot;CASCADE 1.0&quot;) + theme(plot.title = element_text(hjust = 0.5), legend.position = &#39;none&#39;) ggpubr::ggscatter(data = scrambled_topo_res %&gt;% filter(scramble_type == &#39;source&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)), x = &quot;sim&quot;, y = &quot;pr_auc&quot;, color = &quot;scramble_type&quot;, palette = c(&#39;red&#39;, &#39;black&#39;), xlab = &quot;Similarity Score&quot;, title = &quot;Source node Scrambling vs Performance (Precision-Recall)&quot;, ylab = &quot;PR AUC&quot;) + #add = &quot;reg.line&quot;, conf.int = TRUE, #add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), #cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, label.y.npc = &quot;top&quot;, size = 6, cor.coef.name = &quot;tau&quot;)) + ylim(c(0,1)) + geom_text(x = 0.9, y = 0.91, label = &quot;CASCADE 1.0&quot;) + theme(plot.title = element_text(hjust = 0.5), legend.position = &#39;none&#39;) Figure 18: Source node scrambling vs Performance (ROC and PR AUC) Target Scrambling ggpubr::ggscatter(data = scrambled_topo_res %&gt;% filter(scramble_type == &#39;target&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)), x = &quot;sim&quot;, y = &quot;roc_auc&quot;, color = &quot;scramble_type&quot;, palette = c(&#39;red&#39;, &#39;black&#39;), xlab = &quot;Similarity Score&quot;, title = &quot;Target node Scrambling vs Performance (ROC)&quot;, ylab = &quot;ROC AUC&quot;) + ylim(c(0,1)) + geom_text(x = 0.95, y = 1, label = &quot;CASCADE 1.0&quot;) + theme(plot.title = element_text(hjust = 0.5), legend.position = &#39;none&#39;) ggpubr::ggscatter(data = scrambled_topo_res %&gt;% filter(scramble_type == &#39;target&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)), x = &quot;sim&quot;, y = &quot;pr_auc&quot;, color = &quot;scramble_type&quot;, palette = c(&#39;red&#39;, &#39;black&#39;), xlab = &quot;Similarity Score&quot;, title = &quot;Target node Scrambling vs Performance (Precision-Recall)&quot;, ylab = &quot;PR AUC&quot;) + ylim(c(0,1)) + geom_text(x = 0.9, y = 0.91, label = &quot;CASCADE 1.0&quot;) + theme(plot.title = element_text(hjust = 0.5), legend.position = &#39;none&#39;) Figure 19: Target node scrambling vs Performance (ROC and PR AUC) Sign Inversion ggpubr::ggscatter(data = scrambled_topo_res %&gt;% filter(scramble_type == &#39;effect&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)), x = &quot;sim&quot;, y = &quot;roc_auc&quot;, color = &quot;scramble_type&quot;, palette = c(&#39;black&#39;, &#39;red&#39;), xlab = &quot;Similarity Score&quot;, title = &quot;Sign Inversion vs Performance (ROC)&quot;, ylab = &quot;ROC AUC&quot;) + ylim(c(0,1)) + geom_text(x = 0.9, y = 0.98, label = &quot;CASCADE 1.0&quot;) + theme(plot.title = element_text(hjust = 0.5), legend.position = &#39;none&#39;) ggpubr::ggscatter(data = scrambled_topo_res %&gt;% filter(scramble_type == &#39;effect&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)), x = &quot;sim&quot;, y = &quot;pr_auc&quot;, color = &quot;scramble_type&quot;, palette = c(&#39;black&#39;, &#39;red&#39;), xlab = &quot;Similarity Score&quot;, title = &quot;Sign Inversion vs Performance (Precision-Recall)&quot;, ylab = &quot;PR AUC&quot;) + ylim(c(0,1)) + geom_text(x = 0.9, y = 0.91, label = &quot;CASCADE 1.0&quot;) + theme(plot.title = element_text(hjust = 0.5), legend.position = &#39;none&#39;) Figure 20: Sign Inversion vs Performance (ROC and PR AUC) Source, Target Scrambling and Sign Inversion ggpubr::ggscatter(data = scrambled_topo_res %&gt;% filter(scramble_type == &#39;all&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)), x = &quot;sim&quot;, y = &quot;roc_auc&quot;, color = &quot;scramble_type&quot;, palette = c(&#39;black&#39;, &#39;red&#39;), xlab = &quot;Similarity Score&quot;, title = &quot;All types of Scrambling vs Performance (ROC)&quot;, ylab = &quot;ROC AUC&quot;) + ylim(c(0,1)) + geom_text(x = 0.95, y = 1, label = &quot;CASCADE 1.0&quot;) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 0.92, y = 0.45, label = &quot;Random (AUC = 0.5)&quot;), color = &#39;#377EB8&#39;) + theme(plot.title = element_text(hjust = 0.5), legend.position = &#39;none&#39;) ggpubr::ggscatter(data = scrambled_topo_res %&gt;% filter(scramble_type == &#39;all&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)), x = &quot;sim&quot;, y = &quot;pr_auc&quot;, color = &quot;scramble_type&quot;, palette = c(&#39;black&#39;, &#39;red&#39;), xlab = &quot;Similarity Score&quot;, title = &quot;All types of Scrambling vs Performance (Precision-Recall)&quot;, ylab = &quot;PR AUC&quot;) + ylim(c(0,1)) + geom_text(x = 0.9, y = 0.91, label = &quot;CASCADE 1.0&quot;) + geom_hline(yintercept = sum(observed)/length(observed), linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 0.83, y = 0.08, label = &quot;Random (AUC = 0.2)&quot;), color = &#39;#377EB8&#39;) + theme(plot.title = element_text(hjust = 0.5), legend.position = &#39;none&#39;) Figure 21: Source, Target node scrambling and Sign Inversion vs Performance (ROC and PR AUC) Bootstrap Calibrated Models + Boxplots Since almost all scrambled results (no matter the type of scrambling) are worse than the results we got when using the curated/unscrambled CASCADE 1.0 topology, we proceed to further generate bootstrap model predictions derived from the curated topology to assess if the results we had found weren’t artifacts and/or outliers. We generate a large pool of gitsbe models (\\(1000\\) simulations =&gt; \\(3000\\) models) and draw randomly a total of \\(50\\) batches of \\(50\\) models each and assess ROC and PR AUC performance for each one of these normalized to the random model predictions (see above). All these bootstrapped models will be part of one category called Curated. The rest of the scrambled topology data (that we presented in scatter plots) will be split to multiple groups based on their similarity score (percentage of common edges with curated topology) and we will visualize the different groups with boxplots. See more details on how to reproduce these simulation results here. Load the bootstrap results and tidy up the data: # add the bootstrapped results of the curated topology to the scrambled results scrambled_topo_res = readRDS(file = &#39;data/scrambled_topo_res_cascade1.rds&#39;) boot_cascade1_res = readRDS(file = &#39;data/boot_cascade1_res.rds&#39;) scrambled_topo_res = dplyr::bind_rows(scrambled_topo_res, boot_cascade1_res) # group by similarity score scrambled_topo_res = scrambled_topo_res %&gt;% mutate(grp = factor(x = case_when(sim &gt;= 0 &amp; sim &lt; 0.25 ~ &#39;0 - 0.25&#39;, sim &gt;= 0.25 &amp; sim &lt; 0.5 ~ &#39;0.25 - 0.5&#39;, sim &gt;= 0.5 &amp; sim &lt; 0.75 ~ &#39;0.5 - 0.75&#39;, sim &gt;= 0.75 &amp; sim &lt; 0.85 ~ &#39;0.75 - 0.85&#39;, sim &gt;= 0.85 &amp; sim &lt; 0.95 ~ &#39;0.85 - 0.95&#39;, sim &gt;= 0.95 &amp; sim &lt; 1 ~ &#39;0.95 - 1&#39;, sim == 1 ~ &#39;Curated&#39;), levels = c(&#39;0 - 0.25&#39;, &#39;0.25 - 0.5&#39;, &#39;0.5 - 0.75&#39;, &#39;0.75 - 0.85&#39;, &#39;0.85 - 0.95&#39;,&#39;0.95 - 1&#39;, &#39;Curated&#39;))) # ROC results scrambled_topo_res %&gt;% filter(scramble_type == &#39;source&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)) %&gt;% ggplot(aes(x = grp, y = roc_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 1.0 Topology&#39;, y = &#39;ROC AUC&#39;, title = &quot;Source Scrambling vs Performance (ROC)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 6.7, y = 0.45, label = &quot;Random (AUC = 0.5)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) # PR results scrambled_topo_res %&gt;% filter(scramble_type == &#39;source&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)) %&gt;% ggplot(aes(x = grp, y = pr_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 1.0 Topology&#39;, y = &#39;PR AUC&#39;, title = &quot;Source Scrambling vs Performance (Precision-Recall)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = sum(observed)/length(observed), linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 6.7, y = 0.15, label = &quot;Random (AUC = 0.2)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 22: Source node scrambling topologies + curated CASCADE 1.0 topology bootstrapped results (ROC and PR AUC) # ROC results scrambled_topo_res %&gt;% filter(scramble_type == &#39;target&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)) %&gt;% ggplot(aes(x = grp, y = roc_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 1.0 Topology&#39;, y = &#39;ROC AUC&#39;, title = &quot;Target Scrambling vs Performance (ROC)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 6.7, y = 0.45, label = &quot;Random (AUC = 0.5)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) # PR results scrambled_topo_res %&gt;% filter(scramble_type == &#39;target&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)) %&gt;% ggplot(aes(x = grp, y = pr_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 1.0 Topology&#39;, y = &#39;PR AUC&#39;, title = &quot;Target Scrambling vs Performance (Precision-Recall)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = sum(observed)/length(observed), linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 6.7, y = 0.13, label = &quot;Random (AUC = 0.2)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 23: Target node scrambling topologies + curated CASCADE 1.0 topology bootstrapped results (ROC and PR AUC) # ROC results scrambled_topo_res %&gt;% filter(scramble_type == &#39;effect&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)) %&gt;% ggplot(aes(x = grp, y = roc_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 1.0 Topology&#39;, y = &#39;ROC AUC&#39;, title = &quot;Sign Inversion vs Performance (ROC)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 6.7, y = 0.45, label = &quot;Random (AUC = 0.5)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) # PR results scrambled_topo_res %&gt;% filter(scramble_type == &#39;effect&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)) %&gt;% ggplot(aes(x = grp, y = pr_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 1.0 Topology&#39;, y = &#39;PR AUC&#39;, title = &quot;Sign Inversion vs Performance (Precision-Recall)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = sum(observed)/length(observed), linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 6.9, y = 0.15, label = &quot;Random (AUC = 0.2)&quot;), size = 3) + theme(plot.title = element_text(hjust = 0.5)) Figure 24: Sign Inverted topologies + curated CASCADE 1.0 topology bootstrapped results (ROC and PR AUC) # no data points in the (0.95-1) class set1_cols = RColorBrewer::brewer.pal(n = 7, name = &#39;Set1&#39;)[c(1:5,7)] # ROC results scrambled_topo_res %&gt;% filter(scramble_type == &#39;all&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)) %&gt;% ggplot(aes(x = grp, y = roc_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_manual(values = set1_cols) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 1.0 Topology&#39;, y = &#39;ROC AUC&#39;, title = &quot;All types of Scrambling vs Performance (ROC)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 5.8, y = 0.45, label = &quot;Random (AUC = 0.5)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) # PR results scrambled_topo_res %&gt;% filter(scramble_type == &#39;all&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)) %&gt;% ggplot(aes(x = grp, y = pr_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_manual(values = set1_cols) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 1.0 Topology&#39;, y = &#39;PR AUC&#39;, title = &quot;All types of Scrambling vs Performance (Precision-Recall)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = sum(observed)/length(observed), linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 5.8, y = 0.15, label = &quot;Random (AUC = 0.2)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 25: Source, Target node scrambling and sign inverted topologies + CASCADE 1.0 topology bootstrapped results (ROC and PR AUC) We observe that even a small perturbation/violation/scrambling of the curated topology (of any type) produces results close to random prediction that are significantly lower than the prediction results when using the curated CASCADE 1.0 topology. "],["cascade-2-0-analysis-link-operator-mutations.html", "CASCADE 2.0 Analysis (Link Operator Mutations) HSA results Bliss results Best ROC and PRC Correlation Fitness Evolution Fitness vs Ensemble Performance Scrambled Topologies Investigation", " CASCADE 2.0 Analysis (Link Operator Mutations) Performance of automatically parameterized models against SINTEF dataset (Flobak et al. 2019) HSA results HSA refers to the synergy method used in Drabme to assess the synergies from the gitsbe models We test performance using ROC and PR AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state (\\(50,100,150,200\\) simulations) Random models: fitted to proliferation profile (\\(150\\) simulations) Gitsbe models have mutations on link operator only Load results: # &#39;ss&#39; =&gt; calibrated models, &#39;prolif&#39; =&gt; random models # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; model-wise ## HSA results ss_hsa_ensemblewise_50sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_50sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) ss_hsa_modelwise_50sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_50sim_fixpoints_hsa_modelwise_synergies.tab&quot;) ss_hsa_ensemblewise_100sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_100sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) ss_hsa_modelwise_100sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_100sim_fixpoints_hsa_modelwise_synergies.tab&quot;) ss_hsa_ensemblewise_150sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_150sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) ss_hsa_modelwise_150sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_150sim_fixpoints_hsa_modelwise_synergies.tab&quot;) ss_hsa_ensemblewise_200sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_200sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) ss_hsa_modelwise_200sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_200sim_fixpoints_hsa_modelwise_synergies.tab&quot;) prolif_hsa_ensemblewise_file = paste0(&quot;results/link-only/cascade_2.0_rand_150sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) prolif_hsa_modelwise_file = paste0(&quot;results/link-only/cascade_2.0_rand_150sim_fixpoints_hsa_modelwise_synergies.tab&quot;) ss_hsa_ensemblewise_synergies_50sim = emba::get_synergy_scores(ss_hsa_ensemblewise_50sim_file) ss_hsa_modelwise_synergies_50sim = emba::get_synergy_scores(ss_hsa_modelwise_50sim_file, file_type = &quot;modelwise&quot;) ss_hsa_ensemblewise_synergies_100sim = emba::get_synergy_scores(ss_hsa_ensemblewise_100sim_file) ss_hsa_modelwise_synergies_100sim = emba::get_synergy_scores(ss_hsa_modelwise_100sim_file, file_type = &quot;modelwise&quot;) ss_hsa_ensemblewise_synergies_150sim = emba::get_synergy_scores(ss_hsa_ensemblewise_150sim_file) ss_hsa_modelwise_synergies_150sim = emba::get_synergy_scores(ss_hsa_modelwise_150sim_file, file_type = &quot;modelwise&quot;) ss_hsa_ensemblewise_synergies_200sim = emba::get_synergy_scores(ss_hsa_ensemblewise_200sim_file) ss_hsa_modelwise_synergies_200sim = emba::get_synergy_scores(ss_hsa_modelwise_200sim_file, file_type = &quot;modelwise&quot;) prolif_hsa_ensemblewise_synergies_150sim = emba::get_synergy_scores(prolif_hsa_ensemblewise_file) prolif_hsa_modelwise_synergies_150sim = emba::get_synergy_scores(prolif_hsa_modelwise_file, file_type = &quot;modelwise&quot;) # calculate probability of synergy in the modelwise results ss_hsa_modelwise_synergies_50sim = ss_hsa_modelwise_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_hsa_modelwise_synergies_100sim = ss_hsa_modelwise_synergies_100sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_hsa_modelwise_synergies_150sim = ss_hsa_modelwise_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_hsa_modelwise_synergies_200sim = ss_hsa_modelwise_synergies_200sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) prolif_hsa_modelwise_synergies_150sim = prolif_hsa_modelwise_synergies_150sim %&gt;% mutate(synergy_prob_prolif = synergies/(synergies + `non-synergies`)) observed_synergies_file = &#39;data/observed_synergies_cascade_2.0&#39; observed_synergies = emba::get_observed_synergies(observed_synergies_file) # 1 (positive/observed synergy) or 0 (negative/not observed) for all tested drug combinations observed = sapply(prolif_hsa_modelwise_synergies_150sim$perturbation %in% observed_synergies, as.integer) # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; model-wise pred_ew_hsa = bind_cols( ss_hsa_ensemblewise_synergies_50sim %&gt;% select(score) %&gt;% rename(ss_score_50sim = score), ss_hsa_ensemblewise_synergies_100sim %&gt;% select(score) %&gt;% rename(ss_score_100sim = score), ss_hsa_ensemblewise_synergies_150sim %&gt;% select(score) %&gt;% rename(ss_score_150sim = score), ss_hsa_ensemblewise_synergies_200sim %&gt;% select(score) %&gt;% rename(ss_score_200sim = score), prolif_hsa_ensemblewise_synergies_150sim %&gt;% select(score) %&gt;% rename(prolif_score_150sim = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_mw_hsa = bind_cols( ss_hsa_modelwise_synergies_50sim %&gt;% select(perturbation, synergy_prob_ss) %&gt;% rename(synergy_prob_ss_50sim = synergy_prob_ss), ss_hsa_modelwise_synergies_100sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_100sim = synergy_prob_ss), ss_hsa_modelwise_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_150sim = synergy_prob_ss), ss_hsa_modelwise_synergies_200sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_200sim = synergy_prob_ss), prolif_hsa_modelwise_synergies_150sim %&gt;% select(synergy_prob_prolif) %&gt;% rename(synergy_prob_prolif_150sim = synergy_prob_prolif), as_tibble_col(observed, column_name = &quot;observed&quot;)) ROC curves res_ss_ew_50sim = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;ss_score_50sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_100sim = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;ss_score_100sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_150sim = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;ss_score_150sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_200sim = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;ss_score_200sim&quot;, label_col = &quot;observed&quot;) res_prolif_ew_150sim = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;prolif_score_150sim&quot;, label_col = &quot;observed&quot;) res_ss_mw_50sim = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_ss_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_100sim = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_ss_100sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_150sim = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_ss_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_200sim = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_ss_200sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_prolif_mw_150sim = get_roc_stats(df = pred_mw_hsa, pred_col = &quot;synergy_prob_prolif_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs plot(x = res_ss_ew_50sim$roc_stats$FPR, y = res_ss_ew_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_ss_ew_100sim$roc_stats$FPR, y = res_ss_ew_100sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = res_ss_ew_150sim$roc_stats$FPR, y = res_ss_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = res_ss_ew_200sim$roc_stats$FPR, y = res_ss_ew_200sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) lines(x = res_prolif_ew_150sim$roc_stats$FPR, y = res_prolif_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[5]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:5], pch = 19, legend = c(paste(round(res_ss_ew_50sim$AUC, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(res_ss_ew_100sim$AUC, digits = 3), &quot;Calibrated (100 sim)&quot;), paste(round(res_ss_ew_150sim$AUC, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(res_ss_ew_200sim$AUC, digits = 3), &quot;Calibrated (200 sim)&quot;), paste(round(res_prolif_ew_150sim$AUC, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) plot(x = res_ss_mw_50sim$roc_stats$FPR, y = res_ss_mw_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_ss_mw_100sim$roc_stats$FPR, y = res_ss_mw_100sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = res_ss_mw_150sim$roc_stats$FPR, y = res_ss_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = res_ss_mw_200sim$roc_stats$FPR, y = res_ss_mw_200sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) lines(x = res_prolif_mw_150sim$roc_stats$FPR, y = res_prolif_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[5]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:5], pch = 19, legend = c(paste(round(res_ss_mw_50sim$AUC, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(res_ss_mw_100sim$AUC, digits = 3), &quot;Calibrated (100 sim)&quot;), paste(round(res_ss_mw_150sim$AUC, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(res_ss_mw_200sim$AUC, digits = 3), &quot;Calibrated (200 sim)&quot;), paste(round(res_prolif_mw_150sim$AUC, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) Figure 26: ROC curves (CASCADE 2.0, HSA synergy method) PR curves pr_ss_ew_hsa_50sim = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(ss_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_ss_ew_hsa_100sim = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(ss_score_100sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_ss_ew_hsa_150sim = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(ss_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_ss_ew_hsa_200sim = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(ss_score_200sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_prolif_ew_hsa_150sim = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(prolif_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_ss_mw_hsa_50sim = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(synergy_prob_ss_50sim), weights.class0 = pred_mw_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_ss_mw_hsa_100sim = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(synergy_prob_ss_100sim), weights.class0 = pred_mw_hsa %&gt;% pull(observed), curve = TRUE) pr_ss_mw_hsa_150sim = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(synergy_prob_ss_150sim), weights.class0 = pred_mw_hsa %&gt;% pull(observed), curve = TRUE) pr_ss_mw_hsa_200sim = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(synergy_prob_ss_200sim), weights.class0 = pred_mw_hsa %&gt;% pull(observed), curve = TRUE) pr_prolif_mw_hsa_150sim = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(synergy_prob_prolif_150sim), weights.class0 = pred_mw_hsa %&gt;% pull(observed), curve = TRUE) plot(pr_ss_ew_hsa_50sim, main = &#39;PR curve, Ensemble-wise synergies (HSA)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_ss_ew_hsa_100sim, add = TRUE, color = my_palette[2]) plot(pr_ss_ew_hsa_150sim, add = TRUE, color = my_palette[3]) plot(pr_ss_ew_hsa_200sim, add = TRUE, color = my_palette[4]) plot(pr_prolif_ew_hsa_150sim, add = TRUE, color = my_palette[5]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:5], pch = 19, legend = c(paste(round(pr_ss_ew_hsa_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_ss_ew_hsa_100sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (100 sim)&quot;), paste(round(pr_ss_ew_hsa_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_ss_ew_hsa_200sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (200 sim)&quot;), paste(round(pr_prolif_ew_hsa_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) plot(pr_ss_mw_hsa_50sim, main = &#39;PR curve, Model-wise synergies (HSA)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_ss_mw_hsa_100sim, add = TRUE, color = my_palette[2]) plot(pr_ss_mw_hsa_150sim, add = TRUE, color = my_palette[3]) plot(pr_ss_mw_hsa_200sim, add = TRUE, color = my_palette[4]) plot(pr_prolif_mw_hsa_150sim, add = TRUE, color = my_palette[5]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:5], pch = 19, legend = c(paste(round(pr_ss_mw_hsa_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_ss_mw_hsa_100sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (100 sim)&quot;), paste(round(pr_ss_mw_hsa_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_ss_mw_hsa_200sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (200 sim)&quot;), paste(round(pr_prolif_mw_hsa_150sim$auc.davis.goadrich, digits = 3), &quot;Random (200 sim)&quot;))) grid(lwd = 0.5) Figure 27: PR curves (CASCADE 2.0, HSA synergy method) To minimize the resulting performance variance, \\(150\\) seems to be a good number of Gitsbe simulations to run for the CASCADE 2.0 network. The PR curves show that the performance of each individual predictor is poor compared to the baseline. Someone looking at the ROC curves only, might reach a different conclusion. Random models perform almost equally well to calibrated models. The model-wise approach produces slightly better ROC results than the ensemble-wise approach AUC sensitivity Investigate same thing as described in here. This is very crucial since the PR performance is poor for the individual predictors, but a combined predictor might be able to counter this. We will combine the synergy scores from the random proliferative simulations with the results from the calibrated Gitsbe simulations (using the results from the \\(150\\) simulation runs). # Ensemble-wise betas = seq(from = -7.5, to = 7.5, by = 0.1) prolif_roc = sapply(betas, function(beta) { pred_ew_hsa = pred_ew_hsa %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = roc.curve(scores.class0 = pred_ew_hsa %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr = sapply(betas, function(beta) { pred_ew_hsa = pred_ew_hsa %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_ew = as_tibble(cbind(betas, prolif_roc, prolif_pr)) df_ew = df_ew %&gt;% tidyr::pivot_longer(-betas, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter (HSA, CASCADE 2.0)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + geom_vline(xintercept = 0) + geom_vline(xintercept = -1, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_text(aes(x=-1.5, label=&quot;β = -1&quot;, y=0.25), colour=&quot;black&quot;, angle=90) + grids() Figure 28: AUC sensitivity (CASCADE 2.0, HSA synergy method, Ensemble-wise results) # Model-wise weights = seq(from = 0, to = 1, by = 0.05) prolif_roc_mw = sapply(weights, function(w) { pred_mw_hsa = pred_mw_hsa %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_hsa$synergy_prob_ss_150sim + w * pred_mw_hsa$synergy_prob_prolif_150sim) res = roc.curve(scores.class0 = pred_mw_hsa %&gt;% pull(weighted_prob), weights.class0 = pred_mw_hsa %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr_mw = sapply(weights, function(w) { pred_mw_hsa = pred_mw_hsa %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_hsa$synergy_prob_ss_150sim + w * pred_mw_hsa$synergy_prob_prolif_150sim) res = pr.curve(scores.class0 = pred_mw_hsa %&gt;% pull(weighted_prob), weights.class0 = pred_mw_hsa %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_mw = as_tibble(cbind(weights, prolif_roc_mw, prolif_pr_mw)) df_mw = df_mw %&gt;% tidyr::pivot_longer(-weights, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_mw, x = &quot;weights&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;weight $w$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title.position = &quot;center&quot;, title = TeX(&quot;AUC sensitivity to weighted average score (HSA, CASCADE 2.0)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + grids() Figure 29: AUC sensitivity (CASCADE 2.0, HSA synergy method, Model-wise results) No added benefit when using the model-wise approach. The proliferative models seem to add a small contribution to the calibrated models performance (right panel ensemble-wise results =&gt; ROC-AUC increases, PR-AUC is insignificantly changed nonetheless). The \\(\\beta_{best}\\) that maximizes the ROC and PR AUC for the combination of random and calibrated models and is equal to \\(\\beta_{best}=-0.3\\). For \\(\\beta=-1\\) we do not observe performance improvement in this case. Logistic Regression Analysis We tried fitting a model using logistic regression as a different approach to combine/augment the results from calibrated simulations with the random proliferative ones (for the HSA-assessed ensemble-wise results where there was a minimal benefit). model = glm(formula = observed ~ ss_score_150sim + prolif_score_150sim - 1, data = pred_ew_hsa, family = binomial()) model_tidy = broom::tidy(model) coef1 = model_tidy %&gt;% filter(term == &quot;ss_score_150sim&quot;) %&gt;% pull(estimate) coef2 = model_tidy %&gt;% filter(term == &quot;prolif_score_150sim&quot;) %&gt;% pull(estimate) pred_ew_hsa = pred_ew_hsa %&gt;% mutate(glm = coef1 * ss_score_150sim + coef2 * prolif_score_150sim) res_roc = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;glm&quot;, label_col = &quot;observed&quot;) res_pr = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(glm) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed)) The model with the coefficients is as follows (note that adding an intercept makes ROC AUC result considerably worse): extract_eq(model, use_coefs = TRUE) \\[ \\log\\left[ \\frac { P( \\operatorname{observed} = \\operatorname{1} ) }{ 1 - P( \\operatorname{observed} = \\operatorname{1} ) } \\right] = -10.63(\\operatorname{ss\\_score\\_150sim}) + 42.92(\\operatorname{prolif\\_score\\_150sim}) + \\epsilon \\] The ROC AUC produced with a logistic regression model is lower than the calibrated models (with \\(150\\) Gitsbe simulations): 0.5782313 (PR-AUC is also lower: 0.0527052). Regularized Logistic Regression Analysis Because the coefficient values found from the above approach are large, we try a regularized logistic regression approach using the glmnet R package (Friedman et al. 2020). We cross validate the \\(\\lambda\\) parameter and try with different \\(\\alpha \\in [0,1]\\) (\\(\\alpha=0\\) means Ridge regression, \\(\\alpha=1\\) means LASSO, in between means Elastic net) while either minimizing the missclassification error (type.measure=\"class\") or maximizing the ROC-AUC (type.measure = \"auc\"). For each respective \\(\\alpha\\) we choose the \\(\\lambda_{min}\\) as the one the minimizes the average CV error. The intercept was again excluded as it resulted in worse AUC performance. x = pred_ew_hsa %&gt;% select(ss_score_150sim, prolif_score_150sim) %&gt;% as.matrix() y = pred_ew_hsa %&gt;% pull(observed) data_list = list() index = 1 for (i in 0:10) { # from Ridge to LASSO a = i/10 for (measure in c(&quot;auc&quot;, &quot;class&quot;)) { set.seed(42) # for reproducibility cvfit = cv.glmnet(x, y, family = &quot;binomial&quot;, type.measure = measure, intercept = FALSE, alpha = a) coef_mat = coef(cvfit, s = &quot;lambda.min&quot;) pred_ew_hsa = pred_ew_hsa %&gt;% mutate(glm_reg = coef_mat[1] + coef_mat[2] * ss_score_150sim + coef_mat[3] * prolif_score_150sim) res_roc = get_roc_stats(df = pred_ew_hsa, pred_col = &quot;glm_reg&quot;, label_col = &quot;observed&quot;) pr_roc = pr.curve(scores.class0 = pred_ew_hsa %&gt;% pull(glm_reg) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_hsa %&gt;% pull(observed)) data_list[[index]] = as_tibble_row(list(alpha = a, measure = measure, ROC_AUC = res_roc$AUC, PR_AUC = pr_roc$auc.davis.goadrich)) index = index + 1 } } data = bind_rows(data_list) # List the best two results data %&gt;% arrange(desc(ROC_AUC)) %&gt;% slice(1:4) %&gt;% kable() alpha measure ROC_AUC PR_AUC 0.0 auc 0.6802721 0.0623343 0.0 class 0.6802721 0.0623343 0.1 auc 0.5770975 0.0527103 0.2 auc 0.5770975 0.0527103 The best ROC AUC produced with a regularized logistic regression model is also lower than the one using calibrated models alone (with \\(150\\) Gitsbe simulations). Note that we get warnings when using glmnet because of the small number of observations for the positive class (observed synergies). Resulting coefficients vary, but tend to be either all too small or larger on the random proliferative model predictor. MAMSE ROC Analysis Using the MAMSE R package (Plante 2017) we try another method to combine the predictor values from the calibrated and the random proliferative models. The resulting ROC curve gets a little bit distorted and AUC is not statistically better from the reference sample population (i.e. the calibrated Gitsbe models with \\(150\\) simulations): # healthy =&gt; non-synergy, diseased =&gt; synergy healthy = list() healthy[[1]] = pred_ew_hsa %&gt;% filter(observed == 0) %&gt;% pull(ss_score_150sim) healthy[[2]] = pred_ew_hsa %&gt;% filter(observed == 0) %&gt;% pull(prolif_score_150sim) diseased = list() diseased[[1]] = pred_ew_hsa %&gt;% filter(observed == 1) %&gt;% pull(ss_score_150sim) diseased[[2]] = pred_ew_hsa %&gt;% filter(observed == 1) %&gt;% pull(prolif_score_150sim) plot(roc(healthy = healthy, diseased = diseased, smalldiseased=TRUE, AUC=TRUE, wh=NULL, wd=NULL, FPR=NULL, method=&quot;np&quot;)) Figure 30: Combined Ensemble-wise Classifier using MAMSE ROC (CASCADE 2.0, HSA) Bliss results Bliss refers to the synergy method used in Drabme to assess the synergies from the gitsbe models We test performance using ROC and PR AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state (\\(50,100,150,200\\) simulations) Random models: fitted to proliferation profile (\\(150\\) simulations) Gitsbe models have mutations on link operator only Load results: # &#39;ss&#39; =&gt; calibrated models, &#39;prolif&#39; =&gt; random proliferative models ## Bliss results ss_bliss_ensemblewise_50sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_50sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_50sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_50sim_fixpoints_bliss_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_100sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_100sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_100sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_100sim_fixpoints_bliss_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_150sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_150sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_150sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_150sim_fixpoints_bliss_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_200sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_200sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) ss_bliss_modelwise_200sim_file = paste0(&quot;results/link-only/cascade_2.0_ss_200sim_fixpoints_bliss_modelwise_synergies.tab&quot;) prolif_bliss_ensemblewise_150sim_file = paste0(&quot;results/link-only/cascade_2.0_rand_150sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) prolif_bliss_modelwise_150sim_file = paste0(&quot;results/link-only/cascade_2.0_rand_150sim_fixpoints_bliss_modelwise_synergies.tab&quot;) ss_bliss_ensemblewise_synergies_50sim = emba::get_synergy_scores(ss_bliss_ensemblewise_50sim_file) ss_bliss_modelwise_synergies_50sim = emba::get_synergy_scores(ss_bliss_modelwise_50sim_file, file_type = &quot;modelwise&quot;) ss_bliss_ensemblewise_synergies_100sim = emba::get_synergy_scores(ss_bliss_ensemblewise_100sim_file) ss_bliss_modelwise_synergies_100sim = emba::get_synergy_scores(ss_bliss_modelwise_100sim_file, file_type = &quot;modelwise&quot;) ss_bliss_ensemblewise_synergies_150sim = emba::get_synergy_scores(ss_bliss_ensemblewise_150sim_file) ss_bliss_modelwise_synergies_150sim = emba::get_synergy_scores(ss_bliss_modelwise_150sim_file, file_type = &quot;modelwise&quot;) ss_bliss_ensemblewise_synergies_200sim = emba::get_synergy_scores(ss_bliss_ensemblewise_200sim_file) ss_bliss_modelwise_synergies_200sim = emba::get_synergy_scores(ss_bliss_modelwise_200sim_file, file_type = &quot;modelwise&quot;) prolif_bliss_ensemblewise_synergies_150sim = emba::get_synergy_scores(prolif_bliss_ensemblewise_150sim_file) prolif_bliss_modelwise_synergies_150sim = emba::get_synergy_scores(prolif_bliss_modelwise_150sim_file, file_type = &quot;modelwise&quot;) # calculate probability of synergy in the modelwise results ss_bliss_modelwise_synergies_50sim = ss_bliss_modelwise_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_bliss_modelwise_synergies_100sim = ss_bliss_modelwise_synergies_100sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_bliss_modelwise_synergies_150sim = ss_bliss_modelwise_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) ss_bliss_modelwise_synergies_200sim = ss_bliss_modelwise_synergies_200sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) prolif_bliss_modelwise_synergies_150sim = prolif_bliss_modelwise_synergies_150sim %&gt;% mutate(synergy_prob_prolif = synergies/(synergies + `non-synergies`)) # tidy data pred_ew_bliss = bind_cols( ss_bliss_ensemblewise_synergies_50sim %&gt;% select(perturbation, score) %&gt;% rename(ss_score_50sim = score), ss_bliss_ensemblewise_synergies_100sim %&gt;% select(score) %&gt;% rename(ss_score_100sim = score), ss_bliss_ensemblewise_synergies_150sim %&gt;% select(score) %&gt;% rename(ss_score_150sim = score), ss_bliss_ensemblewise_synergies_200sim %&gt;% select(score) %&gt;% rename(ss_score_200sim = score), prolif_bliss_ensemblewise_synergies_150sim %&gt;% select(score) %&gt;% rename(prolif_score_150sim = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_mw_bliss = bind_cols( ss_bliss_modelwise_synergies_50sim %&gt;% select(perturbation, synergy_prob_ss) %&gt;% rename(synergy_prob_ss_50sim = synergy_prob_ss), ss_bliss_modelwise_synergies_100sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_100sim = synergy_prob_ss), ss_bliss_modelwise_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_150sim = synergy_prob_ss), ss_bliss_modelwise_synergies_200sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_200sim = synergy_prob_ss), prolif_bliss_modelwise_synergies_150sim %&gt;% select(synergy_prob_prolif) %&gt;% rename(synergy_prob_prolif_150sim = synergy_prob_prolif), as_tibble_col(observed, column_name = &quot;observed&quot;)) ROC curves # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; model-wise res_ss_ew_50sim = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score_50sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_100sim = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score_100sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_150sim = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score_150sim&quot;, label_col = &quot;observed&quot;) res_ss_ew_200sim = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;ss_score_200sim&quot;, label_col = &quot;observed&quot;) res_prolif_ew_150sim = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;prolif_score_150sim&quot;, label_col = &quot;observed&quot;) res_ss_mw_50sim = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_100sim = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss_100sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_150sim = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_ss_mw_200sim = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_ss_200sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) res_prolif_mw_150sim = get_roc_stats(df = pred_mw_bliss, pred_col = &quot;synergy_prob_prolif_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs plot(x = res_ss_ew_50sim$roc_stats$FPR, y = res_ss_ew_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_ss_ew_100sim$roc_stats$FPR, y = res_ss_ew_100sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = res_ss_ew_150sim$roc_stats$FPR, y = res_ss_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = res_ss_ew_200sim$roc_stats$FPR, y = res_ss_ew_200sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) lines(x = res_prolif_ew_150sim$roc_stats$FPR, y = res_prolif_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[5]) legend(&#39;topleft&#39;, title = &#39;AUC&#39;, col = my_palette[1:5], pch = 19, legend = c(paste(round(res_ss_ew_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(res_ss_ew_100sim$AUC, digits = 2), &quot;Calibrated (100 sim)&quot;), paste(round(res_ss_ew_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(res_ss_ew_200sim$AUC, digits = 2), &quot;Calibrated (200 sim)&quot;), paste(round(res_prolif_ew_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) plot(x = res_ss_mw_50sim$roc_stats$FPR, y = res_ss_mw_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_ss_mw_100sim$roc_stats$FPR, y = res_ss_mw_100sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = res_ss_mw_150sim$roc_stats$FPR, y = res_ss_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = res_ss_mw_200sim$roc_stats$FPR, y = res_ss_mw_200sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) lines(x = res_prolif_mw_150sim$roc_stats$FPR, y = res_prolif_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[5]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:5], pch = 19, cex = 0.9, legend = c(paste(round(res_ss_mw_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(res_ss_mw_100sim$AUC, digits = 2), &quot;Calibrated (100 sim)&quot;), paste(round(res_ss_mw_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(res_ss_mw_200sim$AUC, digits = 2), &quot;Calibrated (200 sim)&quot;), paste(round(res_prolif_mw_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) Figure 31: ROC curves (CASCADE 2.0, Bliss synergy method) PR curves pr_ss_ew_bliss_50sim = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(ss_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_ss_ew_bliss_100sim = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(ss_score_100sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_ss_ew_bliss_150sim = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(ss_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_ss_ew_bliss_200sim = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(ss_score_200sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_prolif_ew_bliss_150sim = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(prolif_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_ss_mw_bliss_50sim = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(synergy_prob_ss_50sim), weights.class0 = pred_mw_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_ss_mw_bliss_100sim = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(synergy_prob_ss_100sim), weights.class0 = pred_mw_bliss %&gt;% pull(observed), curve = TRUE) pr_ss_mw_bliss_150sim = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(synergy_prob_ss_150sim), weights.class0 = pred_mw_bliss %&gt;% pull(observed), curve = TRUE) pr_ss_mw_bliss_200sim = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(synergy_prob_ss_200sim), weights.class0 = pred_mw_bliss %&gt;% pull(observed), curve = TRUE) pr_prolif_mw_bliss_150sim = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(synergy_prob_prolif_150sim), weights.class0 = pred_mw_bliss %&gt;% pull(observed), curve = TRUE) plot(pr_ss_ew_bliss_50sim, main = &#39;PR curve, Ensemble-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_ss_ew_bliss_100sim, add = TRUE, color = my_palette[2]) plot(pr_ss_ew_bliss_150sim, add = TRUE, color = my_palette[3]) plot(pr_ss_ew_bliss_200sim, add = TRUE, color = my_palette[4]) plot(pr_prolif_ew_bliss_150sim, add = TRUE, color = my_palette[5]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:6], pch = 19, legend = c(paste(round(pr_ss_ew_bliss_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_ss_ew_bliss_100sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (100 sim)&quot;), paste(round(pr_ss_ew_bliss_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_ss_ew_bliss_200sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (200 sim)&quot;), paste(round(pr_prolif_ew_bliss_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) plot(pr_ss_mw_bliss_50sim, main = &#39;PR curve, Model-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_ss_mw_bliss_100sim, add = TRUE, color = my_palette[2]) plot(pr_ss_mw_bliss_150sim, add = TRUE, color = my_palette[3]) plot(pr_ss_mw_bliss_200sim, add = TRUE, color = my_palette[4]) plot(pr_prolif_mw_bliss_150sim, add = TRUE, color = my_palette[5]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:5], pch = 19, legend = c(paste(round(pr_ss_mw_bliss_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_ss_mw_bliss_100sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (100 sim)&quot;), paste(round(pr_ss_mw_bliss_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_ss_mw_bliss_200sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (200 sim)&quot;), paste(round(pr_prolif_mw_bliss_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) Figure 32: PR curves (CASCADE 2.0, Bliss synergy method) To minimize the resulting performance variance, \\(150\\) seems to be a good number of Gitsbe simulations to run for the CASCADE 2.0 network. Individual predictor model-wise results (when looking at the ROC curves) show good performance. Individual predictor ensemble-wise results show that random and calibrated models have poor performance. The PR curves show that the performance of all individual predictors is poor compared to the baseline. Bootstrap Random Model AUC In the previous ROC and PR curves we found a very low ensemble-wise random (proliferative) model performance, indicated by the low numbers of ROC and PR AUC. We want to assess the statistical significance of this result, by bootstrapping many model samples from a pool of random models and evaluating the performance of these ensembles. For more details on how to generate the bootstrapped model ensembles and tidy up the result data, see section Random Model Bootstrap. As we can see below, the random model performance if indeed very close to the median of the bootstrapped AUCs: rand_res = readRDS(file = &quot;data/bootstrap_rand_res.rds&quot;) ggboxplot(data = rand_res, y = &quot;roc_auc&quot;, title = &quot;Bootstrap Random Models (ROC)&quot;, xlab = &quot;&quot;, ylab = &quot;ROC AUC&quot;, fill = &quot;gray&quot;) + theme(plot.title = element_text(hjust = 0.5)) + rremove(&quot;x.text&quot;) + rremove(&quot;x.ticks&quot;) ggboxplot(data = rand_res, y = &quot;pr_auc&quot;, title = &quot;Bootstrap Random Models (Precision-Recall)&quot;, xlab = &quot;&quot;, ylab = &quot;PR AUC&quot;, fill = &quot;gray&quot;) + theme(plot.title = element_text(hjust = 0.5)) + rremove(&quot;x.text&quot;) + rremove(&quot;x.ticks&quot;) Figure 33: Random Model Bootstrap: ROC and PR AUCs (CASCADE 2.0, Bliss synergy method) AUC sensitivity Investigate same thing as described in here. This is very crucial since the PR performance is poor for the individual predictors and the ensemble-wise predictors were really bad in terms of AUC-ROC, but a combined predictor might be able to counter this. We will combine the synergy scores from the random proliferative simulations with the results from the calibrated Gitsbe simulations (number of simulations: \\(150\\)). # Ensemble-wise betas = seq(from = -5, to = 5, by = 0.1) prolif_roc = sapply(betas, function(beta) { pred_ew_bliss = pred_ew_bliss %&gt;% mutate(combined_score = ss_score_50sim + beta * prolif_score_150sim) res = roc.curve(scores.class0 = pred_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr = sapply(betas, function(beta) { pred_ew_bliss = pred_ew_bliss %&gt;% mutate(combined_score = ss_score_50sim + beta * prolif_score_150sim) res = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_ew = as_tibble(cbind(betas, prolif_roc, prolif_pr)) df_ew = df_ew %&gt;% tidyr::pivot_longer(-betas, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, ylim = c(0,0.85), panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + geom_vline(xintercept = 0) + geom_vline(xintercept = -1.6, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_vline(xintercept = -1, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_text(aes(x=-2, y=0.4, label=&quot;β = -1.6&quot;), angle=90, colour=&quot;black&quot;) + geom_text(aes(x=-0.75, y=0.38, label=&quot;β = -1&quot;), angle=90, colour=&quot;black&quot;) + grids() Figure 34: AUC sensitivity (CASCADE 2.0, Bliss synergy method, Ensemble-wise results) # Model-wise weights = seq(from = 0, to = 1, by = 0.05) prolif_roc_mw = sapply(weights, function(w) { pred_mw_bliss = pred_mw_bliss %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_bliss$synergy_prob_ss_150sim + w * pred_mw_bliss$synergy_prob_prolif_150sim) res = roc.curve(scores.class0 = pred_mw_bliss %&gt;% pull(weighted_prob), weights.class0 = pred_mw_bliss %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr_mw = sapply(weights, function(w) { pred_mw_bliss = pred_mw_bliss %&gt;% mutate(weighted_prob = (1 - w) * pred_mw_bliss$synergy_prob_ss_150sim + w * pred_mw_bliss$synergy_prob_prolif_150sim) res = pr.curve(scores.class0 = pred_mw_bliss %&gt;% pull(weighted_prob), weights.class0 = pred_mw_bliss %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_mw = as_tibble(cbind(weights, prolif_roc_mw, prolif_pr_mw)) df_mw = df_mw %&gt;% tidyr::pivot_longer(-weights, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_mw, x = &quot;weights&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;weight $w$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title.position = &quot;center&quot;, title = TeX(&quot;AUC sensitivity to weighted average score (Bliss, CASCADE 2.0)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + grids() Figure 35: AUC sensitivity (CASCADE 2.0, Bliss synergy method, Model-wise results) No added benefit when using the model-wise approach. The random proliferative models can be used to normalize against the predictions of the calibrated models and thus bring significant contribution to the calibrated models performance (both ROC-AUC and PR-AUC are increased). The \\(\\beta_{best}\\) that maximizes the ROC and PR AUC for the combination of proliferative and calibrated models and is equal to \\(\\beta_{best}=-1.6\\). For \\(\\beta=-1\\) we still see significant performance improvement. Best ROC and PRC For the Bliss ensemble-wise results we demonstrated above that a value of \\(\\beta_{best}=-1.6\\) can result in significant performance gain of the combined predictor (\\(calibrated + \\beta \\times random\\)) using the results from the \\(150\\) simulation runs (the results for \\(\\beta=-1\\) were still better than the single predictors). Here, we present the ROC and PR curves for the calibrated (normalized to random model) predictions compared to the random proliferative model results. Only for the next plot, Calibrated stands for the combined predictor results, i.e. \\(calibrated + \\beta \\times random, \\beta=-1\\). best_beta1 = -1.6 best_beta2 = -1 pred_ew_bliss = pred_ew_bliss %&gt;% mutate(best_score1 = ss_score_150sim + best_beta1 * prolif_score_150sim, best_score2 = ss_score_150sim + best_beta2 * prolif_score_150sim) roc_best_res1 = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;best_score1&quot;, label_col = &quot;observed&quot;) roc_best_res2 = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;best_score2&quot;, label_col = &quot;observed&quot;) pr_best_res1 = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(best_score1) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_best_res2 = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(best_score2) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) # Plot best ROCs plot(x = roc_best_res2$roc_stats$FPR, y = roc_best_res2$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = (&#39;ROC curve, Ensemble-wise synergies (Bliss)&#39;), xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = res_prolif_ew_150sim$roc_stats$FPR, y = res_prolif_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) #lines(x = roc_best_res1$roc_stats$FPR, y = roc_best_res1$roc_stats$TPR, # lwd = 2, col = my_palette[3]) legend(&#39;topleft&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, cex = 1.5, legend = c(paste(round(roc_best_res2$AUC, digits = 2), &#39;Calibrated&#39;), paste(round(res_prolif_ew_150sim$AUC, digits = 2), &#39;Random&#39;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) # Plot best PRCs plot(pr_best_res2, main = &#39;PR curve, Ensemble-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE, lwd = 3) plot(pr_prolif_ew_bliss_150sim, add = TRUE, color = my_palette[2], lwd = 3) #plot(pr_best_res1, add = TRUE, color = my_palette[3], lwd = 2) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:2], pch = 19, cex = 1.5, legend = c(paste(round(pr_best_res2$auc.davis.goadrich, digits = 2), &#39;Calibrated&#39;), paste(round(pr_ss_ew_bliss_150sim$auc.davis.goadrich, digits = 2), &#39;Random&#39;))) grid(lwd = 0.5) Figure 36: ROC and PR curves for Random and Combined Predictor (CASCADE 2.0, Link Operator Mutations) The ROC ensemble-wise statistics data for the combined predictor (\\(\\beta=-1\\), the Calibrated in the above plot) are as follows: DT::datatable(data = roc_best_res2$roc_stats, options = list(pageLength = 5, lengthMenu = c(5, 20, 40), searching = FALSE)) %&gt;% formatRound(c(1,6,7,8,9), digits = 3) Figure 37: ROC data for Best Combined Predictor (CASCADE 2.0, Link Operator Mutations, Bliss synergy method) # TP synergies at a specified threshold (0 below) # pred_ew_bliss %&gt;% # select(perturbation, observed, best_score2) %&gt;% # filter(best_score2 &lt; 0, observed == 1) # investigate the average threshold as a synergy classification index # thres = roc_best_res2$roc_stats %&gt;% pull(threshold) # thres = thres[is.finite(thres)] # remove Inf&#39;s # roc_best_res2$roc_stats %&gt;% # filter(threshold &lt; mean(thres)) %&gt;% # slice(n()) %&gt;% kable() Correlation We test for correlation between some of the results shown in the ROC curves. The results tested are the ensemble-wise vs model-wise, random models vs calibrated models and HSA vs Bliss synergy assessment (the calibrated and proliferative models are from the \\(150\\) simulation results). P-values are represented at 3 significant levels: \\(0.05, 0.01, 0.001\\) (*, **, ***) and the correlation coefficient is calculated using Kendall’s tau statistic. synergy_scores = bind_cols( pred_ew_hsa %&gt;% select(ss_score_150sim, prolif_score_150sim) %&gt;% rename(cal_ew_hsa = ss_score_150sim, random_ew_hsa = prolif_score_150sim), pred_ew_bliss %&gt;% select(ss_score_150sim, prolif_score_150sim) %&gt;% rename(cal_ew_bliss = ss_score_150sim, random_ew_bliss = prolif_score_150sim), pred_mw_hsa %&gt;% select(synergy_prob_ss_150sim, synergy_prob_prolif_150sim) %&gt;% rename(cal_mw_hsa = synergy_prob_ss_150sim, random_mw_hsa = synergy_prob_prolif_150sim), pred_mw_bliss %&gt;% select(synergy_prob_ss_150sim, synergy_prob_prolif_150sim) %&gt;% rename(cal_mw_bliss = synergy_prob_ss_150sim, random_mw_bliss = synergy_prob_prolif_150sim) ) M = cor(synergy_scores, method = &quot;kendall&quot;) res = cor.mtest(synergy_scores, method = &quot;kendall&quot;) corrplot(corr = M, type = &quot;upper&quot;, p.mat = res$p, sig.level = c(.001, .01, .05), pch.cex = 1, pch.col = &quot;white&quot;, insig = &quot;label_sig&quot;, tl.col = &quot;black&quot;, tl.srt = 45) Figure 38: Correlation Plot for CASCADE 2.0 Results Bliss ensemble-wise results don’t correlate at all with the model-wise results (topright part of the correlation plot). The HSA ensemble-wise results do so (at some degree). Between the ensemble-wise results there is no strong correlation (topleft) while between the model-wise (bottomright) there is strong correlation. Fitness Evolution Results are from the run with \\(200\\) Gitsbe simulations, fitting to steady state (calibrated models). fitness_summary_file = &quot;results/link-only/cascade_2.0_ss_200sim_fixpoints_hsa_summary.txt&quot; fit_res = read_summary_file(file_name = fitness_summary_file) # rows = simulations, columns = generations # value in (sim,gen) cell = average fitness of models in that particular (sim,gen) combination avg_fit_link = do.call(dplyr::bind_rows, sapply(fit_res, colMeans)) colnames(avg_fit_link) = 1:ncol(avg_fit_link) avg_fit_long_link = avg_fit_link %&gt;% pivot_longer(cols = everything()) %&gt;% mutate(name = as.integer(name)) ggline(data = avg_fit_long_link, x = &quot;name&quot;, y = &quot;value&quot;, color = my_palette[2], add = &quot;mean_sd&quot;, add.params = list(color = &quot;black&quot;), main = &quot;Fitness Evolution across Generations&quot;, xlab = &quot;Generations&quot;, ylab = &quot;Fitness&quot;) + theme(plot.title = element_text(hjust = 0.5)) + grids() Figure 39: Fitness Evolution (200 simulations, link operator mutations, CASCADE 2.0) Fitness vs Ensemble Performance We check for correlation between the calibrated models fitness to the AGS steady state and their ensemble performance subject to normalization to the random model predictions. The main idea here is that we generate different training data samples, in which the boolean steady state nodes have their values flipped (so they are only partially correct) and we fit models to these (\\(20\\) simulations =&gt; \\(60\\) models per training data, \\(205\\) training data samples in total). These calibrated model ensembles can then be tested for their prediction performance. Then we use the ensemble-wise random proliferative model predictions (\\(150\\) simulations) to normalize (\\(\\beta=-1\\)) against the calibrated model predictions and compute the AUC ROC and AUC PR for each model ensemble. Check how to generate the appropriate data, run the simulations and tidy up the results in the section Fitness vs Performance Methods. Load the already-stored result: res = readRDS(file = &quot;data/res_fit_aucs.rds&quot;) We check if our data is normally distributed using the Shapiro-Wilk normality test: shapiro.test(x = res$roc_auc) Shapiro-Wilk normality test data: res$roc_auc W = 0.92436, p-value = 8.883e-09 shapiro.test(x = res$pr_auc) Shapiro-Wilk normality test data: res$pr_auc W = 0.94464, p-value = 4.475e-07 shapiro.test(x = res$avg_fit) Shapiro-Wilk normality test data: res$avg_fit W = 0.89506, p-value = 8.472e-11 We observe from the low p-values that the data is not normally distributed. Thus, we are going to use a non-parametric correlation metric, namely the Kendall rank-based test (and it’s respective coefficient, \\(\\tau\\)), to check for correlation between the ensemble model performance (ROC-AUC, PR-AUC) and the fitness to the AGS steady state: ggscatter(data = res, x = &quot;avg_fit&quot;, y = &quot;roc_auc&quot;, xlab = &quot;Average Fitness per Model Ensemble&quot;, title = &quot;Fitness to AGS Steady State vs Performance (ROC)&quot;, ylab = &quot;ROC AUC&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, label.y.npc = &quot;bottom&quot;, size = 6, cor.coef.name = &quot;tau&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 40: Fitness to AGS Steady State vs ROC-AUC Performance (CASCADE 2.0, Bliss synergy method, Ensemble-wise normalized results) ggscatter(data = res, x = &quot;avg_fit&quot;, y = &quot;pr_auc&quot;, xlab = &quot;Average Fitness per Model Ensemble&quot;, title = &quot;Fitness to AGS Steady State vs Performance (Precision-Recall)&quot;, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), ylab = &quot;PR AUC&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, size = 6, cor.coef.name = &quot;tau&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 41: Fitness to AGS Steady State vs PR-AUC Performance (CASCADE 2.0, Bliss synergy method, Ensemble-wise normalized results) We observe that there exists some correlation between the normalized ensemble model performance vs the models fitness to the training steady state data. The performance as measured by the ROC AUC is less sensitive to changes in the training data but there is better correlation with regards to the PR AUC, which is a more informative measure for our imbalanced dataset (Saito and Rehmsmeier 2015). Scrambled Topologies Investigation We create several scrambled topologies from the CASCADE 2.0 one, in order to assess the tolerance of the curated network topology to random edge changes with regards to model ensemble performance using link-operator mutations. For more details see the same investigation done for CASCADE 1.0. For each of the \\(4\\) different types of scrambling, we make \\(10\\) random topologies for each expected similarity score between the randomized and the curated topology, ranging from \\(0\\) to \\(0.99\\) similarity with a total of \\(23\\) steps, thus \\(10\\times23=230\\) random topologies per different type of scrambling. See more details on how to generate these topologies in the script gen_scrambled_topologies_cascade2.R. To get the drug combination predictions for each scrambled topology, we executed the druglogics-synergy module with the default configuration (\\(50\\) simulations per topology, for both calibrated to steady state and random proliferative models, using the Bliss synergy assessment method in Drabme). Note that because of the CASCADE 2.0 network size and the amount of simulations for this analysis, we had to switch to the faster BNReduction attractor tool for the calculation of fixpoints (Veliz-Cuba et al. 2014). See discussion here for limitations of the use of the bnet_reduction_reduced attractor tool option in our configuration file and to execute the simulations with the scrambled topologies use the run_druglogics_synergy_scrambled_topo_cascade2.sh script. We calculate the normalized predictor performance (\\(calibrated - random\\)) for each topology-specific simulation and tidy up the result data in get_syn_res_scrambled_topo_cascade2.R. Next, we load the scrambled topologies simulation results and also add the ROC and PR AUC results of the link-operator bootstrapped model analysis (see section below). The results are split to multiple groups, based on their similarity score (percentage of common edges with the curated CASCADE 2.0 topology). Note that the topology scrambling type is set to none for the bootstrap results that used the original/curated CASCADE 2.0 topology. # results from the scrambled topology simulations scrambled_topo_res = readRDS(file = &#39;data/scrambled_topo_res_cascade2.rds&#39;) # results from bootstrap parameterization analysis boot_res = readRDS(file = &quot;data/res_param_boot_aucs.rds&quot;) # the un-scrambled topology results have a similarity score equal to 1, # and &#39;none&#39; scrambling whatsoever as `scramble_type` lo_boot_res = boot_res %&gt;% add_column(sim = 1, scramble_type = &#39;none&#39;, .before = 1) %&gt;% filter(param == &#39;link-only&#39;) %&gt;% # keep only the link-operator results select(-one_of(&quot;param&quot;)) # remove unwanted column scrambled_topo_res = dplyr::bind_rows(scrambled_topo_res, lo_boot_res) # group results by similarity score scrambled_topo_res = scrambled_topo_res %&gt;% mutate(grp = factor(x = case_when(sim &gt;= 0 &amp; sim &lt; 0.25 ~ &#39;0 - 0.25&#39;, sim &gt;= 0.25 &amp; sim &lt; 0.5 ~ &#39;0.25 - 0.5&#39;, sim &gt;= 0.5 &amp; sim &lt; 0.75 ~ &#39;0.5 - 0.75&#39;, sim &gt;= 0.75 &amp; sim &lt; 0.85 ~ &#39;0.75 - 0.85&#39;, sim &gt;= 0.85 &amp; sim &lt; 0.95 ~ &#39;0.85 - 0.95&#39;, sim &gt;= 0.95 &amp; sim &lt; 1 ~ &#39;0.95 - 1&#39;, sim == 1 ~ &#39;Curated&#39;), levels = c(&#39;0 - 0.25&#39;, &#39;0.25 - 0.5&#39;, &#39;0.5 - 0.75&#39;, &#39;0.75 - 0.85&#39;, &#39;0.85 - 0.95&#39;,&#39;0.95 - 1&#39;, &#39;Curated&#39;))) Interestingly, there were some scrambled topologies which didn’t produce not even \\(1\\) boolean model with a stable state when using the genetic algorithm of Gitsbe (so no predictions could be made for these topologies): ordered_types = c(&#39;none&#39;, &#39;source&#39;, &#39;target&#39;, &#39;sign&#39;, &#39;all&#39;) scrambled_topo_res %&gt;% mutate(scramble_type = replace(x = scramble_type, list = scramble_type == &#39;effect&#39;, values = &#39;sign&#39;)) %&gt;% group_by(scramble_type) %&gt;% summarise(percent = sum(is.na(roc_auc))/n(), .groups = &#39;drop&#39;) %&gt;% mutate(scramble_type = factor(scramble_type, levels = ordered_types)) %&gt;% ggplot(aes(x = scramble_type, y = percent, fill = scramble_type)) + geom_col() + geom_text(aes(label = scales::percent(percent, accuracy = 1)), vjust = -0.5, size = 8) + scale_y_continuous(labels = scales::percent, limits = c(0,0.3)) + scale_fill_brewer(palette = &quot;Set1&quot;) + guides(fill = guide_legend(title = latex2exp::TeX(&quot;Scramble Type&quot;))) + labs(x = &quot;&quot;, title = &quot;Topologies with zero-stable-state boolean models&quot;, y = &quot;&quot;) + theme_classic(base_size = 14) + theme(axis.text.x = element_text(size = 18)) Figure 42: Percentage of topologies that did not have any boolean model with a stable state after simulations with Gitsbe ended (CASCADE 2.0 topology). Every possible topology scrambling type is represented. So potentially tweaking either the source or the target nodes of each edge in the curated topology, resulted in \\(13\\%\\) of the produced topologies to have a network configuration that wouldn’t allow the existence of attractor stability in the explored link-operator parameterization space of the Gitsbe algorithm. Same as with the CASCADE 1.0 results, tweaking the effect (activation vs inhibition), we always get topologies that can be translated to boolean models with a stable state attractor. Tweaking both source node, target node and interaction sign, results in the highest number of topologies with boolean models that lack stable behavior. Source Scrambling # ROC results scrambled_topo_res %&gt;% filter(scramble_type == &#39;source&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)) %&gt;% ggplot(aes(x = grp, y = roc_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 2.0 Topology&#39;, y = &#39;ROC AUC&#39;, title = &quot;Source Scrambling vs Performance (ROC)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 6.7, y = 0.45, label = &quot;Random (AUC = 0.5)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) # PR results scrambled_topo_res %&gt;% filter(scramble_type == &#39;source&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)) %&gt;% ggplot(aes(x = grp, y = pr_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,0.6)) + labs(x = &#39;Similarity Score to CASCADE 2.0 Topology&#39;, y = &#39;PR AUC&#39;, title = &quot;Source Scrambling vs Performance (Precision-Recall)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = sum(observed)/length(observed), linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 6.7, y = 0.01, label = &quot;Random (AUC = 0.04)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 43: Source node scrambling topologies + curated CASCADE 2.0 topology bootstrapped results (ROC and PR AUC) Target Scrambling # ROC results scrambled_topo_res %&gt;% filter(scramble_type == &#39;target&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)) %&gt;% ggplot(aes(x = grp, y = roc_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 2.0 Topology&#39;, y = &#39;ROC AUC&#39;, title = &quot;Target Scrambling vs Performance (ROC)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 6.7, y = 0.45, label = &quot;Random (AUC = 0.5)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) # PR results scrambled_topo_res %&gt;% filter(scramble_type == &#39;target&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)) %&gt;% ggplot(aes(x = grp, y = pr_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,0.6)) + labs(x = &#39;Similarity Score to CASCADE 2.0 Topology&#39;, y = &#39;PR AUC&#39;, title = &quot;Target Scrambling vs Performance (Precision-Recall)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = sum(observed)/length(observed), linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 6.7, y = 0.01, label = &quot;Random (AUC = 0.04)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 44: Target node scrambling topologies + curated CASCADE 2.0 topology bootstrapped results (ROC and PR AUC) Sign Inversion # ROC results scrambled_topo_res %&gt;% filter(scramble_type == &#39;effect&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)) %&gt;% ggplot(aes(x = grp, y = roc_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 2.0 Topology&#39;, y = &#39;ROC AUC&#39;, title = &quot;Sign Inversion vs Performance (ROC)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 6.7, y = 0.45, label = &quot;Random (AUC = 0.5)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) # PR results scrambled_topo_res %&gt;% filter(scramble_type == &#39;effect&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)) %&gt;% ggplot(aes(x = grp, y = pr_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,0.6)) + labs(x = &#39;Similarity Score to CASCADE 2.0 Topology&#39;, y = &#39;PR AUC&#39;, title = &quot;Sign Inversion vs Performance (Precision-Recall)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = sum(observed)/length(observed), linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 6.9, y = 0.01, label = &quot;Random (AUC = 0.04)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 45: Sign Inverted topologies + curated CASCADE 2.0 topology bootstrapped results (ROC and PR AUC) Source, Target Scrambling and Sign Inversion # ROC results scrambled_topo_res %&gt;% filter(scramble_type == &#39;all&#39; | scramble_type == &#39;none&#39;, !is.na(roc_auc)) %&gt;% ggplot(aes(x = grp, y = roc_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,1)) + labs(x = &#39;Similarity Score to CASCADE 2.0 Topology&#39;, y = &#39;ROC AUC&#39;, title = &quot;All types of Scrambling vs Performance (ROC)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 5.8, y = 0.45, label = &quot;Random (AUC = 0.5)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) # PR results scrambled_topo_res %&gt;% filter(scramble_type == &#39;all&#39; | scramble_type == &#39;none&#39;, !is.na(pr_auc)) %&gt;% ggplot(aes(x = grp, y = pr_auc, fill = grp)) + geom_boxplot(show.legend = FALSE) + scale_fill_brewer(palette = &#39;Set1&#39;) + geom_jitter(shape = 20, position = position_jitter(0.2), show.legend = FALSE) + ylim(c(0,0.6)) + labs(x = &#39;Similarity Score to CASCADE 2.0 Topology&#39;, y = &#39;PR AUC&#39;, title = &quot;All types of Scrambling vs Performance (Precision-Recall)&quot;) + theme_classic(base_size = 14) + geom_hline(yintercept = sum(observed)/length(observed), linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 5.8, y = 0.01, label = &quot;Random (AUC = 0.04)&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 46: Source, Target node scrambling and sign inverted topologies + CASCADE 2.0 topology bootstrapped results (ROC and PR AUC) We observe that even a small perturbation/violation/scrambling of the curated topology (of any type) produces results close to random prediction that are significantly lower than the prediction results when using the curated CASCADE 2.0 topology. Note that even with completely scrambled topologies we get high ROC and PR AUC values (this is true for all types of scrambling expect the sign inversion), but these topologies (and the boolean ensemble model performance resulted from them) represent statistical outliers (they are more like the exception and not the rule so to speak). "],["cascade-2-0-analysis-topology-mutations.html", "CASCADE 2.0 Analysis (Topology Mutations) HSA Results Bliss Results Best ROC and PRC Fitness vs Ensemble Performance", " CASCADE 2.0 Analysis (Topology Mutations) Load the results: # &#39;ss&#39; =&gt; calibrated models, &#39;rand&#39; =&gt; proliferative models (so not random but kind of!) # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; modelwise ## HSA results ss topo_ss_hsa_ew_50sim_file = paste0(&quot;results/topology-only/cascade_2.0_ss_50sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) topo_ss_hsa_mw_50sim_file = paste0(&quot;results/topology-only/cascade_2.0_ss_50sim_fixpoints_hsa_modelwise_synergies.tab&quot;) topo_ss_hsa_ew_150sim_file = paste0(&quot;results/topology-only/cascade_2.0_ss_150sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) topo_ss_hsa_mw_150sim_file = paste0(&quot;results/topology-only/cascade_2.0_ss_150sim_fixpoints_hsa_modelwise_synergies.tab&quot;) topo_ss_hsa_ew_synergies_50sim = emba::get_synergy_scores(topo_ss_hsa_ew_50sim_file) topo_ss_hsa_mw_synergies_50sim = emba::get_synergy_scores(topo_ss_hsa_mw_50sim_file, file_type = &quot;modelwise&quot;) topo_ss_hsa_ew_synergies_150sim = emba::get_synergy_scores(topo_ss_hsa_ew_150sim_file) topo_ss_hsa_mw_synergies_150sim = emba::get_synergy_scores(topo_ss_hsa_mw_150sim_file, file_type = &quot;modelwise&quot;) ## HSA results rand topo_prolif_hsa_ew_50sim_file = paste0(&quot;results/topology-only/cascade_2.0_rand_50sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) topo_prolif_hsa_mw_50sim_file = paste0(&quot;results/topology-only/cascade_2.0_rand_50sim_fixpoints_hsa_modelwise_synergies.tab&quot;) topo_prolif_hsa_ew_150sim_file = paste0(&quot;results/topology-only/cascade_2.0_rand_150sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) topo_prolif_hsa_mw_150sim_file = paste0(&quot;results/topology-only/cascade_2.0_rand_150sim_fixpoints_hsa_modelwise_synergies.tab&quot;) topo_prolif_hsa_ew_synergies_50sim = emba::get_synergy_scores(topo_prolif_hsa_ew_50sim_file) topo_prolif_hsa_mw_synergies_50sim = emba::get_synergy_scores(topo_prolif_hsa_mw_50sim_file, file_type = &quot;modelwise&quot;) topo_prolif_hsa_ew_synergies_150sim = emba::get_synergy_scores(topo_prolif_hsa_ew_150sim_file) topo_prolif_hsa_mw_synergies_150sim = emba::get_synergy_scores(topo_prolif_hsa_mw_150sim_file, file_type = &quot;modelwise&quot;) ## Bliss results ss topo_ss_bliss_ew_50sim_file = paste0(&quot;results/topology-only/cascade_2.0_ss_50sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) topo_ss_bliss_mw_50sim_file = paste0(&quot;results/topology-only/cascade_2.0_ss_50sim_fixpoints_bliss_modelwise_synergies.tab&quot;) topo_ss_bliss_ew_150sim_file = paste0(&quot;results/topology-only/cascade_2.0_ss_150sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) topo_ss_bliss_mw_150sim_file = paste0(&quot;results/topology-only/cascade_2.0_ss_150sim_fixpoints_bliss_modelwise_synergies.tab&quot;) topo_ss_bliss_ew_synergies_50sim = emba::get_synergy_scores(topo_ss_bliss_ew_50sim_file) topo_ss_bliss_mw_synergies_50sim = emba::get_synergy_scores(topo_ss_bliss_mw_50sim_file, file_type = &quot;modelwise&quot;) topo_ss_bliss_ew_synergies_150sim = emba::get_synergy_scores(topo_ss_bliss_ew_150sim_file) topo_ss_bliss_mw_synergies_150sim = emba::get_synergy_scores(topo_ss_bliss_mw_150sim_file, file_type = &quot;modelwise&quot;) ## Bliss results rand topo_prolif_bliss_ew_50sim_file = paste0(&quot;results/topology-only/cascade_2.0_rand_50sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) topo_prolif_bliss_mw_50sim_file = paste0(&quot;results/topology-only/cascade_2.0_rand_50sim_fixpoints_bliss_modelwise_synergies.tab&quot;) topo_prolif_bliss_ew_150sim_file = paste0(&quot;results/topology-only/cascade_2.0_rand_150sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) topo_prolif_bliss_mw_150sim_file = paste0(&quot;results/topology-only/cascade_2.0_rand_150sim_fixpoints_bliss_modelwise_synergies.tab&quot;) topo_prolif_bliss_ew_synergies_50sim = emba::get_synergy_scores(topo_prolif_bliss_ew_50sim_file) topo_prolif_bliss_mw_synergies_50sim = emba::get_synergy_scores(topo_prolif_bliss_mw_50sim_file, file_type = &quot;modelwise&quot;) topo_prolif_bliss_ew_synergies_150sim = emba::get_synergy_scores(topo_prolif_bliss_ew_150sim_file) topo_prolif_bliss_mw_synergies_150sim = emba::get_synergy_scores(topo_prolif_bliss_mw_150sim_file, file_type = &quot;modelwise&quot;) # calculate probability of synergy in the modelwise results topo_ss_hsa_mw_synergies_50sim = topo_ss_hsa_mw_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topo_ss_hsa_mw_synergies_150sim = topo_ss_hsa_mw_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topo_prolif_hsa_mw_synergies_50sim = topo_prolif_hsa_mw_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topo_prolif_hsa_mw_synergies_150sim = topo_prolif_hsa_mw_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topo_ss_bliss_mw_synergies_50sim = topo_ss_bliss_mw_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topo_ss_bliss_mw_synergies_150sim = topo_ss_bliss_mw_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topo_prolif_bliss_mw_synergies_50sim = topo_prolif_bliss_mw_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topo_prolif_bliss_mw_synergies_150sim = topo_prolif_bliss_mw_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) # Tidy the data pred_topo_ew_hsa = bind_cols( topo_ss_hsa_ew_synergies_50sim %&gt;% rename(ss_score_50sim = score), topo_ss_hsa_ew_synergies_150sim %&gt;% select(score) %&gt;% rename(ss_score_150sim = score), topo_prolif_hsa_ew_synergies_50sim %&gt;% select(score) %&gt;% rename(prolif_score_50sim = score), topo_prolif_hsa_ew_synergies_150sim %&gt;% select(score) %&gt;% rename(prolif_score_150sim = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_topo_mw_hsa = bind_cols( topo_ss_hsa_mw_synergies_50sim %&gt;% select(perturbation, synergy_prob_ss) %&gt;% rename(synergy_prob_ss_50sim = synergy_prob_ss), topo_ss_hsa_mw_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_150sim = synergy_prob_ss), topo_prolif_hsa_mw_synergies_50sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_prolif_50sim = synergy_prob_ss), topo_prolif_hsa_mw_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_prolif_150sim = synergy_prob_ss), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_topo_ew_bliss = bind_cols( topo_ss_bliss_ew_synergies_50sim %&gt;% rename(ss_score_50sim = score), topo_ss_bliss_ew_synergies_150sim %&gt;% select(score) %&gt;% rename(ss_score_150sim = score), topo_prolif_bliss_ew_synergies_50sim %&gt;% select(score) %&gt;% rename(prolif_score_50sim = score), topo_prolif_bliss_ew_synergies_150sim %&gt;% select(score) %&gt;% rename(prolif_score_150sim = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_topo_mw_bliss = bind_cols( topo_ss_bliss_mw_synergies_50sim %&gt;% select(perturbation, synergy_prob_ss) %&gt;% rename(synergy_prob_ss_50sim = synergy_prob_ss), topo_ss_bliss_mw_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_150sim = synergy_prob_ss), topo_prolif_bliss_mw_synergies_50sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_prolif_50sim = synergy_prob_ss), topo_prolif_bliss_mw_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_prolif_150sim = synergy_prob_ss), as_tibble_col(observed, column_name = &quot;observed&quot;)) HSA Results HSA refers to the synergy method used in Drabme to assess the synergies from the gitsbe models We test performance using ROC and PR AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state (\\(50,150\\) simulations) Random models: fitted to proliferation profile (\\(50,150\\) simulations) Gitsbe models have only topology mutations (\\(50\\) mutations as a bootstrap value, \\(10\\) after models with stable states are found) ROC curves topo_res_ss_ew_50sim = get_roc_stats(df = pred_topo_ew_hsa, pred_col = &quot;ss_score_50sim&quot;, label_col = &quot;observed&quot;) topo_res_ss_ew_150sim = get_roc_stats(df = pred_topo_ew_hsa, pred_col = &quot;ss_score_150sim&quot;, label_col = &quot;observed&quot;) topo_res_prolif_ew_50sim = get_roc_stats(df = pred_topo_ew_hsa, pred_col = &quot;prolif_score_50sim&quot;, label_col = &quot;observed&quot;) topo_res_prolif_ew_150sim = get_roc_stats(df = pred_topo_ew_hsa, pred_col = &quot;prolif_score_150sim&quot;, label_col = &quot;observed&quot;) topo_res_ss_mw_50sim = get_roc_stats(df = pred_topo_mw_hsa, pred_col = &quot;synergy_prob_ss_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topo_res_ss_mw_150sim = get_roc_stats(df = pred_topo_mw_hsa, pred_col = &quot;synergy_prob_ss_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topo_res_prolif_mw_50sim = get_roc_stats(df = pred_topo_mw_hsa, pred_col = &quot;synergy_prob_prolif_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topo_res_prolif_mw_150sim = get_roc_stats(df = pred_topo_mw_hsa, pred_col = &quot;synergy_prob_prolif_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs plot(x = topo_res_ss_ew_50sim$roc_stats$FPR, y = topo_res_ss_ew_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = topo_res_ss_ew_150sim$roc_stats$FPR, y = topo_res_ss_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = topo_res_prolif_ew_50sim$roc_stats$FPR, y = topo_res_prolif_ew_50sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = topo_res_prolif_ew_150sim$roc_stats$FPR, y = topo_res_prolif_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(topo_res_ss_ew_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(topo_res_ss_ew_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(topo_res_prolif_ew_50sim$AUC, digits = 2), &quot;Random (50 sim)&quot;), paste(round(topo_res_prolif_ew_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) plot(x = topo_res_ss_mw_50sim$roc_stats$FPR, y = topo_res_ss_mw_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = topo_res_ss_mw_150sim$roc_stats$FPR, y = topo_res_ss_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = topo_res_prolif_mw_50sim$roc_stats$FPR, y = topo_res_prolif_mw_50sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = topo_res_prolif_mw_150sim$roc_stats$FPR, y = topo_res_prolif_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(topo_res_ss_mw_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(topo_res_ss_mw_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(topo_res_prolif_mw_50sim$AUC, digits = 2), &quot;Random (50 sim)&quot;), paste(round(topo_res_prolif_mw_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) Figure 47: ROC curves (CASCADE 2.0, Topology Mutations, HSA synergy method) PR curves pr_topo_res_ss_ew_50sim = pr.curve(scores.class0 = pred_topo_ew_hsa %&gt;% pull(ss_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_topo_res_ss_ew_150sim = pr.curve(scores.class0 = pred_topo_ew_hsa %&gt;% pull(ss_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_topo_res_prolif_ew_50sim = pr.curve(scores.class0 = pred_topo_ew_hsa %&gt;% pull(prolif_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_topo_res_prolif_ew_150sim = pr.curve(scores.class0 = pred_topo_ew_hsa %&gt;% pull(prolif_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_topo_res_ss_mw_50sim = pr.curve(scores.class0 = pred_topo_mw_hsa %&gt;% pull(synergy_prob_ss_50sim), weights.class0 = pred_topo_mw_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_topo_res_ss_mw_150sim = pr.curve(scores.class0 = pred_topo_mw_hsa %&gt;% pull(synergy_prob_ss_150sim), weights.class0 = pred_topo_mw_hsa %&gt;% pull(observed), curve = TRUE) pr_topo_res_prolif_mw_50sim = pr.curve(scores.class0 = pred_topo_mw_hsa %&gt;% pull(synergy_prob_prolif_50sim), weights.class0 = pred_topo_mw_hsa %&gt;% pull(observed), curve = TRUE) pr_topo_res_prolif_mw_150sim = pr.curve(scores.class0 = pred_topo_mw_hsa %&gt;% pull(synergy_prob_prolif_150sim), weights.class0 = pred_topo_mw_hsa %&gt;% pull(observed), curve = TRUE) plot(pr_topo_res_ss_ew_50sim, main = &#39;PR curve, Ensemble-wise synergies (HSA)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_topo_res_ss_ew_150sim, add = TRUE, color = my_palette[2]) plot(pr_topo_res_prolif_ew_50sim, add = TRUE, color = my_palette[3]) plot(pr_topo_res_prolif_ew_150sim, add = TRUE, color = my_palette[4]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(pr_topo_res_ss_ew_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_topo_res_ss_ew_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_topo_res_prolif_ew_50sim$auc.davis.goadrich, digits = 3), &quot;Random (50 sim)&quot;), paste(round(pr_topo_res_prolif_ew_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) plot(pr_topo_res_ss_mw_50sim, main = &#39;PR curve, Model-wise synergies (HSA)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_topo_res_ss_mw_150sim, add = TRUE, color = my_palette[2]) plot(pr_topo_res_prolif_mw_50sim, add = TRUE, color = my_palette[3]) plot(pr_topo_res_prolif_mw_150sim, add = TRUE, color = my_palette[4]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(pr_topo_res_ss_mw_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_topo_res_ss_mw_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_topo_res_prolif_mw_50sim$auc.davis.goadrich, digits = 3), &quot;Random (50 sim)&quot;), paste(round(pr_topo_res_prolif_mw_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) Figure 48: PR curves (CASCADE 2.0, Topology Mutations, HSA synergy method) The PR curves show that the performance of each individual predictor is poor compared to the baseline. Someone looking at the ROC curves only might reach a different conclusion. Random proliferative models perform slightly better than the calibrated ones. The model-wise approach produces slightly better ROC results than the ensemble-wise approach. AUC sensitivity Investigate same thing as described in here. This is very crucial since the PR performance is poor for the individual predictors, but a combined predictor might be able to counter this. We will combine the synergy scores from the random proliferative simulations with the results from the calibrated Gitsbe simulations (number of simulations: \\(150\\)). # Ensemble-wise betas = seq(from = -5, to = 5, by = 0.1) prolif_roc_topo = sapply(betas, function(beta) { pred_topo_ew_hsa = pred_topo_ew_hsa %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = roc.curve(scores.class0 = pred_topo_ew_hsa %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_hsa %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr_topo = sapply(betas, function(beta) { pred_topo_ew_hsa = pred_topo_ew_hsa %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = pr.curve(scores.class0 = pred_topo_ew_hsa %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_hsa %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_ew = as_tibble(cbind(betas, prolif_roc_topo, prolif_pr_topo)) df_ew = df_ew %&gt;% tidyr::pivot_longer(-betas, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, ylim = c(0,0.85), panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + geom_vline(xintercept = 0) + geom_vline(xintercept = -1, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_text(aes(x=-1.5, label=&quot;β = -1&quot;, y=0.14), colour=&quot;black&quot;, angle=90) + grids() Figure 49: AUC sensitivity (CASCADE 2.0, Topology Mutations, HSA synergy method, Ensemble-wise results) The proliferative models do not bring any significant change to the prediction performance of the calibrated models. Bliss Results Bliss refers to the synergy method used in Drabme to assess the synergies from the gitsbe models We test performance using ROC and PR AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state (\\(50,150\\) simulations) Random models: fitted to proliferation profile (\\(50,150\\) simulations) Gitsbe models have only topology mutations (\\(50\\) mutations as a bootstrap value, \\(10\\) after models with stable states are found) ROC curves topo_res_ss_ew_50sim = get_roc_stats(df = pred_topo_ew_bliss, pred_col = &quot;ss_score_50sim&quot;, label_col = &quot;observed&quot;) topo_res_ss_ew_150sim = get_roc_stats(df = pred_topo_ew_bliss, pred_col = &quot;ss_score_150sim&quot;, label_col = &quot;observed&quot;) topo_res_prolif_ew_50sim = get_roc_stats(df = pred_topo_ew_bliss, pred_col = &quot;prolif_score_50sim&quot;, label_col = &quot;observed&quot;) topo_res_prolif_ew_150sim = get_roc_stats(df = pred_topo_ew_bliss, pred_col = &quot;prolif_score_150sim&quot;, label_col = &quot;observed&quot;) topo_res_ss_mw_50sim = get_roc_stats(df = pred_topo_mw_bliss, pred_col = &quot;synergy_prob_ss_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topo_res_ss_mw_150sim = get_roc_stats(df = pred_topo_mw_bliss, pred_col = &quot;synergy_prob_ss_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topo_res_prolif_mw_50sim = get_roc_stats(df = pred_topo_mw_bliss, pred_col = &quot;synergy_prob_prolif_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topo_res_prolif_mw_150sim = get_roc_stats(df = pred_topo_mw_bliss, pred_col = &quot;synergy_prob_prolif_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs plot(x = topo_res_ss_ew_50sim$roc_stats$FPR, y = topo_res_ss_ew_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = topo_res_ss_ew_150sim$roc_stats$FPR, y = topo_res_ss_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = topo_res_prolif_ew_50sim$roc_stats$FPR, y = topo_res_prolif_ew_50sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = topo_res_prolif_ew_150sim$roc_stats$FPR, y = topo_res_prolif_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(topo_res_ss_ew_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(topo_res_ss_ew_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(topo_res_prolif_ew_50sim$AUC, digits = 2), &quot;Random (50 sim)&quot;), paste(round(topo_res_prolif_ew_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) plot(x = topo_res_ss_mw_50sim$roc_stats$FPR, y = topo_res_ss_mw_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = topo_res_ss_mw_150sim$roc_stats$FPR, y = topo_res_ss_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = topo_res_prolif_mw_50sim$roc_stats$FPR, y = topo_res_prolif_mw_50sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = topo_res_prolif_mw_150sim$roc_stats$FPR, y = topo_res_prolif_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(topo_res_ss_mw_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(topo_res_ss_mw_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(topo_res_prolif_mw_50sim$AUC, digits = 2), &quot;Random (50 sim)&quot;), paste(round(topo_res_prolif_mw_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) Figure 50: ROC curves (CASCADE 2.0, Topology Mutations, Bliss synergy method) PR curves pr_topo_res_ss_ew_50sim = pr.curve(scores.class0 = pred_topo_ew_bliss %&gt;% pull(ss_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_topo_res_ss_ew_150sim = pr.curve(scores.class0 = pred_topo_ew_bliss %&gt;% pull(ss_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_topo_res_prolif_ew_50sim = pr.curve(scores.class0 = pred_topo_ew_bliss %&gt;% pull(prolif_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_topo_res_prolif_ew_150sim = pr.curve(scores.class0 = pred_topo_ew_bliss %&gt;% pull(prolif_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_topo_res_ss_mw_50sim = pr.curve(scores.class0 = pred_topo_mw_bliss %&gt;% pull(synergy_prob_ss_50sim), weights.class0 = pred_topo_mw_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_topo_res_ss_mw_150sim = pr.curve(scores.class0 = pred_topo_mw_bliss %&gt;% pull(synergy_prob_ss_150sim), weights.class0 = pred_topo_mw_bliss %&gt;% pull(observed), curve = TRUE) pr_topo_res_prolif_mw_50sim = pr.curve(scores.class0 = pred_topo_mw_bliss %&gt;% pull(synergy_prob_prolif_50sim), weights.class0 = pred_topo_mw_bliss %&gt;% pull(observed), curve = TRUE) pr_topo_res_prolif_mw_150sim = pr.curve(scores.class0 = pred_topo_mw_bliss %&gt;% pull(synergy_prob_prolif_150sim), weights.class0 = pred_topo_mw_bliss %&gt;% pull(observed), curve = TRUE) plot(pr_topo_res_ss_ew_50sim, main = &#39;PR curve, Ensemble-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_topo_res_ss_ew_150sim, add = TRUE, color = my_palette[2]) plot(pr_topo_res_prolif_ew_50sim, add = TRUE, color = my_palette[3]) plot(pr_topo_res_prolif_ew_150sim, add = TRUE, color = my_palette[4]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(pr_topo_res_ss_ew_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_topo_res_ss_ew_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_topo_res_prolif_ew_50sim$auc.davis.goadrich, digits = 3), &quot;Random (50 sim)&quot;), paste(round(pr_topo_res_prolif_ew_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) plot(pr_topo_res_ss_mw_50sim, main = &#39;PR curve, Model-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_topo_res_ss_mw_150sim, add = TRUE, color = my_palette[2]) plot(pr_topo_res_prolif_mw_50sim, add = TRUE, color = my_palette[3]) plot(pr_topo_res_prolif_mw_150sim, add = TRUE, color = my_palette[4]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(pr_topo_res_ss_mw_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_topo_res_ss_mw_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_topo_res_prolif_mw_50sim$auc.davis.goadrich, digits = 3), &quot;Random (50 sim)&quot;), paste(round(pr_topo_res_prolif_mw_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) Figure 51: PR curves (CASCADE 2.0, Topology Mutations, Bliss synergy method) The PR curves show that the performance of all individual predictors is poor compared to the baseline. Random proliferative models perform slightly better than the calibrated ones. The model-wise approach produces slightly better ROC and PR results than the ensemble-wise approach AUC sensitivity Investigate same thing as described in here. This is very crucial since the PR performance is poor for the individual predictors, but a combined predictor might be able to counter this. We will combine the synergy scores from the random proliferative simulations with the results from the calibrated Gitsbe simulations (number of simulations: \\(150\\)). # Ensemble-wise betas = seq(from = -5, to = 5, by = 0.1) prolif_roc = sapply(betas, function(beta) { pred_topo_ew_bliss = pred_topo_ew_bliss %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = roc.curve(scores.class0 = pred_topo_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_bliss %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr = sapply(betas, function(beta) { pred_topo_ew_bliss = pred_topo_ew_bliss %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = pr.curve(scores.class0 = pred_topo_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_bliss %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_ew = as_tibble(cbind(betas, prolif_roc, prolif_pr)) df_ew = df_ew %&gt;% tidyr::pivot_longer(-betas, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, ylim = c(0,0.85), panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + geom_vline(xintercept = 0) + geom_vline(xintercept = -1, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_text(aes(x=-1.5, label=&quot;β = -1&quot;, y=0.15), colour=&quot;black&quot;, angle = 90) + grids() Figure 52: AUC sensitivity (CASCADE 2.0, Topology Mutations, Bliss synergy method, Ensemble-wise results) The proliferative models can be used to normalize against the predictions of the calibrated models and thus bring significant contribution to the calibrated models performance (both ROC-AUC and PR-AUC are increased). The \\(\\beta_{best}\\) values of the combined calibrated and random proliferative model predictor that maximize the ROC-AUC and PR-AUC respectively are \\(\\beta_{best}^{\\text{ROC-AUC}}=-0.8\\) and \\(\\beta_{best}^{\\text{PR-AUC}}=-1\\) Best ROC and PRC For the Bliss ensemble-wise results we demonstrated above that a value of \\(\\beta_{best}=-1\\) can result in significant performance gain of the combined predictor (\\(calibrated + \\beta \\times random\\)). So, the best ROC and PR curves we can get with our simulations when using models with topology mutations are: best_beta = -1 pred_topo_ew_bliss = pred_topo_ew_bliss %&gt;% mutate(best_score = ss_score_150sim + best_beta * prolif_score_150sim) roc_best_res = get_roc_stats(df = pred_topo_ew_bliss, pred_col = &quot;best_score&quot;, label_col = &quot;observed&quot;) pr_best_res = pr.curve(scores.class0 = pred_topo_ew_bliss %&gt;% pull(best_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) # Plot best ROC plot(x = roc_best_res$roc_stats$FPR, y = roc_best_res$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = TeX(&#39;ROC curve (Ensemble-wise), $calibrated + \\\\beta \\\\times random$&#39;), xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) legend(&#39;bottomright&#39;, title = TeX(&#39;AUC ($\\\\beta$ = -1)&#39;), col = my_palette[1], pch = 19, legend = paste(round(roc_best_res$AUC, digits = 2), &#39;Bliss (150 sim)&#39;), cex = 1.5) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) # Plot best PRC plot(pr_best_res, main = TeX(&#39;PR curve (Ensemble-wise), $calibrated + \\\\beta \\\\times random$&#39;), auc.main = FALSE, color = my_palette[2], rand.plot = TRUE) legend(&#39;topright&#39;, title = TeX(&#39;AUC ($\\\\beta$ = -1)&#39;), col = my_palette[2], pch = 19, legend = paste(round(pr_best_res$auc.davis.goadrich, digits = 3), &#39;Bliss (150 sim)&#39;), cex = 1.5) grid(lwd = 0.5) Figure 53: ROC and PR curve for best beta (CASCADE 2.0, Topology Mutations) Fitness vs Ensemble Performance We check for correlation between the calibrated models fitness to the AGS steady state and their ensemble performance subject to normalization to the random model predictions. The main idea here is that we generate different training data samples, in which the boolean steady state nodes have their values flipped (so they are only partially correct) and we fit models to these (\\(50\\) simulations =&gt; \\(150\\) topology-mutated models per training data, \\(205\\) training data samples in total). These calibrated model ensembles can then be tested for their prediction performance. Then we use the ensemble-wise random proliferative model predictions (\\(50\\) simulations) to normalize (\\(\\beta=-1\\)) against the calibrated model predictions and compute the AUC ROC and AUC PR for each model ensemble. Check how to generate the appropriate data, run the simulations and tidy up the results in the section Fitness vs Performance Methods. Load the already-stored result: res = readRDS(file = &quot;data/res_fit_aucs_topo.rds&quot;) We check if our data is normally distributed using the Shapiro-Wilk normality test: shapiro.test(x = res$roc_auc) Shapiro-Wilk normality test data: res$roc_auc W = 0.98463, p-value = 0.02488 shapiro.test(x = res$pr_auc) Shapiro-Wilk normality test data: res$pr_auc W = 0.92214, p-value = 6.025e-09 shapiro.test(x = res$avg_fit) Shapiro-Wilk normality test data: res$avg_fit W = 0.88305, p-value = 1.609e-11 We observe from the low p-values that the data is not normally distributed. Thus, we are going to use a non-parametric correlation metric, namely the Kendall rank-based test (and it’s respective coefficient, \\(\\tau\\)), to check for correlation between the ensemble model performance (ROC-AUC, PR-AUC) and the fitness to the AGS steady state: ggscatter(data = res, x = &quot;avg_fit&quot;, y = &quot;roc_auc&quot;, xlab = &quot;Average Fitness per Model Ensemble&quot;, title = &quot;Fitness to AGS Steady State vs Performance (ROC)&quot;, ylab = &quot;ROC AUC&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, size = 6, cor.coef.name = &quot;tau&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 54: Fitness to AGS Steady State vs ROC-AUC Performance (CASCADE 2.0, Topology mutations, Bliss synergy method, Ensemble-wise normalized results) ggscatter(data = res, x = &quot;avg_fit&quot;, y = &quot;pr_auc&quot;, xlab = &quot;Average Fitness per Model Ensemble&quot;, title = &quot;Fitness to AGS Steady State vs Performance (Precision-Recall)&quot;, add.params = list(color = &quot;blue&quot;, fill = &quot;lightgray&quot;), ylab = &quot;PR AUC&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, cor.coef = TRUE, cor.coeff.args = list(method = &quot;kendall&quot;, size = 6, cor.coef.name = &quot;tau&quot;)) + theme(plot.title = element_text(hjust = 0.5)) Figure 55: Fitness to AGS Steady State vs PR-AUC Performance (CASCADE 2.0, Topology Mutations, Bliss synergy method, Ensemble-wise normalized results) We observe that there exists some correlation between the normalized ensemble model performance vs the models fitness to the training steady state data. Correlation results are better than when applying link-operator mutations to the models. The topology mutations offer a larger variation in performance in terms of both ROC and PR AUC, given the limited set of provided steady state nodes for calibration of the models (24 out of 144 in total for the AGS cell line). The performance as measured by the ROC AUC is less sensitive to changes in the training data but there is better correlation with regards to the PR AUC, which is a more informative measure for our imbalanced dataset (Saito and Rehmsmeier 2015). "],["cascade-2-0-analysis-topology-and-link-operator-mutations.html", "CASCADE 2.0 Analysis (Topology and Link Operator Mutations) HSA Results Bliss Results Best ROC and PRC", " CASCADE 2.0 Analysis (Topology and Link Operator Mutations) # &#39;ss&#39; =&gt; calibrated models, &#39;rand&#39; =&gt; proliferative models (so not random but kind of!) # &#39;ew&#39; =&gt; ensemble-wise, &#39;mw&#39; =&gt; modelwise ## HSA results ss topolink_ss_hsa_ew_50sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_ss_50sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) topolink_ss_hsa_mw_50sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_ss_50sim_fixpoints_hsa_modelwise_synergies.tab&quot;) topolink_ss_hsa_ew_150sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_ss_150sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) topolink_ss_hsa_mw_150sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_ss_150sim_fixpoints_hsa_modelwise_synergies.tab&quot;) topolink_ss_hsa_ew_synergies_50sim = emba::get_synergy_scores(topolink_ss_hsa_ew_50sim_file) topolink_ss_hsa_mw_synergies_50sim = emba::get_synergy_scores(topolink_ss_hsa_mw_50sim_file, file_type = &quot;modelwise&quot;) topolink_ss_hsa_ew_synergies_150sim = emba::get_synergy_scores(topolink_ss_hsa_ew_150sim_file) topolink_ss_hsa_mw_synergies_150sim = emba::get_synergy_scores(topolink_ss_hsa_mw_150sim_file, file_type = &quot;modelwise&quot;) ## HSA results rand topolink_prolif_hsa_ew_50sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_rand_50sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) topolink_prolif_hsa_mw_50sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_rand_50sim_fixpoints_hsa_modelwise_synergies.tab&quot;) topolink_prolif_hsa_ew_150sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_rand_150sim_fixpoints_hsa_ensemblewise_synergies.tab&quot;) topolink_prolif_hsa_mw_150sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_rand_150sim_fixpoints_hsa_modelwise_synergies.tab&quot;) topolink_prolif_hsa_ew_synergies_50sim = emba::get_synergy_scores(topolink_prolif_hsa_ew_50sim_file) topolink_prolif_hsa_mw_synergies_50sim = emba::get_synergy_scores(topolink_prolif_hsa_mw_50sim_file, file_type = &quot;modelwise&quot;) topolink_prolif_hsa_ew_synergies_150sim = emba::get_synergy_scores(topolink_prolif_hsa_ew_150sim_file) topolink_prolif_hsa_mw_synergies_150sim = emba::get_synergy_scores(topolink_prolif_hsa_mw_150sim_file, file_type = &quot;modelwise&quot;) ## Bliss results ss topolink_ss_bliss_ew_50sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_ss_50sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) topolink_ss_bliss_mw_50sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_ss_50sim_fixpoints_bliss_modelwise_synergies.tab&quot;) topolink_ss_bliss_ew_150sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_ss_150sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) topolink_ss_bliss_mw_150sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_ss_150sim_fixpoints_bliss_modelwise_synergies.tab&quot;) topolink_ss_bliss_ew_synergies_50sim = emba::get_synergy_scores(topolink_ss_bliss_ew_50sim_file) topolink_ss_bliss_mw_synergies_50sim = emba::get_synergy_scores(topolink_ss_bliss_mw_50sim_file, file_type = &quot;modelwise&quot;) topolink_ss_bliss_ew_synergies_150sim = emba::get_synergy_scores(topolink_ss_bliss_ew_150sim_file) topolink_ss_bliss_mw_synergies_150sim = emba::get_synergy_scores(topolink_ss_bliss_mw_150sim_file, file_type = &quot;modelwise&quot;) ## Bliss results rand topolink_prolif_bliss_ew_50sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_rand_50sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) topolink_prolif_bliss_mw_50sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_rand_50sim_fixpoints_bliss_modelwise_synergies.tab&quot;) topolink_prolif_bliss_ew_150sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_rand_150sim_fixpoints_bliss_ensemblewise_synergies.tab&quot;) topolink_prolif_bliss_mw_150sim_file = paste0(&quot;results/topo-and-link/cascade_2.0_rand_150sim_fixpoints_bliss_modelwise_synergies.tab&quot;) topolink_prolif_bliss_ew_synergies_50sim = emba::get_synergy_scores(topolink_prolif_bliss_ew_50sim_file) topolink_prolif_bliss_mw_synergies_50sim = emba::get_synergy_scores(topolink_prolif_bliss_mw_50sim_file, file_type = &quot;modelwise&quot;) topolink_prolif_bliss_ew_synergies_150sim = emba::get_synergy_scores(topolink_prolif_bliss_ew_150sim_file) topolink_prolif_bliss_mw_synergies_150sim = emba::get_synergy_scores(topolink_prolif_bliss_mw_150sim_file, file_type = &quot;modelwise&quot;) # calculate probability of synergy in the modelwise results topolink_ss_hsa_mw_synergies_50sim = topolink_ss_hsa_mw_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topolink_ss_hsa_mw_synergies_150sim = topolink_ss_hsa_mw_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topolink_prolif_hsa_mw_synergies_50sim = topolink_prolif_hsa_mw_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topolink_prolif_hsa_mw_synergies_150sim = topolink_prolif_hsa_mw_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topolink_ss_bliss_mw_synergies_50sim = topolink_ss_bliss_mw_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topolink_ss_bliss_mw_synergies_150sim = topolink_ss_bliss_mw_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topolink_prolif_bliss_mw_synergies_50sim = topolink_prolif_bliss_mw_synergies_50sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) topolink_prolif_bliss_mw_synergies_150sim = topolink_prolif_bliss_mw_synergies_150sim %&gt;% mutate(synergy_prob_ss = synergies/(synergies + `non-synergies`)) # Tidy the data pred_topolink_ew_hsa = bind_cols( topolink_ss_hsa_ew_synergies_50sim %&gt;% rename(ss_score_50sim = score), topolink_ss_hsa_ew_synergies_150sim %&gt;% select(score) %&gt;% rename(ss_score_150sim = score), topolink_prolif_hsa_ew_synergies_50sim %&gt;% select(score) %&gt;% rename(prolif_score_50sim = score), topolink_prolif_hsa_ew_synergies_150sim %&gt;% select(score) %&gt;% rename(prolif_score_150sim = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_topolink_mw_hsa = bind_cols( topolink_ss_hsa_mw_synergies_50sim %&gt;% select(perturbation, synergy_prob_ss) %&gt;% rename(synergy_prob_ss_50sim = synergy_prob_ss), topolink_ss_hsa_mw_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_150sim = synergy_prob_ss), topolink_prolif_hsa_mw_synergies_50sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_prolif_50sim = synergy_prob_ss), topolink_prolif_hsa_mw_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_prolif_150sim = synergy_prob_ss), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_topolink_ew_bliss = bind_cols( topolink_ss_bliss_ew_synergies_50sim %&gt;% rename(ss_score_50sim = score), topolink_ss_bliss_ew_synergies_150sim %&gt;% select(score) %&gt;% rename(ss_score_150sim = score), topolink_prolif_bliss_ew_synergies_50sim %&gt;% select(score) %&gt;% rename(prolif_score_50sim = score), topolink_prolif_bliss_ew_synergies_150sim %&gt;% select(score) %&gt;% rename(prolif_score_150sim = score), as_tibble_col(observed, column_name = &quot;observed&quot;)) pred_topolink_mw_bliss = bind_cols( topolink_ss_bliss_mw_synergies_50sim %&gt;% select(perturbation, synergy_prob_ss) %&gt;% rename(synergy_prob_ss_50sim = synergy_prob_ss), topolink_ss_bliss_mw_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_ss_150sim = synergy_prob_ss), topolink_prolif_bliss_mw_synergies_50sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_prolif_50sim = synergy_prob_ss), topolink_prolif_bliss_mw_synergies_150sim %&gt;% select(synergy_prob_ss) %&gt;% rename(synergy_prob_prolif_150sim = synergy_prob_ss), as_tibble_col(observed, column_name = &quot;observed&quot;)) HSA Results HSA refers to the synergy method used in Drabme to assess the synergies from the gitsbe models We test performance using ROC and PR AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state (\\(50,150\\) simulations) Random models: fitted to proliferation profile (\\(50,150\\) simulations) Gitsbe models have both balance and topology mutations (\\(3000,50\\) mutations as a bootstrap value, \\(3\\) and \\(10\\) respectively after models with stable states are found) ROC curves topolink_res_ss_ew_50sim = get_roc_stats(df = pred_topolink_ew_hsa, pred_col = &quot;ss_score_50sim&quot;, label_col = &quot;observed&quot;) topolink_res_ss_ew_150sim = get_roc_stats(df = pred_topolink_ew_hsa, pred_col = &quot;ss_score_150sim&quot;, label_col = &quot;observed&quot;) topolink_res_prolif_ew_50sim = get_roc_stats(df = pred_topolink_ew_hsa, pred_col = &quot;prolif_score_50sim&quot;, label_col = &quot;observed&quot;) topolink_res_prolif_ew_150sim = get_roc_stats(df = pred_topolink_ew_hsa, pred_col = &quot;prolif_score_150sim&quot;, label_col = &quot;observed&quot;) topolink_res_ss_mw_50sim = get_roc_stats(df = pred_topolink_mw_hsa, pred_col = &quot;synergy_prob_ss_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topolink_res_ss_mw_150sim = get_roc_stats(df = pred_topolink_mw_hsa, pred_col = &quot;synergy_prob_ss_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topolink_res_prolif_mw_50sim = get_roc_stats(df = pred_topolink_mw_hsa, pred_col = &quot;synergy_prob_prolif_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topolink_res_prolif_mw_150sim = get_roc_stats(df = pred_topolink_mw_hsa, pred_col = &quot;synergy_prob_prolif_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs plot(x = topolink_res_ss_ew_50sim$roc_stats$FPR, y = topolink_res_ss_ew_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = topolink_res_ss_ew_150sim$roc_stats$FPR, y = topolink_res_ss_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = topolink_res_prolif_ew_50sim$roc_stats$FPR, y = topolink_res_prolif_ew_50sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = topolink_res_prolif_ew_150sim$roc_stats$FPR, y = topolink_res_prolif_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(topolink_res_ss_ew_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(topolink_res_ss_ew_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(topolink_res_prolif_ew_50sim$AUC, digits = 2), &quot;Random (50 sim)&quot;), paste(round(topolink_res_prolif_ew_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) plot(x = topolink_res_ss_mw_50sim$roc_stats$FPR, y = topolink_res_ss_mw_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (HSA)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = topolink_res_ss_mw_150sim$roc_stats$FPR, y = topolink_res_ss_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = topolink_res_prolif_mw_50sim$roc_stats$FPR, y = topolink_res_prolif_mw_50sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = topolink_res_prolif_mw_150sim$roc_stats$FPR, y = topolink_res_prolif_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(topolink_res_ss_mw_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(topolink_res_ss_mw_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(topolink_res_prolif_mw_50sim$AUC, digits = 2), &quot;Random (50 sim)&quot;), paste(round(topolink_res_prolif_mw_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) Figure 56: ROC curves (CASCADE 2.0, Link Operator and Topology Mutations, HSA synergy method) PR curves pr_topolink_res_ss_ew_50sim = pr.curve(scores.class0 = pred_topolink_ew_hsa %&gt;% pull(ss_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_topolink_res_ss_ew_150sim = pr.curve(scores.class0 = pred_topolink_ew_hsa %&gt;% pull(ss_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_topolink_res_prolif_ew_50sim = pr.curve(scores.class0 = pred_topolink_ew_hsa %&gt;% pull(prolif_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_topolink_res_prolif_ew_150sim = pr.curve(scores.class0 = pred_topolink_ew_hsa %&gt;% pull(prolif_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_hsa %&gt;% pull(observed), curve = TRUE) pr_topolink_res_ss_mw_50sim = pr.curve(scores.class0 = pred_topolink_mw_hsa %&gt;% pull(synergy_prob_ss_50sim), weights.class0 = pred_topolink_mw_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_topolink_res_ss_mw_150sim = pr.curve(scores.class0 = pred_topolink_mw_hsa %&gt;% pull(synergy_prob_ss_150sim), weights.class0 = pred_topolink_mw_hsa %&gt;% pull(observed), curve = TRUE) pr_topolink_res_prolif_mw_50sim = pr.curve(scores.class0 = pred_topolink_mw_hsa %&gt;% pull(synergy_prob_prolif_50sim), weights.class0 = pred_topolink_mw_hsa %&gt;% pull(observed), curve = TRUE) pr_topolink_res_prolif_mw_150sim = pr.curve(scores.class0 = pred_topolink_mw_hsa %&gt;% pull(synergy_prob_prolif_150sim), weights.class0 = pred_topolink_mw_hsa %&gt;% pull(observed), curve = TRUE) plot(pr_topolink_res_ss_ew_50sim, main = &#39;PR curve, Ensemble-wise synergies (HSA)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_topolink_res_ss_ew_150sim, add = TRUE, color = my_palette[2]) plot(pr_topolink_res_prolif_ew_50sim, add = TRUE, color = my_palette[3]) plot(pr_topolink_res_prolif_ew_150sim, add = TRUE, color = my_palette[4]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(pr_topolink_res_ss_ew_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_topolink_res_ss_ew_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_topolink_res_prolif_ew_50sim$auc.davis.goadrich, digits = 3), &quot;Random (50 sim)&quot;), paste(round(pr_topolink_res_prolif_ew_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) plot(pr_topolink_res_ss_mw_50sim, main = &#39;PR curve, Model-wise synergies (HSA)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_topolink_res_ss_mw_150sim, add = TRUE, color = my_palette[2]) plot(pr_topolink_res_prolif_mw_50sim, add = TRUE, color = my_palette[3]) plot(pr_topolink_res_prolif_mw_150sim, add = TRUE, color = my_palette[4]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(pr_topolink_res_ss_mw_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_topolink_res_ss_mw_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_topolink_res_prolif_mw_50sim$auc.davis.goadrich, digits = 3), &quot;Random (50 sim)&quot;), paste(round(pr_topolink_res_prolif_mw_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) Figure 57: PR curves (CASCADE 2.0, Link Operator and Topology Mutations, HSA synergy method) The PR curves show that the performance of each individual predictor is poor compared to the baseline. Someone looking at the ROC curves only might reach a different conclusion. The model-wise approach produces slightly better ROC results than the ensemble-wise approach. AUC sensitivity Investigate same thing as described in here. This is very crucial since the PR performance is poor for the individual predictors, but a combined predictor might be able to counter this. We will combine the synergy scores from the random proliferative simulations with the results from the calibrated Gitsbe simulations (number of simulations: \\(150\\)). # Ensemble-wise betas = seq(from = -5, to = 5, by = 0.1) prolif_roc_topo = sapply(betas, function(beta) { pred_topolink_ew_hsa = pred_topolink_ew_hsa %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = roc.curve(scores.class0 = pred_topolink_ew_hsa %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_hsa %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr_topo = sapply(betas, function(beta) { pred_topolink_ew_hsa = pred_topolink_ew_hsa %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = pr.curve(scores.class0 = pred_topolink_ew_hsa %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_hsa %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_ew = as_tibble(cbind(betas, prolif_roc_topo, prolif_pr_topo)) df_ew = df_ew %&gt;% tidyr::pivot_longer(-betas, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, ylim = c(0,0.85), panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + geom_vline(xintercept = 0) + geom_vline(xintercept = -1, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_text(aes(x=-1.6, label=&quot;β = -1&quot;, y=0.33), colour=&quot;black&quot;, angle=90) + grids() Figure 58: AUC sensitivity (CASCADE 2.0, Link Operator and Topology Mutations, HSA synergy method, Ensemble-wise results) The random proliferative models can be used to normalize against the predictions of the calibrated models and thus bring significant contribution to the calibrated models performance (PR-AUC shows much more sensitivity in that regard - it increases substantially more than the ROC-AUC). The \\(\\beta_{best}\\) value of the combined calibrated and random proliferative model predictor that maximizes both the ROC-AUC and PR-AUC is \\(\\beta_{best}=-1\\). Bliss Results Bliss refers to the synergy method used in Drabme to assess the synergies from the gitsbe models We test performance using ROC and PR AUC for both the ensemble-wise and model-wise synergies from Drabme Calibrated models: fitted to steady state (\\(50,150\\) simulations) Random models: fitted to proliferation profile (\\(50,150\\) simulations) Gitsbe models have both balance and topology mutations (\\(3000,50\\) mutations as a bootstrap value, \\(3\\) and \\(10\\) respectively after models with stable states are found) ROC curves topolink_res_ss_ew_50sim = get_roc_stats(df = pred_topolink_ew_bliss, pred_col = &quot;ss_score_50sim&quot;, label_col = &quot;observed&quot;) topolink_res_ss_ew_150sim = get_roc_stats(df = pred_topolink_ew_bliss, pred_col = &quot;ss_score_150sim&quot;, label_col = &quot;observed&quot;) topolink_res_prolif_ew_50sim = get_roc_stats(df = pred_topolink_ew_bliss, pred_col = &quot;prolif_score_50sim&quot;, label_col = &quot;observed&quot;) topolink_res_prolif_ew_150sim = get_roc_stats(df = pred_topolink_ew_bliss, pred_col = &quot;prolif_score_150sim&quot;, label_col = &quot;observed&quot;) topolink_res_ss_mw_50sim = get_roc_stats(df = pred_topolink_mw_bliss, pred_col = &quot;synergy_prob_ss_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topolink_res_ss_mw_150sim = get_roc_stats(df = pred_topolink_mw_bliss, pred_col = &quot;synergy_prob_ss_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topolink_res_prolif_mw_50sim = get_roc_stats(df = pred_topolink_mw_bliss, pred_col = &quot;synergy_prob_prolif_50sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) topolink_res_prolif_mw_150sim = get_roc_stats(df = pred_topolink_mw_bliss, pred_col = &quot;synergy_prob_prolif_150sim&quot;, label_col = &quot;observed&quot;, direction = &quot;&gt;&quot;) # Plot ROCs plot(x = topolink_res_ss_ew_50sim$roc_stats$FPR, y = topolink_res_ss_ew_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Ensemble-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = topolink_res_ss_ew_150sim$roc_stats$FPR, y = topolink_res_ss_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = topolink_res_prolif_ew_50sim$roc_stats$FPR, y = topolink_res_prolif_ew_50sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = topolink_res_prolif_ew_150sim$roc_stats$FPR, y = topolink_res_prolif_ew_150sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(topolink_res_ss_ew_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(topolink_res_ss_ew_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(topolink_res_prolif_ew_50sim$AUC, digits = 2), &quot;Random (50 sim)&quot;), paste(round(topolink_res_prolif_ew_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) plot(x = topolink_res_ss_mw_50sim$roc_stats$FPR, y = topolink_res_ss_mw_50sim$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = &#39;ROC curve, Model-wise synergies (Bliss)&#39;, xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = topolink_res_ss_mw_150sim$roc_stats$FPR, y = topolink_res_ss_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[2]) lines(x = topolink_res_prolif_mw_50sim$roc_stats$FPR, y = topolink_res_prolif_mw_50sim$roc_stats$TPR, lwd = 3, col = my_palette[3]) lines(x = topolink_res_prolif_mw_150sim$roc_stats$FPR, y = topolink_res_prolif_mw_150sim$roc_stats$TPR, lwd = 3, col = my_palette[4]) legend(&#39;bottomright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(topolink_res_ss_mw_50sim$AUC, digits = 2), &quot;Calibrated (50 sim)&quot;), paste(round(topolink_res_ss_mw_150sim$AUC, digits = 2), &quot;Calibrated (150 sim)&quot;), paste(round(topolink_res_prolif_mw_50sim$AUC, digits = 2), &quot;Random (50 sim)&quot;), paste(round(topolink_res_prolif_mw_150sim$AUC, digits = 2), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) Figure 59: ROC curves (CASCADE 2.0, Link Operator and Topology Mutations, Bliss synergy method) PR curves pr_topolink_res_ss_ew_50sim = pr.curve(scores.class0 = pred_topolink_ew_bliss %&gt;% pull(ss_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_topolink_res_ss_ew_150sim = pr.curve(scores.class0 = pred_topolink_ew_bliss %&gt;% pull(ss_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_topolink_res_prolif_ew_50sim = pr.curve(scores.class0 = pred_topolink_ew_bliss %&gt;% pull(prolif_score_50sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_topolink_res_prolif_ew_150sim = pr.curve(scores.class0 = pred_topolink_ew_bliss %&gt;% pull(prolif_score_150sim) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_bliss %&gt;% pull(observed), curve = TRUE) pr_topolink_res_ss_mw_50sim = pr.curve(scores.class0 = pred_topolink_mw_bliss %&gt;% pull(synergy_prob_ss_50sim), weights.class0 = pred_topolink_mw_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_topolink_res_ss_mw_150sim = pr.curve(scores.class0 = pred_topolink_mw_bliss %&gt;% pull(synergy_prob_ss_150sim), weights.class0 = pred_topolink_mw_bliss %&gt;% pull(observed), curve = TRUE) pr_topolink_res_prolif_mw_50sim = pr.curve(scores.class0 = pred_topolink_mw_bliss %&gt;% pull(synergy_prob_prolif_50sim), weights.class0 = pred_topolink_mw_bliss %&gt;% pull(observed), curve = TRUE) pr_topolink_res_prolif_mw_150sim = pr.curve(scores.class0 = pred_topolink_mw_bliss %&gt;% pull(synergy_prob_prolif_150sim), weights.class0 = pred_topolink_mw_bliss %&gt;% pull(observed), curve = TRUE) plot(pr_topolink_res_ss_ew_50sim, main = &#39;PR curve, Ensemble-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_topolink_res_ss_ew_150sim, add = TRUE, color = my_palette[2]) plot(pr_topolink_res_prolif_ew_50sim, add = TRUE, color = my_palette[3]) plot(pr_topolink_res_prolif_ew_150sim, add = TRUE, color = my_palette[4]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(pr_topolink_res_ss_ew_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_topolink_res_ss_ew_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_topolink_res_prolif_ew_50sim$auc.davis.goadrich, digits = 3), &quot;Random (50 sim)&quot;), paste(round(pr_topolink_res_prolif_ew_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) plot(pr_topolink_res_ss_mw_50sim, main = &#39;PR curve, Model-wise synergies (Bliss)&#39;, auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_topolink_res_ss_mw_150sim, add = TRUE, color = my_palette[2]) plot(pr_topolink_res_prolif_mw_50sim, add = TRUE, color = my_palette[3]) plot(pr_topolink_res_prolif_mw_150sim, add = TRUE, color = my_palette[4]) legend(&#39;topright&#39;, title = &#39;AUC&#39;, col = my_palette[1:4], pch = 19, legend = c(paste(round(pr_topolink_res_ss_mw_50sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (50 sim)&quot;), paste(round(pr_topolink_res_ss_mw_150sim$auc.davis.goadrich, digits = 3), &quot;Calibrated (150 sim)&quot;), paste(round(pr_topolink_res_prolif_mw_50sim$auc.davis.goadrich, digits = 3), &quot;Random (50 sim)&quot;), paste(round(pr_topolink_res_prolif_mw_150sim$auc.davis.goadrich, digits = 3), &quot;Random (150 sim)&quot;))) grid(lwd = 0.5) Figure 60: PR curves (CASCADE 2.0, Link Operator and Topology Mutations, Bliss synergy method) The PR curves show that the performance of each individual predictor is poor compared to the baseline. The model-wise approach produces better ROC and PR results than the ensemble-wise approach (performance in terms of AUC value is almost doubled) AUC sensitivity Investigate same thing as described in here. This is very crucial since the PR performance is poor for the individual predictors, but a combined predictor might be able to counter this. We will combine the synergy scores from the random proliferative simulations with the results from the calibrated Gitsbe simulations (number of simulations: \\(150\\)). # Ensemble-wise betas = seq(from = -5, to = 5, by = 0.1) prolif_roc = sapply(betas, function(beta) { pred_topolink_ew_bliss = pred_topolink_ew_bliss %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = roc.curve(scores.class0 = pred_topolink_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_bliss %&gt;% pull(observed)) auc_value = res$auc }) prolif_pr = sapply(betas, function(beta) { pred_topolink_ew_bliss = pred_topolink_ew_bliss %&gt;% mutate(combined_score = ss_score_150sim + beta * prolif_score_150sim) res = pr.curve(scores.class0 = pred_topolink_ew_bliss %&gt;% pull(combined_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_bliss %&gt;% pull(observed)) auc_value = res$auc.davis.goadrich }) df_ew = as_tibble(cbind(betas, prolif_roc, prolif_pr)) df_ew = df_ew %&gt;% tidyr::pivot_longer(-betas, names_to = &quot;type&quot;, values_to = &quot;AUC&quot;) ggline(data = df_ew, x = &quot;betas&quot;, y = &quot;AUC&quot;, numeric.x.axis = TRUE, color = &quot;type&quot;, plot_type = &quot;l&quot;, xlab = TeX(&quot;$\\\\beta$&quot;), ylab = &quot;AUC (Area Under Curve)&quot;, legend = &quot;none&quot;, facet.by = &quot;type&quot;, palette = my_palette, ylim = c(0,0.85), panel.labs = list(type = c(&quot;Precision-Recall&quot;, &quot;ROC&quot;)), title = TeX(&quot;AUC sensitivity to $\\\\beta$ parameter&quot;)) + theme(plot.title = element_text(hjust = 0.5)) + geom_vline(xintercept = 0) + geom_vline(xintercept = -1, color = &quot;black&quot;, size = 0.3, linetype = &quot;dashed&quot;) + geom_text(aes(x=-1.5, label=&quot;β = -1&quot;, y=0.35), colour=&quot;black&quot;, angle = 90) + grids() Figure 61: AUC sensitivity (CASCADE 2.0, Link Operator and Topology Mutations, Bliss synergy method, Ensemble-wise results) The random proliferative models can be used to normalize against the predictions of the calibrated models and thus bring significant contribution to the calibrated models performance (both ROC-AUC and PR-AUC are increased). The \\(\\beta_{best}\\) values of the combined calibrated and random model predictor that maximize the ROC-AUC and PR-AUC respectively are \\(\\beta_{best}^{\\text{ROC-AUC}}=-1.1\\) and \\(\\beta_{best}^{\\text{PR-AUC}}=-1.3\\). For \\(\\beta=-1\\) we still see significant performance improvement. Best ROC and PRC For both the Bliss and HSA ensemble-wise results we demonstrated above that a value of \\(\\beta_{best}=-1\\) can result in significant performance gain of the combined predictor (\\(calibrated + \\beta \\times random\\)). So, the best ROC and PR curves we can get with our simulations when using models with both link operator (balance) and topology mutations are: best_beta = -1 pred_topolink_ew_hsa = pred_topolink_ew_hsa %&gt;% mutate(best_score = ss_score_150sim + best_beta * prolif_score_150sim) pred_topolink_ew_bliss = pred_topolink_ew_bliss %&gt;% mutate(best_score = ss_score_150sim + best_beta * prolif_score_150sim) roc_best_res_hsa = get_roc_stats(df = pred_topolink_ew_hsa, pred_col = &quot;best_score&quot;, label_col = &quot;observed&quot;) roc_best_res_bliss = get_roc_stats(df = pred_topolink_ew_bliss, pred_col = &quot;best_score&quot;, label_col = &quot;observed&quot;) pr_best_res_hsa = pr.curve(scores.class0 = pred_topolink_ew_hsa %&gt;% pull(best_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_hsa %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) pr_best_res_bliss = pr.curve(scores.class0 = pred_topolink_ew_bliss %&gt;% pull(best_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_bliss %&gt;% pull(observed), curve = TRUE) # Plot best ROCs plot(x = roc_best_res_hsa$roc_stats$FPR, y = roc_best_res_hsa$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = TeX(&#39;ROC curve (Ensemble-wise), $calibrated + \\\\beta \\\\times random$&#39;), xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = roc_best_res_bliss$roc_stats$FPR, y = roc_best_res_bliss$roc_stats$TPR, lwd = 3, col = my_palette[2]) legend(&#39;bottomright&#39;, title = TeX(&#39;AUC ($\\\\beta$ = -1)&#39;), col = c(my_palette[1:2]), pch = 19, cex = 1.5, legend = c(paste(round(roc_best_res_hsa$AUC, digits = 2), &#39;HSA (150 sim)&#39;), paste(round(roc_best_res_bliss$AUC, digits = 2), &#39;Bliss (150 sim)&#39;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) # Plot best PRCs plot(pr_best_res_hsa, main = TeX(&#39;PR curve (Ensemble-wise), $calibrated + \\\\beta \\\\times random$&#39;), auc.main = FALSE, color = my_palette[1], rand.plot = TRUE) plot(pr_best_res_bliss, add = TRUE, color = my_palette[2]) legend(&#39;topright&#39;, title = TeX(&#39;AUC ($\\\\beta$ = -1)&#39;), col = c(my_palette[1:2]), pch = 19, cex = 1.5, legend = c(paste(round(pr_best_res_hsa$auc.davis.goadrich, digits = 2), &#39;HSA (150 sim)&#39;), paste(round(pr_best_res_bliss$auc.davis.goadrich, digits = 2), &#39;Bliss (150 sim)&#39;))) grid(lwd = 0.5) Figure 62: ROC and PR curve for best beta (CASCADE 2.0, Link Operator and Topology Mutations) "],["parameterization-vs-performance.html", "Parameterization vs Performance Best ROC and PRC Bootstrap Simulations", " Parameterization vs Performance Best ROC and PRC In this section we will compare the normalized combined predictors (\\(calibrated + \\beta \\times random, \\beta=-1\\)) across all 3 model parameterizations/mutations we tested in this report for CASCADE 2.0: link operator mutations, topology mutations and both. We use the normalization parameter \\(\\beta=-1\\) for all combined predictors, as it was observed throughout the report that it approximately maximizes the performance of all Bliss-assessed, ensemble-wise combined synergy predictors in terms of ROC and PR AUC. The results are from the \\(150\\) simulation runs (\\(450\\) models). Why call \\(\\beta\\) a normalization parameter? What matters for the calculation of the ROC and PR points is the ranking of the synergy scores. Thus if we bring the predictor’s synergy scores to the exponential space, a value of \\(-1\\) for \\(\\beta\\) translates to a simple fold-change normalization technique: \\(calibrated + \\beta \\times random \\overset{\\beta = -1}{=} calibrated - random \\xrightarrow[\\text{same ranking}]{e(x) \\text{ monotonous}}\\) \\(exp(calibrated - random)=exp(calibrated)/exp(random)\\). # Link operator mutations results (`best_score2` has the results for β = -1, `best_score1` for β = -1.6) roc_link_res = get_roc_stats(df = pred_ew_bliss, pred_col = &quot;best_score2&quot;, label_col = &quot;observed&quot;) pr_link_res = pr.curve(scores.class0 = pred_ew_bliss %&gt;% pull(best_score2) %&gt;% (function(x) {-x}), weights.class0 = pred_ew_bliss %&gt;% pull(observed), curve = TRUE, rand.compute = TRUE) # Topology mutations results roc_topo_res = get_roc_stats(df = pred_topo_ew_bliss, pred_col = &quot;best_score&quot;, label_col = &quot;observed&quot;) pr_topo_res = pr.curve(scores.class0 = pred_topo_ew_bliss %&gt;% pull(best_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topo_ew_bliss %&gt;% pull(observed), curve = TRUE) # Both Link Operator and Topology mutations results roc_topolink_res = get_roc_stats(df = pred_topolink_ew_bliss, pred_col = &quot;best_score&quot;, label_col = &quot;observed&quot;) pr_topolink_res = pr.curve(scores.class0 = pred_topolink_ew_bliss %&gt;% pull(best_score) %&gt;% (function(x) {-x}), weights.class0 = pred_topolink_ew_bliss %&gt;% pull(observed), curve = TRUE) # Plot best ROCs plot(x = roc_link_res$roc_stats$FPR, y = roc_link_res$roc_stats$TPR, type = &#39;l&#39;, lwd = 3, col = my_palette[1], main = TeX(&#39;ROC curves (Ensemble-wise), $calibrated + \\\\beta \\\\times random$&#39;), xlab = &#39;False Positive Rate (FPR)&#39;, ylab = &#39;True Positive Rate (TPR)&#39;) lines(x = roc_topo_res$roc_stats$FPR, y = roc_topo_res$roc_stats$TPR, lwd = 2, col = my_palette[2]) lines(x = roc_topolink_res$roc_stats$FPR, y = roc_topolink_res$roc_stats$TPR, lwd = 2.3, col = my_palette[3]) legend(&#39;bottomright&#39;, title = TeX(&#39;AUC ($\\\\beta$ = -1): Mutations&#39;), col = c(my_palette[1:3]), pch = 19, cex = 1.5, legend = c(paste(round(roc_link_res$AUC, digits = 2), &#39;Link Operator&#39;), paste(round(roc_topo_res$AUC, digits = 2), &#39;Topology&#39;), paste(round(roc_topolink_res$AUC, digits = 2), &#39;Both&#39;))) grid(lwd = 0.5) abline(a = 0, b = 1, col = &#39;lightgrey&#39;, lty = &#39;dotdash&#39;, lwd = 1.2) # Plot best PRCs plot(pr_link_res, main = TeX(&#39;PR curves (Ensemble-wise), $calibrated + \\\\beta \\\\times random$&#39;), auc.main = FALSE, color = my_palette[1], rand.plot = TRUE, lwd = 3) plot(pr_topo_res, add = TRUE, color = my_palette[2], lwd = 2) plot(pr_topolink_res, add = TRUE, color = my_palette[3], lwd = 2.3) legend(&#39;topright&#39;, title = TeX(&#39;AUC ($\\\\beta$ = -1): Mutations&#39;), col = c(my_palette[1:3]), pch = 19, cex = 1.3, legend = c(paste(round(pr_link_res$auc.davis.goadrich, digits = 2), &#39;Link Operator&#39;), paste(round(pr_topo_res$auc.davis.goadrich, digits = 2), &#39;Topology&#39;), paste(round(pr_topolink_res$auc.davis.goadrich, digits = 2), &#39; Both&#39;))) grid(lwd = 0.5) Figure 63: Comparing ROC and PR curves for combined predictors across 3 parameterization schemes (CASCADE 2.0, Bliss synergy method, Ensemble-wise results) We observe that if we had used the results for the link operator only combined predictor with \\(\\beta_{best}=-1.6\\) as was demonstrated here, we would have an AUC-ROC of \\(0.85\\) and AUC-PR of \\(0.27\\), which are pretty close to the results we see above for \\(\\beta=-1\\), using both link and topology mutations. Overall, this suggests that to parameterize our boolean models using topology mutations can increase the performance of our proposed synergy prediction approach much more than using either link operator (balance) mutations alone or combined with topology parameterization. Note that the difference in terms of ROC AUC is not significant compared to the difference of PR AUC scores and since the dataset we test our models on is fairly imbalanced, we base our conclusion on the information from the PR plots (Saito and Rehmsmeier 2015). Bootstrap Simulations Now we would like to statistically verify the previous conclusion (that topology is superior to the other two parameterization schemes and produces better predictive models for our dataset) and so we will run a bootstrap analysis. Simply put, we generate 3 large pools of calibrated to steady state models (\\(4500\\) models each). Each pool corresponds to the 3 parameterization schemes (i.e. it has models with either topology mutations only, link-operator mutations only, or models with both mutations). Then, we take several model samples from each pool (\\(25\\) samples, each sample containing \\(300\\) models) and run the drug response simulations for these calibrated model ensembles to get their predictions. Normalizing each calibrated simulation prediction output to the corresponding random (proliferative) model predictions (using a \\(\\beta=-1\\) as above), results in different ROC and PR AUCs for each parameterization scheme and chosen bootstrapped sample. See more details on reproducing the results on section Parameterization Bootstrap. Load the already-stored result: res = readRDS(file = &quot;data/res_param_boot_aucs.rds&quot;) Compare all 3 schemes # define group comparisons for statistics my_comparisons = list(c(&quot;link-only&quot;,&quot;topology-only&quot;), c(&quot;link-only&quot;,&quot;topo-and-link&quot;), c(&quot;topology-only&quot;,&quot;topo-and-link&quot;)) # ROC AUCs ggboxplot(data = res, x = &quot;param&quot;, y = &quot;roc_auc&quot;, fill = &quot;param&quot;, add = &quot;jitter&quot;, palette = &quot;Set1&quot;, xlab = &quot;Parameterization&quot;, ylab = &quot;ROC AUC&quot;, title = &quot;Parameterization vs Performance (ROC)&quot;) + stat_compare_means(comparisons = my_comparisons, method = &quot;wilcox.test&quot;, label = &quot;p.format&quot;) + theme(plot.title = element_text(hjust = 0.5)) + theme(legend.position = &quot;none&quot;) # PR AUCs ggboxplot(data = res, x = &quot;param&quot;, y = &quot;pr_auc&quot;, fill = &quot;param&quot;, add = &quot;jitter&quot;, palette = &quot;Set1&quot;, xlab = &quot;Parameterization&quot;, ylab = &quot;PR AUC&quot;, title = &quot;Parameterization vs Performance (Precision-Recall)&quot;) + stat_compare_means(comparisons = my_comparisons, method = &quot;wilcox.test&quot;, label = &quot;p.format&quot;) + theme(plot.title = element_text(hjust = 0.5)) + theme(legend.position = &quot;none&quot;) Figure 64: Comparing ROC and PR AUCs from bootstrapped calibrated model ensembles normalized to random model predictions across 3 parameterization schemes (CASCADE 2.0, Bliss synergy method, Ensemble-wise results) The topology mutations generate the best performing models in terms of PR AUC with statistical significance compared to the other two groups of model ensembles using different parameterization. In terms of ROC AUC performance we also note the larger variance of the topology mutated models. Compare Topology vs Link-operator Parameterization # load the data res = readRDS(file = &quot;results/res_param_boot_aucs.rds&quot;) # filter data res = res %&gt;% filter(param != &quot;topo-and-link&quot;) param_comp = list(c(&quot;link-only&quot;,&quot;topology-only&quot;)) stat_test_roc = res %&gt;% rstatix::wilcox_test(formula = roc_auc ~ param, comparisons = param_comp) %&gt;% rstatix::add_significance(&quot;p&quot;) # ROC AUCs ggboxplot(res, x = &quot;param&quot;, y = &quot;roc_auc&quot;, fill = &quot;param&quot;, palette = &quot;Set1&quot;, add = &quot;jitter&quot;, xlab = &quot;&quot;, ylab = &quot;ROC AUC&quot;, title = &quot;Parameterization vs Performance (ROC)&quot;) + scale_x_discrete(breaks = c(&quot;link-only&quot;,&quot;topology-only&quot;), labels = c(&quot;Link-Operator Mutations&quot;, &quot;Edge Mutations&quot;)) + ggpubr::stat_pvalue_manual(stat_test_roc, label = &quot;p = {p} ({p.signif})&quot;, y.position = c(1)) + ylim(c(0.2,1)) + theme_classic(base_size = 14) + theme(plot.title = element_text(hjust = 0.5), axis.text = element_text(size = 14)) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 2.1, y = 0.45, label=&quot;Random Predictions (AUC = 0.5)&quot;)) + theme(legend.position = &quot;none&quot;) stat_test_pr = res %&gt;% rstatix::wilcox_test(formula = pr_auc ~ param, comparisons = param_comp) %&gt;% rstatix::add_significance(&quot;p&quot;) %&gt;% rstatix::add_y_position() # PR AUCs ggboxplot(res, x = &quot;param&quot;, y = &quot;pr_auc&quot;, fill = &quot;param&quot;, palette = &quot;Set1&quot;, add = &quot;jitter&quot;, xlab = &quot;&quot;, ylab = &quot;PR AUC&quot;, title = &quot;Parameterization vs Performance (Precision-Recall)&quot;) + scale_x_discrete(breaks = c(&quot;link-only&quot;,&quot;topology-only&quot;), labels = c(&quot;Link-Operator Mutations&quot;, &quot;Edge Mutations&quot;)) + ggpubr::stat_pvalue_manual(stat_test_pr, label = &quot;p = {p} ({p.signif})&quot;) + theme_classic(base_size = 14) + theme(plot.title = element_text(hjust = 0.5), axis.text = element_text(size = 14)) + geom_hline(yintercept = 6/153, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 2.15, y = 0.08, label=&quot;Random Predictions (AUC = 0.04)&quot;)) + theme(legend.position = &quot;none&quot;) Figure 65: Comparing ROC and PR AUCs from bootstrapped calibrated model ensembles normalized to random model predictions - Topology vs Link-operator mutations (CASCADE 2.0, Bliss synergy method, Ensemble-wise results) "],["annotated-heatmaps.html", "Annotated Heatmaps Annotations Link-Operator mutated models Topology-mutated models ERK performance investigation", " Annotated Heatmaps In this section we will use the models from the bootstrap analysis above and produce heatmaps of the models stable states and parameterization. Specifically, we will use the two CASCADE 2.0 model pools created, that have either only link-operator mutated or only topology-mutated models. For both pools, a stable state heatmap will be produced (columns are nodes). For the first pool, the parameterization is presented with a link-operator heatmap (columns are nodes) and for the second pool as an edge heatmap (columns are edges). Annotations Pathways Every node in CASCADE 2.0 belongs to a specific pathway, as can be seen in Fig. 1A of (Niederdorfer et al. 2020). The pathway categorization is a result of a computational analysis performed by the author of that paper and provided as file here. We present the node and edge distribution across the pathways in CASCADE 2.0. For the edge pathway annotation, either both ends/nodes of an edge belong to a specific pathway and we use that label or the nodes belong to different pathways and the edge is labeled as Cross-talk: knitr::include_graphics(path = &#39;img/node_path_dist.png&#39;) knitr::include_graphics(path = &#39;img/edge_path_dist.png&#39;) Figure 66: Node and Edge Distribution across pathways in CASCADE 2.0 \\(\\approx50\\%\\) of the edges are labeled Cross-talk Pathways with more nodes have also more edges between these nodes Training Data We annotate in the stable state heatmaps the states (activation or inhibition) of the nodes as they were in the AGS training data. Connectivity We annotate each node’s in-degree or out-degree connectivity for the node-oriented heatmaps, i.e. the number of its regulators (in-degree) or the number of nodes it connects to (out-degree). For the edge-oriented heatmaps, we provide either the in-degree of each edge’s target or the out-degree of each edge’s source. Drug Target The CASCADE 2.0 model was used to test in-silico prediction performance of the drug combination dataset in (Flobak et al. 2019). The drug panel used for the simulations involved \\(18\\) drugs (excluding the SF drug), each one having one to several drug targets in the CASCADE 2.0 network. We annotate this information on the combined stable states and parameterization heatmap, by specifying exactly which nodes are drug targets. For the edge-oriented heatmaps, we specify either if an edge’s target, source, both or none of them is a drug target. COSMIC Cancer Gene Census (CGC) We annotate some of the CASCADE 2.0 nodes either as tumor suppressors (TSG), oncogenes or both, based on the COSMIC Cancer Gene Census dataset, an expert-curated effort to describe genes driving human cancer (Sondka et al. 2018). We used the HGNC symbols of the CASCADE 2.0 nodes and via the HGNC REST API (Braschi et al. 2019), we got the respective Ensemble IDs that helped us match the genes in the COSMIC dataset. From the COSMIC genes that we got back, we did not restrict them to a particular cancer type, we discarded the Tier 2 (lower quality) genes, as well the ones that were annotated with only the term fusion in their respective cancer role. We kept cancer genes that were annotated as both TSGs and fusion or oncogenes and fusion genes and maintained only the TSG or oncogene annotation tag (discarding only the fusion tag). Lastly note that for the CASCADE 2.0 nodes that represent families, complexes, etc. and they include a few COSMIC genes in their membership, we use a majority rule to decide which cancer role to assign to these nodes. See the script get_cosmic_data_annot.R for more details. A total of \\(52\\) CASCADE 2.0 nodes were annotated and in the following figure we can see that most of them were oncogenes, followed by TSGs and a few annotated as both categories: knitr::include_graphics(path = &#39;img/cosmic_cascade2_dist.png&#39;) Figure 67: CASCADE 2.0 Nodes and their role in cancer as annotated by the COSMIC CGC dataset Agreement (Parameterization vs Activity) For the link-operator CASCADE 2.0 nodes we calculate the percent agreement between link-operator parameterization (AND-NOT =&gt; \\(0\\), OR-NOT =&gt; \\(1\\)) and stable state activity (Inhibited state =&gt; \\(0\\), Active state =&gt; \\(1\\)). The percent agreement is defined here as the number of matches (node has the link-operator AND-NOT (resp. OR-NOT) and it’s stable state activity value is \\(0\\) (resp. \\(1\\))) divided by the total amount of models (\\(4500\\)). Note that the models of the link-operator Gitsbe pool from the previous bootstrap analysis that we will use for the heatmaps, had precicely \\(1\\) stable state each, making thus the aforementioned comparison/calculation much easier. Link-Operator mutated models See script lo_mutated_models_heatmaps.R for creating the heatmaps. knitr::include_graphics(path = &#39;img/lo_ss_heat.png&#39;) Figure 68: Stable state annotated heatmap for the link operator-mutated models. A total of 144 CASCADE 2.0 nodes have been grouped to 3 clusters with K-means. Training data, COSMIC, pathway and in-degree connectivity annotations are shown. Calibrated models obey training data, i.e. stable states for nodes specified in training data, match the training data activity values knitr::include_graphics(path = &#39;img/cosmic_state_cmp.png&#39;) Figure 69: Comparing the average stable activity state between the TSG and the oncogene nodes. The Wilcoxon test is used to derive the p-value for the difference between the two groups. Nodes that are annotated as oncogenes have statistically higher average activity state than the ones annotated as TSGs (also evident partially from the stable states heatmap). The median values for the two groups in the boxplot are \\(0.997\\) (oncogene) and \\(0.452\\) (TSG) respectively. The RTPK_g node is an outlier in our data: it is annotated as an oncogene and in all models it had a stable state of \\(0\\). knitr::include_graphics(path = &#39;img/lo_heat.png&#39;) Figure 70: Parameterization annotated heatmap for the link operator-mutated models. Only the CASCADE 2.0 nodes that have a link-operator in their respective boolean equation are shown. The 52 link-operator nodes have been grouped to 3 clusters with K-means. COSMIC, Pathway and in-degree connectivity annotations are shown. knitr::include_graphics(path = &#39;img/lo_combined_heat.png&#39;) Figure 71: Combined stable states and parameterization heatmaps. Only the CASCADE 2.0 nodes that have a link-operator in their respective boolean equation are shown. The 52 link-operator nodes have been grouped to 3 clusters with K-means using the stable states matrix data. The link-operator data heatmap has the same row order as the stable states heatmap. Training data, COSMIC, Pathway, Drug Target, in-degree, out-degree Connectivity and Percent Agreement annotations are shown. High degree of agreement between link-operator parameterization and stable state activity. Nodes of the second cluster (the most heterogeneous one) where the parameterization and stable state activity seem to be assigned randomly (i.e. in \\(\\approx50\\%\\) of the total models a node is in an inhibited vs an active state, or has the AND-NOT vs the OR-NOT link-operator) we observe the high percent agreement scores. In the third cluster, where the models nodes are mostly in an active state (obeying the training data), we observe that the parameterization does not affect the stable state activity and that these nodes have mostly low connectivity (\\(&lt;5\\) regulators). Topology-mutated models See script topo_mutated_models_heatmaps.R for creating the heatmaps. knitr::include_graphics(path = &#39;img/topo_ss_heat.png&#39;) Figure 72: Stable state annotated heatmap for the topology-mutated models. A total of 144 CASCADE 2.0 nodes have been grouped to 3 clusters with K-means. Training data, pathway and edge target in-degree connectivity annotations are shown. Calibrated models obey training data, i.e. stable states for nodes specified in training data, match the training data activity values. knitr::include_graphics(path = &#39;img/edge_heat.png&#39;) Figure 73: Edge annotated heatmap. All edges from the CASCADE 2.0 topology are included. A total of 367 edges have been grouped to 5 clusters with K-means. Pathway, Drug Target, edge target in-degree and edge source out-degree Connectivity annotations are shown. Looking at the above figure from left to right we have \\(5\\) clusters: First cluster has all the edges whose target has a single regulator and these are not removed by the topology mutations in Gitsbe, to preserve the network connectivity. Second cluster with edges that are mostly present in the topology-mutated models. These edges have two distinguished characteristics: they show high target connectivity (\\(\\ge 5\\) regulators) - meaning that they target mostly hub-nodes - and their source and target nodes belong mostly to different pathways (i.e. they are Cross-talk edges). Third cluster with edges that have a ~50% percent chance to stay in the topology-mutated models. These edges belong to a variety of pathways and can have both low and high target in-degree connectivity. Fourth cluster with edges that will most likely be removed in the topology-mutated models. These edges belong to a variety of pathways and mostly have low target in-degree connectivity. Fifth cluster with edges that are mostly absent in the topology-mutated models. Some of them are high target-connectivity nodes and most of them belong to the TGF-b pathway. Now, we present a subset of columns (edges) of the above heatmap, chosen based on some user-defined thresholds to include only the edges that are either mostly absent or present in the models (so the second and last cluster). We do not include the edges that are present in all models (cluster 1) since there were the ones whose target had only \\(1\\) regulator and as such they couldn’t be removed by the Gitsbe algorithm (we don’t lose connectivity when using topology mutations). knitr::include_graphics(path = &#39;img/edge_heat_stable.png&#39;) Figure 74: Edge annotated heatmap. A subset of the total edges is included, the least heterogeneous across all the models (rows) based on some user-defined thresholds. Edges that were always present are removed (connectivity = 1). Edges have been grouped to 2 clusters with K-means. Pathway, Drug Target, edge target in-degree and edge source out-degree Connectivity annotations are shown. ERK performance investigation We investigate the role of the activity of the ERK_f node in the performance of boolean models with link operator mutations. In the middle cluster of the stable states heatmap (see Figure 68) there were lot of nodes whose stable state activity was different for about half of the models. For example, although ERK_f is defined in an active state in the training data, we also get models after training that have it inhibited in their corresponding stable state. Since these boolean models essentially represent AGS proliferating cancer cells, it’s remarkable that the literature curation results are also divided, i.e. around half of the publications support that activation of ERK_f and the other its inhibition (see Table S2 from (Flobak et al. 2015)). So, do we have a way to distinguish which of the two scenarios (ERK active vs inhibited) better matches the observed biological reality? Model-wise analyses provide evidence which suggests that the overexpression of ERK_f is a characteristic biomarker of the higher performance AGS models in terms of synergy prediction, i.e. models that have ERK_f active in their stable state can predict synergies that have been observed experimentally in the AGS cancer cells. See methodology and how to reproduce the results here. res = readRDS(file = &quot;data/res_erk.rds&quot;) set1_col = RColorBrewer::brewer.pal(9, &#39;Set1&#39;) stat_test_roc = res %&gt;% rstatix::wilcox_test(formula = roc_auc ~ erk_state) %&gt;% rstatix::add_significance(&quot;p&quot;) # ROC AUCs ggboxplot(res, x = &quot;erk_state&quot;, y = &quot;roc_auc&quot;, fill = &quot;erk_state&quot;, palette = c(set1_col[3], set1_col[1]), add = &quot;jitter&quot;, xlab = &quot;&quot;, ylab = &quot;ROC AUC&quot;, title = &quot;ERK_f Pools Performance Comparison (ROC)&quot;) + scale_x_discrete(breaks = c(&quot;active&quot;,&quot;inhibited&quot;), labels = c(&quot;Active&quot;, &quot;Inhibited&quot;)) + ggpubr::stat_pvalue_manual(stat_test_roc, label = &quot;p = {p} ({p.signif})&quot;, y.position = c(1)) + ylim(c(0,1)) + theme(plot.title = element_text(hjust = 0.5), axis.text = element_text(size = 14)) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 2.1, y = 0.55, label = &quot;Random Predictions (AUC = 0.5)&quot;)) + theme(legend.position = &quot;none&quot;) stat_test_pr = res %&gt;% rstatix::wilcox_test(formula = pr_auc ~ erk_state) %&gt;% rstatix::add_significance(&quot;p&quot;) %&gt;% rstatix::add_y_position() # PR AUCs ggboxplot(res, x = &quot;erk_state&quot;, y = &quot;pr_auc&quot;, fill = &quot;erk_state&quot;, palette = c(set1_col[3], set1_col[1]), add = &quot;jitter&quot;, xlab = &quot;&quot;, ylab = &quot;PR AUC&quot;, title = &quot;ERK_f Pools Performance Comparison (Precision-Recall)&quot;) + scale_x_discrete(breaks = c(&quot;active&quot;,&quot;inhibited&quot;), labels = c(&quot;Active&quot;, &quot;Inhibited&quot;)) + ggpubr::stat_pvalue_manual(stat_test_pr, label = &quot;p = {p} ({p.signif})&quot;) + theme(plot.title = element_text(hjust = 0.5), axis.text = element_text(size = 14)) + # 6 out 153 drug combos were synergistic geom_hline(yintercept = 6/153, linetype = &#39;dashed&#39;, color = &quot;red&quot;) + geom_text(aes(x = 1.05, y = 0.06, label = &quot;Random Predictions (AUC = 0.04)&quot;)) + theme(legend.position = &quot;none&quot;) Figure 75: Comparing drug prediction performance (ROC and PR AUCs) between bootstrapped calibrated model ensembles from two model pools. Results were normalized to random model predictions. The models had link operator mutations only. In one pool, each model had a single stable state with ERK_f active and on the other pool ERK_f was inhibited at the stable state (CASCADE 2.0, Bliss synergy method, Ensemble-wise results) Significantly better performance of the bootstrapped ensembles with ERK_f active, suggesting that ERK should be considered active in AGS cells from a functional point of view. "],["reproduce-data-simulation-results.html", "Reproduce Data &amp; Simulation Results ROC and PR curves, Fitness Evolution2 Fitness vs Performance Methods Random Model Bootstrap Parameterization Bootstrap ERK investigation CASCADE 1.0 Calibrated Models bootstrap Repo results structure", " Reproduce Data &amp; Simulation Results We have stored all the simulations results in an open-access repository provided by Zenodo: ROC and PR curves, Fitness Evolution2 Install the druglogics-synergy module and use the version 1.2.0: git checkout v1.2.0 (or use directly the released v1.2.0 package) Run the script run_druglogics_synergy.sh in the above repo. You can of course change several other parameters in the input files or the script itself (e.g. number of simulations to run - see here for a complete list of configuration options). To get the results for the topology mutations for CASCADE 2.0 you need to change the ags_cascade_2.0/config file option topology_mutations: 10 and balance_mutations: 0 (the default options are \\(0\\) topology mutations and \\(3\\) link-operator/balance mutations). If you wish to get the results using both kinds of mutation, set both topology_mutations and balance_mutations options to a non-zero value (\\(10\\) and \\(3\\) were used in the simulations). So, for example to get the simulation output directories for the Cascade 1.0 Analysis I just run the run_druglogics_synergy.sh script with the following options defined in the loops inside (no need to change any further configuration): cascade_version: 1.0 (which topology to use) train: ss rand (train to the AGS steady state or to a (random) proliferation phenotype)) sim_num: 50 (number of simulations) attr_tool: fixpoints (attractor tool, common across all report) synergy_method: hsa bliss (synergy calculation method used by drabme) Each subsequent druglogics-synergy execution results in an output directory and the files of interest (which are used to produce the ROC and PR curves in this report and the AUC sensitivity figures) are the modelwise_synergies.tab and the ensemble_synergies.tab respectively. For the fitness evolution figures we used the summary.txt file of the corresponding simulations. Specifically, the results described above are stored in the compressed Zenodo file sim_res.tar.gz. When uncompressed, the sim_res.tar.gz file outputs 2 separate directories, one per different topology (CASCADE 1.0 and CASCADE 2.0). The directory with the CASCADE 2.0 related results has 3 subsequent directories, corresponding to the different parameterization that was used in the simulations (link mutations, topology mutations or both). Each further directory, specifies on its name the training type, simulation number, attractor tool and synergy assessment method. Fitness vs Performance Methods Generate the training data samples Use the gen_training_data.R script to produce the training data samples. In this script we first choose \\(11\\) numbers that represent the number of nodes that are going to be flipped in the AGS steady state. These numbers range from \\(1\\) (flip just one node) to \\(24\\) (flip all nodes, i.e. create a complete reversed steady state). Then, for each such number, we generate \\(20\\) new partially correct steady states, each one having the same amount of randomly-chosen flips in the steady state (e.g. \\(20\\) steady states where randomly-chosen sets of \\(3\\) nodes have been flipped). Thus, in total, \\(205\\) training data sample files are produced (\\(205 = 9 \\times 20 + 1 \\times 24 + 1 \\times 1\\), where from the \\(11\\) number of flips, the one flip happens for every node (\\(24\\) different steady states) and flipping all the nodes generates the unique completely reversed steady state). The training data files are stored in the Zenodo file training-data-files.tar.gz. Run model ensembles simulations To generate the calibrated model ensembles and perform the drug response analysis on them we use the script run_druglogics_synergy_training.sh from the druglogics-synergy repository root (version 1.2.0: git checkout v1.2.0). Note that the training-data-files directory must be placed inside the druglogics-synergy root directory before executing the aforementioned script. The end result we get is the simulation results for each of the training data files (a different directory per training data file). The following changes need to be applied to the CASCADE 1.0 or 2.0 configuration file (depends on the topology you are using, the files are either druglogics-synergy/ags_cascade_1.0/config or druglogics-synergy/ags_cascade_2.0/config) before executing the script (some are done automatically in the script): If topology mutations are used, disable the link-operator mutations (balance_mutations: 0) and use topology_mutations: 10. Change the number of simulations to \\(20\\) (link-operator mutations) or \\(50\\) (topology mutations) for CASCADE 2.0 and to \\(50\\) for CASCADE 1.0 (default value, link-operator mutations). Change to Bliss synergy method (synergy_method: bliss) no matter the mutations used or topology. The results of the CASCADE 2.0 link-operator mutated model simulations are stored in the Zenodo file fit-vs-performance-results-bliss.tar.gz, whereas for the CASCADE 2.0 topology mutated models, in the fit-vs-performance-results-bliss-topo.tar.gz file. The results of the CASCADE 2.0 link-operator mutated model simulations are stored in the Zenodo file fit-vs-performance-results-bliss-cascade1.tar.gz. To parse and tidy up the data from the simulations, use the scripts fit_vs_perf_cascade2_lo.R (for the link-operator-based CASCADE 2.0 simulations), fit_vs_perf_cascade2_topo.R (for the topology-mutation-based CASCADE 2.0 simulations) and fit_vs_perf_cascade1_lo.R (for the link-operator-based CASCADE 1.0 simulations). Also, we used the run_druglogics_synergy.sh script at the root of the druglogics-synergy (script configuration for CASCADE 2.0: {2.0, prolif, 150, fixpoints, bliss} and for CASCADE 1.0: {1.0, prolif, 50, fixpoints, bliss}) repo to get the ensemble results of the random (proliferative) models that we will use to normalize the calibrated model performance. The result of this simulation is also part of the results described above (see section above, also considering the necessary changes applied for the topology mutation-based simulations for CASCADE 2.0) and it’s available inside the file sim_res.tar.gz of the Zenodo dataset (also available in the results directory - see Repo results structure). Random Model Bootstrap Install the druglogics-synergy module and use the version 1.2.0: git checkout v1.2.0 (or use directly the released v1.2.0 package) Run the the script run_gitsbe_random.sh inside the ags_cascade_2.0 directory of the druglogics-synergy repository. This creates a results directory which includes a models directory, with a total of \\(3000\\) gitsbe models which we are going to use for the bootstrapping. Place the models directory inside the ags_cascade_2.0 directory. Execute the bootstrap_models_drabme.sh inside the druglogics-synergy/ags_cascade_2.0 directory. Change appropriately the config file to have synergy_method: bliss. The bootstrap configuration consists of \\(20\\) batches, each one consisting of a sample of \\(100\\) randomly selected models from the model directory pool. Use the script random_model_boot.R to tidy the data from the simulations. The results of the simulations are stored in the random_model_bootstrap.tar.gz file of the Zenodo dataset. Parameterization Bootstrap Install the druglogics-synergy module and use the version 1.2.0: git checkout v1.2.0 (or use directly the released v1.2.0 package) To generate the \\(3\\) pools of calibrated models (fitting to the AGS steady state) subject to different normalization schemes, run the script run_gitsbe_param.sh inside the ags_cascade_2.0 directory of the druglogics-synergy repository root. This will generate the directories: gitsbe_link_only_cascade_2.0_ss gitsbe_topology_only_cascade_2.0_ss gitsbe_topo_and_link_cascade_2.0_ss, each of which have a models directory (the model pool) Repeat for each different pool (models directory): Place the models directory inside the ags_cascade_2.0 directory of the druglogics-synergy repository root. Use the bootstrap_models_drabme.sh script, while changing the following configuration: batches=25, batch_size=300 and the project variable name (input to eu.druglogics.drabme.Launcher) as one of the three: --project=link_only_cascade_2.0_ss_bliss_batch_${batch} --project=topology_only_cascade_2.0_ss_bliss_batch_${batch} --project=topo_and_link_cascade_2.0_ss_bliss_batch_${batch} , depending on the parameterization scheme that was used in the previous step to produce the models pool. Also change appropriately the config file to have synergy_method: bliss. The results of all these simulations are stored in the parameterization-comp.tar.gz Zenodo file. Use the script get_param_comp_boot_data.R to tidy up the simulation data to a nice table format. When uncompressed, the parameterization-comp.tar.gz file outputs 3 separate directories, one per parameterization scheme. Each separate directory is structured so as to contain the gitsbe simulation results with the model pool inside (result of the script run_gitsbe_param.sh), a boot_res directory (includes the results of the bootstrap_models_drabme.sh script) and lastly the results of the random proliferative model simulations which can be reproduced following the guidelines above. ERK investigation We split the link operator model pool (\\(4500\\) models, see above) to \\(2\\) pools, one with a total of \\(2764\\) models that have ERK_f active and one with a total of \\(1736\\) models that have it inhibited in the corresponding stable states. The two model pools are the two directories named erk_active_pool and erk_inhibited_pool respectively inside the Zenodo file erk_perf_investigation.tar.gz. Then: Install the druglogics-synergy module and use the version 1.2.0: git checkout v1.2.0 (or use directly the released v1.2.0 package) Run the script bootstrap_models_drabme_erk_pools.sh inside the ags_cascade_2.0 directory of the druglogics-synergy repository. This will produce the drug combination prediction results for the bootstrapped ensembles of boolean models from each pool. From each pool, we bootstrapped \\(35\\) ensembles with \\(300\\) models each and used the bliss drabme synergy method to calculate the prediction results. Run the script erk_perf_tidy_data.R to calculate the ROC and PR AUC of every bootstrapped ensemble, subject to normalization against the random proliferative model predictions. CASCADE 1.0 Calibrated Models bootstrap Install the druglogics-synergy module and use the version 1.2.0: git checkout v1.2.0 (or use directly the released v1.2.0 package) Generate one large pool of calibrated models (fitting to the AGS steady state) by using the instructions above =&gt; use the run_druglogics_synergy.sh script at the root of the druglogics-synergy repo with script config: {1.0, ss, 1000, fixpoints, bliss} Use the bootstrap_models_drabme_cascade1.sh script to run the bootstrapped model simulations. Use the get_syn_res_boot_ss_cascade1.R script to tidy up the bootstrap simulation data. The results from the bootstrap simulations are stored in the ss_cascade1_model_bootstrap.tar.gz file of the Zenodo dataset. Repo results structure We have gathered all the necessary output files from the above simulations (mostly relating to ROC, PR curves and AUC sensitivity figures) to the directory results for ease of use in our report. The results directory has 3 main sub-directories: link-only: results from the link-operator mutated models only (used in the sections Cascade 1.0 Analysis and CASCADE 2.0 Analysis (Link Operator Mutations)) topology-only: results from the topology-mutated models only (used in the section CASCADE 2.0 Analysis (Topology Mutations)) topo-and-link: results where both mutations applied to the generated boolean models (used in section CASCADE 2.0 Analysis (Topology and Link Operator Mutations)) In addition, there is a data directory that includes the following: observed_synergies_cascade_1.0: the gold-standard synergies for the CASCADE 1.0 topology (Flobak et al. 2015) observed_synergies_cascade_2.0: the gold-standard synergies for the CASCADE 2.0 topology (Flobak et al. 2019) steadystate, steadystate.rds: the AGS training data for the calibrated models (file + compressed data) - see lo_mutated_models_heatmaps.R script. edge_mat.rds, topo_ss_df.rds: heatmap data for the topology-mutation models - see lo_mutated_models_heatmaps.R script. lo_df.rds, lo_ss_df.rds: heatmap data for the link-operator models - see topo_mutated_models_heatmaps.R script. node_pathway_annotations_cascade2.csv, node_path_tbl.rds: node pathway annotation data for CASCADE 2.0 and compressed data table produced via the node_path_annot_cascade2.R script. cosmic_cancer_gene_census_all_29102020.tsv: Cancer Gene Census COSMIC data downloaded from https://cancer.sanger.ac.uk/census (for academic purposes) cosmic_tbl.rds: a compressed file with a tibble object having the CASCADE 2.0 nodes and their respective COSMIC cancer role annotation (see get_cosmic_data_annot.R script). bootstrap_rand_res.rds: a compressed file with a tibble object having the result data in a tidy format for the analysis related to the Bootstrap Random Model AUC section. res_fit_aucs_cascade1.rds: a compressed file with a tibble object having the result data in a tidy format for the analysis related to the Fitness vs Ensemble Performance section (CASCADE 1.0, link operator mutations). res_fit_aucs.rds: a compressed file with a tibble object having the result data in a tidy format for the analysis related to the Fitness vs Ensemble Performance section (CASCADE 2.0, link operator mutations). res_fit_aucs_topo.rds: a compressed file with a tibble object having the result data in a tidy format for the analysis related to the Fitness vs Ensemble Performance section (CASCADE 2.0, topology mutations). res_param_boot_aucs.rds: a compressed file with a tibble object having the result data in a tidy format for the analysis related to the Bootstrap Simulations section. boot_cascade1_res.rds: a compressed file with a tibble object having the result data from executing the script get_syn_res_boot_ss_cascade1.R, related to the scrambled topologies investigation in CASCADE 1.0. scrambled_topo_res_cascade1.rds: a compressed file with a tibble object having the result data from executing the script get_syn_res_scrambled_topo_cascade1.R, related to the scrambled topologies investigation in CASCADE 1.0. scrambled_topo_res_cascade2.rds: a compressed file with a tibble object having the result data from executing the script get_syn_res_scrambled_topo_cascade2.R, related to the scrambled topologies investigation in CASCADE 2.0. res_erl.rds: a compressed file with a tibble object having the result data from executing the script erk_perf_tidy_data.R, related to the ERK analysis with the link operator mutated models in CASCADE 2.0. The AUC sensitivity plots across the report are also included↩︎ "],["r-session-info.html", "R session info", " R session info xfun::session_info() R version 3.6.3 (2020-02-29) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 20.04.1 LTS Locale: LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C Package version: abind_1.4-5 assertthat_0.2.1 backports_1.2.1 base64enc_0.1.3 BH_1.72.0.3 bookdown_0.21 boot_1.3.25 brio_1.1.0 broom_0.7.3 callr_3.5.1 car_3.0-10 carData_3.0-4 cellranger_1.1.0 circlize_0.4.11 Ckmeans.1d.dp_4.3.3 cli_2.2.0 clipr_0.7.1 clue_0.3-58 cluster_2.1.0 codetools_0.2-18 colorspace_2.0-0 compiler_3.6.3 ComplexHeatmap_2.2.0 conquer_1.0.2 corrplot_0.84 cowplot_1.1.0 cpp11_0.2.4 crayon_1.3.4 crosstalk_1.1.0.1 curl_4.3 data.table_1.13.4 desc_1.2.0 diffobj_0.3.2 digest_0.6.27 dplyr_1.0.2 DT_0.16 ellipsis_0.3.1 emba_0.1.8 equatiomatic_0.1.0 evaluate_0.14 fansi_0.4.1 farver_2.0.3 forcats_0.5.0 foreach_1.5.1 foreign_0.8-75 gbRd_0.4-11 generics_0.1.0 GetoptLong_1.0.5 ggplot2_3.3.2 ggpubr_0.4.0 ggrepel_0.9.0 ggsci_2.9 ggsignif_0.6.0 glmnet_4.0-2 GlobalOptions_0.1.2 glue_1.4.2 graphics_3.6.3 grDevices_3.6.3 grid_3.6.3 gridExtra_2.3 gtable_0.3.0 haven_2.3.1 highr_0.8 hms_0.5.3 htmltools_0.5.0 htmlwidgets_1.5.3 igraph_1.2.6 isoband_0.2.3 iterators_1.0.13 jsonlite_1.7.2 knitr_1.30 labeling_0.4.2 later_1.1.0.1 latex2exp_0.4.0 lattice_0.20-41 lazyeval_0.2.2 lifecycle_0.2.0 lme4_1.1.26 magrittr_2.0.1 MAMSE_0.2-1 maptools_1.0.2 markdown_1.1 MASS_7.3.53 Matrix_1.2-18 MatrixModels_0.4.1 matrixStats_0.57.0 methods_3.6.3 mgcv_1.8.33 mime_0.9 minqa_1.2.4 munsell_0.5.0 nlme_3.1.151 nloptr_1.2.2.2 nnet_7.3.14 openxlsx_4.2.3 parallel_3.6.3 pbkrtest_0.4.8.6 pillar_1.4.7 pkgbuild_1.2.0 pkgconfig_2.0.3 pkgload_1.1.0 png_0.1-7 polynom_1.4.0 praise_1.0.0 prettyunits_1.1.1 processx_3.4.5 progress_1.2.2 promises_1.1.1 PRROC_1.3.1 ps_1.5.0 purrr_0.3.4 quantreg_5.75 R6_2.5.0 rbibutils_2.0 RColorBrewer_1.1-2 Rcpp_1.0.5 RcppArmadillo_0.10.1.2.0 RcppEigen_0.3.3.7.0 Rdpack_2.1 readr_1.4.0 readxl_1.3.1 rematch_1.0.1 rematch2_2.1.2 rio_0.5.16 rje_1.10.16 rjson_0.2.20 rlang_0.4.9 rmarkdown_2.6 rprojroot_2.0.2 rstatix_0.6.0 rstudioapi_0.13 scales_1.1.1 shape_1.4.5 sp_1.4.4 SparseM_1.78 splines_3.6.3 statmod_1.4.35 stats_3.6.3 stringi_1.5.3 stringr_1.4.0 survival_3.2-7 testthat_3.0.0 tibble_3.0.4 tidyr_1.1.2 tidyselect_1.1.0 tinytex_0.28 tools_3.6.3 usefun_0.4.8 utf8_1.1.4 utils_3.6.3 vctrs_0.3.5 viridisLite_0.3.0 visNetwork_2.0.9 waldo_0.2.3 withr_2.3.0 xfun_0.19 yaml_2.2.1 zip_2.1.1 "],["references.html", "References", " References Braschi, Bryony, Paul Denny, Kristian Gray, Tamsin Jones, Ruth Seal, Susan Tweedie, Bethan Yates, and Elspeth Bruford. 2019. “Genenames.org: The HGNC and VGNC resources in 2019.” Nucleic Acids Research 47 (D1): D786–D792. https://doi.org/10.1093/nar/gky930. Flobak, Åsmund, Anaïs Baudot, Elisabeth Remy, Liv Thommesen, Denis Thieffry, Martin Kuiper, and Astrid Lægreid. 2015. “Discovery of Drug Synergies in Gastric Cancer Cells Predicted by Logical Modeling.” Edited by Ioannis Xenarios. PLOS Computational Biology 11 (8): e1004426. https://doi.org/10.1371/journal.pcbi.1004426. Flobak, Åsmund, Barbara Niederdorfer, Vu To Nakstad, Liv Thommesen, Geir Klinkenberg, and Astrid Lægreid. 2019. “A high-throughput drug combination screen of targeted small molecule inhibitors in cancer cell lines.” Scientific Data 6 (1): 237. https://doi.org/10.1038/s41597-019-0255-7. Friedman, Jerome, Trevor Hastie, Rob Tibshirani, Balasubramanian Narasimhan, Kenneth Tay, and Noah Simon. 2020. Glmnet: Lasso and Elastic-Net Regularized Generalized Linear Models. https://CRAN.R-project.org/package=glmnet. Grau, Jan, Ivo Grosse, and Jens Keilwagen. 2015. “PRROC: computing and visualizing precision-recall and receiver operating characteristic curves in R.” Bioinformatics 31 (15): 2595–7. https://doi.org/10.1093/bioinformatics/btv153. Gu, Zuguang, Roland Eils, and Matthias Schlesner. 2016. “Complex heatmaps reveal patterns and correlations in multidimensional genomic data.” Bioinformatics 32 (18): 2847–9. https://doi.org/10.1093/bioinformatics/btw313. Holland, John Henry. 1992. Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence. MIT press. Niederdorfer, Barbara, Vasundra Touré, Miguel Vazquez, Liv Thommesen, Martin Kuiper, Astrid Lægreid, and Åsmund Flobak. 2020. “Strategies to Enhance Logic Modeling-Based Cell Line-Specific Drug Synergy Prediction.” Frontiers in Physiology 11 (July): 862. https://doi.org/10.3389/fphys.2020.00862. Pepe, M. S. 2000. “Combining diagnostic test results to increase accuracy.” Biostatistics 1 (2): 123–40. https://doi.org/10.1093/biostatistics/1.2.123. Plante, Jean-Francois. 2017. MAMSE: Calculation of Minimum Averaged Mean Squared Error (Mamse) Weights. https://CRAN.R-project.org/package=MAMSE. Saito, Takaya, and Marc Rehmsmeier. 2015. “The Precision-Recall Plot Is More Informative than the ROC Plot When Evaluating Binary Classifiers on Imbalanced Datasets.” Edited by Guy Brock. PLOS ONE 10 (3): e0118432. https://doi.org/10.1371/journal.pone.0118432. Sondka, Zbyslaw, Sally Bamford, Charlotte G. Cole, Sari A. Ward, Ian Dunham, and Simon A. Forbes. 2018. “The COSMIC Cancer Gene Census: describing genetic dysfunction across all human cancers.” Nature Reviews Cancer 18 (11): 696–705. https://doi.org/10.1038/s41568-018-0060-1. Veliz-Cuba, Alan, Boris Aguilar, Franziska Hinkelmann, and Reinhard Laubenbacher. 2014. “Steady state analysis of Boolean molecular network models via model reduction and computational algebra.” BMC Bioinformatics 15 (1): 221. https://doi.org/10.1186/1471-2105-15-221. Zobolas, John. 2020a. Rtemps: R Templates for Reproducible Data Analyses. https://github.com/bblodfon/rtemps. ———. 2020b. usefun: A Collection of Useful Functions by John. https://github.com/bblodfon/usefun. Zobolas, John, Martin Kuiper, and Åsmund Flobak. 2020. “Emba: R Package for Analysis and Visualization of Biomarkers in Boolean Model Ensembles.” Journal of Open Source Software 5 (53): 2583. https://doi.org/10.21105/joss.02583. "]]
